The recent big data movement resulted in a surge of activity on layering declarative languages on top of distributed computation platforms
In the Semantic Web realm this surge of analytics languages was not reflected despite the significant growth in the available Semantic Web data
Consequently when analysing large RDF datasets users are left with two main options using SPARQL or using an existing nonRDFspecific big data language
Consequently when analysing large RDF datasets users are left with an existing nonRDFspecific own limitations
the high cost of evaluation can be limiting in some scenarios
The pure declarative nature of SPARQL can be limiting in some scenarios
On the other hand existing big data languages are designed mainly for tabular data and therefore applying languages to Semantic Web data results in verbose unreadable scripts
On the other hand existing big data languages are designed mainly for tabular data and therefore applying languages to Semantic Web data results in verbose sometimes inefficient scripts
In this paper we introduce SYRql
In this paper we introduce a dataflow language
a dataflow language designed to process Semantic Web data at a large scale
SYRql blends concepts from both SPARQL languages
SYRql blends concepts from existing big data languages
a closed algebra that underlies SYRql
a closed algebra that discuss a closed algebra
a closed algebra that underlies SYRql
We formally define a closed algebra and some unique optimisation opportunities this algebra provides properties and some unique optimisation opportunities this algebra provides
a closed algebra that discuss its properties
Furthermore we describe an implementation
an implementation that translates SYRql scripts into a series of MapReduce jobs
an implementation that compare the performance to other big data processing languages