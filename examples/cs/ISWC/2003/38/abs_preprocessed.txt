we present this benchmark is intended to evaluate the performance of damloil repositories with respect to extensional queries over a large data
this benchmark is intended to evaluate the performance of damloil repositories with respect to extensional queries over a large data set that commits to a single realistic ontology
this benchmark is intended to evaluate the performance of damloil repositories with respect to extensional queries over a large data consists of several performance metrics
this benchmark is intended to evaluate the performance of damloil repositories with respect to extensional queries over a large data consists of customizable synthetic data
this benchmark is intended to evaluate the performance of damloil repositories with respect to extensional queries over a large data consists of a set of test queries
this benchmark is intended to evaluate the performance of damloil repositories with respect to extensional queries over a large data consists of the ontology
main features of the benchmark include a plausible ontology for the university domain
a repeatable data set that can be scaled to an arbitrary size
main features of the benchmark include a repeatable data set
main features of the benchmark include an approach for measuring the degree to which a repository returns complete query answers
we also show a benchmark experiment for the evaluation of dldb
a damloil repository that extends a relational database management system with description logic inference capabilities
we also show a benchmark experiment for the evaluation of a damloil repository