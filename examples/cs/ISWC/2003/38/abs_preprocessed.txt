We present This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data set that commits to a single realistic ontology
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of customizable synthetic data
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of several performance metrics
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of a set of test queries
This benchmark is intended to evaluate the performance of DAMLOIL repositories with respect to extensional queries over a large data consists of the ontology
Main features of the benchmark include a plausible ontology for the university domain
Main features of the benchmark include an approach for measuring the degree to which a repository returns complete query answers
a repeatable data set that can be scaled to an arbitrary size
Main features of the benchmark include a repeatable data set
a DAMLOIL repository that extends a relational database management system with description logic inference capabilities
We also show a benchmark experiment for the evaluation of DLDB
We also show a benchmark experiment for the evaluation of a DAMLOIL repository