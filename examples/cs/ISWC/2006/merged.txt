an ontology alignment explicitly describes the relations
the relations holding between two ontologies
a system composed of ontologies interconnecting them
a system composed of ontologies interconnecting a system
a system composed of alignments interconnecting a system
a system is herein called a distributed system
a system composed of alignments interconnecting them
we give three different semantics of a distributed system
a distributed system that do not interfere with the semantics of ontologies
a system composed of ontologies interconnecting them advantages
a system are compared with respect to allowing consistent merge of ontologies
a system are compared with respect to managing heterogeneity
a system composed of alignments interconnecting them advantages
a system are compared with respect to complying with an alignment composition operation
we show that only the first two variants can offer a sound composition operation
only the first two variants which differ from other proposed semanticsontology search and reuse is becoming increasingly important as the quest for methods to reduce the cost of constructing such knowledge structures continues
a number of search engines are coming to existence to facilitate locating potentially relevant ontologies
a number of ontology libraries are coming to existence to facilitate retrieving potentially relevant ontologies
a number of search engines are coming to existence to facilitate retrieving potentially relevant ontologies
a number of ontology libraries are coming to existence to facilitate locating potentially relevant ontologies
a number of ontology libraries is steadily growing
a number of ontology libraries so is the need for methods to evaluate and rank existing ontologies in terms of a number of search engines relevance to the needs of the knowledge engineer
a number of search engines so is the need for methods to evaluate and rank existing ontologies in terms of a number of search engines relevance to the needs of the knowledge engineer
a number of search engines so is the need for methods to evaluate and rank existing ontologies in terms of a number of ontology libraries relevance to the needs of the knowledge engineer
a number of search engines is steadily growing
a number of ontology libraries so is the need for methods to evaluate and rank existing ontologies in terms of a number of ontology libraries relevance to the needs of the knowledge engineer
this paper presents a prototype system for ranking ontologies
this paper presents aktiverank
ranking ontologies based on a number of structural metricsin recent years workflows have been increasingly used in scientific applications
this paper presents novel metadata reasoning capabilities that we have developed to support the creation of large workflows
this paper include 3  subworkflows that generate metadata
this paper include 2  validation of metadata constraints from inputs to outputs in a workflow component
this paper include 2  propagation of metadata constraints from inputs to outputs in a workflow component
this paper include 2  propagation of metadata constraints from inputs through the links among components in a workflow
this paper include 1  use of semantic web technologies in handling metadata constraints on file nested file collections
this paper include 2  validation of metadata constraints from inputs through the links among components in a workflow
this paper include 1  use of semantic web technologies in handling metadata constraints on file collections
metadata needed for workflow creation
we show how we used these capabilities to support the creation of large executable workflows in an earthquake science application with more than 7000 jobs generating metadata for more than 100000 new filesan ontology language developed by the w3c
owl is an ontology language
although initially developed for the semantic web owl has rapidly become a de facto standard for ontology development in general
the specification includes a formal semantics
the design of owl was heavily influenced by research in description logics
one of the goals of this formal approach was to provide interoperability different owl reasoners should provide the same results when processing the same ontologies
a system that allows users to test owl reasoners using an extensible library of reallife ontologies to check the  correctness  of owl reasoners by comparing the computed class hierarchy to compare the performance of owl reasoners when to use sql queries to analyse the results in any way
a system that allows users to compare owl reasoners using an extensible library of reallife ontologies to check the  correctness  of owl reasoners by comparing the computed class hierarchy to compare the performance of owl reasoners when to use sql queries to analyse the results in any way
a system that allows users to test owl reasoners using an extensible library of reallife ontologies to check the  correctness  of owl reasoners by comparing the computed class hierarchy to compare the performance of owl reasoners when to use sql queries to present the results in any way
in this paper we present a system they see fit
a system that allows users to test owl reasoners using an extensible library of reallife ontologies to check the  correctness  of owl reasoners by comparing the computed class hierarchy to compare the performance of owl reasoners when performing this task
a system that allows users to compare owl reasoners using an extensible library of reallife ontologies to check the  correctness  of owl reasoners by comparing the computed class hierarchy to compare the performance of owl reasoners when to use sql queries to present the results in any way
a system that allows users to compare owl reasoners using an extensible library of reallife ontologies to check the  correctness  of owl reasoners by comparing the computed class hierarchy to compare the performance of owl reasoners when performing this taskfacet browsing has become popular as a user friendly interface to data repositories
the semantic web raises new challenges due to the heterogeneous character of the data
first users should be able to make selections based on properties of other semantically related types
first users should be able to select through facets of resources of any type
first users should be able to navigate through facets of resources of any type
second where traditional facet browsers require manual configuration of the software a semantic web browser should be able to handle any rdfs dataset without any additional configuration
third hierarchical data on the semantic web is not designed for browsing complementary techniques such as search should be available to overcome this problem
we address these requirements in we browser facet
the hierarchical navigation that characterizes current facet browsing
additionally the interface allows the inclusion of facetspecific display options
facetspecific display options that go beyond the hierarchical navigation
facet is a tool for the semantic web developers as an instant interface to the semantic web complete dataset
the automatic facet configuration can then be further
the automatic facet configuration generated by the system
further refined to configure the system as a tool for end users
the implementation is based on current web standards
the implementation is based on open source software
the new functionality is motivated using a scenario from the cultural heritage domainthe technical challenges associated with the development and deployment of ontologies
the technical challenges have been subject to a considerable number of research initiatives since the beginning of the nineties
the economical aspects of these processes are however still poorly exploited impeding the dissemination of ontologydriven technologies beyond the boundaries of the academic community
this paper aims at contributing to the alleviation of this situation by proposing ontocom 
the costs arising in ontology engineering processes
this paper aims at contributing to the alleviation of this situation by proposing a model to predict the costs
this paper aims at contributing to the alleviation of this situation by proposing ontology cost model 
we introduce an inventory of cost drivers
cost drivers which influence the amount of effort
we introduce a methodology to generate a cost model adapted to a particular ontology development strategy
activities performed during an ontology life cycle
effort invested in activities
the model validation procedure which covered a statistical calibration on 36 data points
36 data points collected from realworld projects
we further present the results of the model validation procedure
the model validation procedure which covered an expertdriven evaluation on 36 data points
a high learning rate indicating that the building of very large ontologies is feasible from an economic point of view
the validation revealed that ontology engineering processes have a high learning rate
moreover the complexity of domain analysis proved to have a major impact on the final ontology engineering process duration
moreover the complexity of conceptualization activities proved to have a major impact on the final ontology engineering process duration
moreover the complexity of ontology evaluation proved to have a major impact on the final ontology engineering process durationlogic programming is often seen as a way to perform closedworld querying
logic programming is often seen as a way to overcome several shortcomings of the web ontology language such as the inability to model integrity constraints
however the openworld semantics of the web ontology language seems to be fundamentally incompatible with the closedworld semantics of logic programming
this has sparked a heated debate in the the semantic web community
a heated debate in the the semantic web community resulting in proposals for alternative ontology languages
alternative ontology languages based entirely on logic programming
the practical use cases which seem to be addressed by logic programming
to help resolving a heated debate in the semantic web community we investigate the practical use cases
in fact many of these requirements have already been addressed outside the semantic web
hybrid mknf knowledge bases which seamlessly integrates the web ontology language with logic programming
by drawing inspiration from these existing formalisms we present a novel logic of hybrid mknf knowledge bases
we are thus capable of addressing the identified use cases without a radical change in the architecture of the semantic websemantic web languages are being used to represent exchange semantic data in many contexts beyond the web in databases networking environments
semantic web languages are being used to represent encode semantic data in many contexts beyond the web in multiagent systems networking environments
semantic web languages are being used to represent encode semantic data in many contexts beyond the web in mobile computing networking environments
semantic web languages are being used to represent encode semantic data in many contexts beyond the web in databases networking environments
semantic web languages are being used to represent exchange semantic data in many contexts beyond the web in ad hoc networking environments
semantic web languages are being used to represent exchange semantic data in many contexts beyond the web in mobile computing networking environments
semantic web languages are being used to represent exchange semantic data in many contexts beyond the web in multiagent systems networking environments
semantic web languages are being used to represent encode semantic data in many contexts beyond the web in ad hoc networking environments
the core paradigm however remains what we call the semantic web use by independent
distributed agents who publish data on the world wide web
the core paradigm however remains what we call the web aspect of the semantic web
the core paradigm however remains what we call distributed agents
distributed agents who consume data on the world wide web
to better understand this central use case we have harvested a collection of the world wide web documents from an estimated ten million available on the world wide web
to better understand this central use case we have analyzed a collection of the world wide web documents from an estimated ten million available on the world wide web
using a corpus of more than 17 million documents we describe a number of usage patterns
more than 17 million documents comprising over 300 million rdf triples
using a corpus of more than 17 million documents we describe a number of global metrics properties
most of the metrics such as the use frequency of the world wide web terms were found to follow a power law distribution
most of the metrics such as the size of the world wide web documents were found to follow a power law distributionthe task of automatically composing web services involves two main composition processes
the task of automatically composing web services involves horizontal composition
the task of automatically composing web services involves vertical
vertical composition consists of defining an appropriate combination of simple processes to perform a composition task
horizontal composition process consists of determining the most appropriate web service from among a set of functionally equivalent ones for each component process
several recent research efforts have dealt with the web service composition problem
nevertheless most of several recent research efforts tackled only the vertical composition of web services despite the growing trend towards functionally equivalent web services
in an attempt to streamline the process of horizontal composition of web services while taking the above limitation into consideration this work includes two main contributions
in an attempt to facilitate this work includes two main contributions
the first is a generic formalization of any web service composition problem a generic formalization of any web service composition problem based on a constraint optimization problem a constraint optimization problem is compatible to any web service description language
any web service composition problem based on a constraint optimization problem
some predefined criteria at runtime
the second contribution is an incremental userinterventionbased protocol to find the optimal composite web service according to some
our goal is i  to deal with many crucial natural features of web services such as incomplete web service information etc and ii  to allow human user intervention to enhance the solving process
our goal is i  to deal with many crucial natural features of web services such as distributed environment etc and ii  to allow human user intervention to enhance the solving process
our goal is i  to deal with many crucial natural features of web services such as uncertain etc and ii  to allow human user intervention to enhance the solving process
our goal is i  to deal with many crucial natural features of web services such as dynamic etc and ii  to allow human user intervention to enhance the solving process
three approaches are described in this work a centralized approach
three approaches are described in this work a distributed approach
three approaches are described in this work a multiagent approach to deal with realistic domainsin this paper we show how to use ontologies to bootstrap a knowledge acquisition process
a knowledge acquisition process that extracts product information from tabular data on web pages
furthermore we use logical rules to to derive higherorder knowledge about product features
furthermore we use logical rules to reason about product specific properties
the knowledge acquisition process covering both procedural aspects
we will also explain the knowledge acquisition process
the knowledge acquisition process covering both ontological aspects
finally we will give an quantitative evaluation of we results
finally we will give an qualitative evaluation of we resultsontology matching is a crucial task to enable interoperation between web applications using related ontologies
ontology matching is a crucial task to enable interoperation between web applications using different ontologies
today most of the ontology matching techniques are targeted to find 11 mappings
however block mappings are in fact more pervasive
both the mapping the partitioning quality
in this paper we suggest that both the should be considered in block matching
in this paper we discuss the block matching problem
both the mapping quality
we propose a novel partitioningbased approach to address the block matching issue
a novel partitioningbased approach considers both structural characteristics of domain entities
a novel partitioningbased approach uses a hierarchical bisection algorithm for partitioning
domain entities based on virtual documents
a novel partitioningbased approach considers both linguistic characteristics of domain entities
we set up two kinds of metrics to evaluate of the quality of block matching
the experimental results demonstrate that we approach is feasibleowl ontologies present many interesting visualization challenges
here we present cropcircles
here we present a technique
a technique designed to view the class hierarchies in ontologies as trees
topology understanding when designing the tool
we place special emphasis on topology understanding
we made substantial changes in the representation and layout
we drew inspiration from treemaps
most notably the spacefillingness of treemap is relaxed in exchange for visual clarity
we outline the problem scape of visualizing ontology hierarchies
the requirements that go into the design of the tool
we discuss the interface and implementation
we note the requirements
finally through a controlled experiment we show the benefits of we design
a controlled experiment involving tasks common to understanding ontologiessemantic annotations of web services can facilitate services composition into workflows
semantic annotations of web services can facilitate the discovery of services
at present however the practical utility of such annotations is limited by the small number of service annotations available for general use
therefore some means is required by which services can be automatically  or semiautomatically  annotated
resources for manual annotation are scarce
in this paper we show how information can be inferred about the semantics of operation parameters
operation parameters based on this paper connections to other  operation parameters within triedandtested workflows
operation parameters based on this paper connections to annotated  operation parameters within triedandtested workflows
in an openworld context we can infer only constraints on the semantics of parameters
these socalled loose annotations are still of value in detecting errors within workflows
these socalled loose annotations are still in simplifying the manual annotation task
these socalled loose annotations are still of value in detecting errors within annotations
these socalled loose annotations are still of value in detecting errors within ontologiesontology mapping plays an important role in bridging the semantic gap between heterogeneous data sources
ontology mapping plays an important role in bridging the semantic gap between distributed data sources
as the semantic web slowly becomes real amount of online semantic data increases a new generation of tools is developed that automatically integrate this data
as the semantic web slowly becomes the amount of online semantic data increases a new generation of tools is developed that automatically find this data
as the semantic web slowly becomes real amount of online semantic data increases a new generation of tools is developed that automatically find this data
as the semantic web slowly becomes the amount of online semantic data increases a new generation of tools is developed that automatically integrate this data
unlike in the case of these new tools these new tools require mapping techniques
techniques that can be performed at run time
the contribution of this paper is twofold
run time mapping techniques
first we investigate the general requirements for run time
second we describe we powermap mapping algorithm
an ontology based question answering tool
algorithm that was designed to be used at runtime by an ontologyvisually impaired users are hindered in visually impaired users efforts to access the largest repository of electronic information in the world 
visually impaired users are hindered in visually impaired users the world wide the world wide web
the web is and does  hinder users
users who need presentationagnostic access to information
the web is visuallycentric with regard to information order layout this can  hinder users
the web is visuallycentric with regard to presentation order layout this can  hinder users
transcoding can help to make information more accessible via a restructuring of pages
we describe an approach based on annotation of web pages encoding semantic information
a form that provides easier access to content
semantic information that can then be used by tools in order to manipulate
we describe an approach based on annotation of web pages encoding present web pages in a form
annotations are made directly to style sheet information allowing the annotation of large numbers of similar pages with little effortin a semantic environment data is described by ontologies
heterogeneity problems have to be solved at the ontological level
this means that alignments between ontologies have to be created most probably during designtime
this means that alignments between ontologies have to be used in various runtime processes
such alignments describe a set of mappings between the target ontologies where the mappings show how instance data from one ontology can be expressed in terms of another ontology
such alignments describe a set of mappings between the source ontologies where the mappings show how instance data from one ontology can be expressed in terms of another ontology
we propose a formal model for mapping creation
starting from a formal model we explore how such a model maps onto a designtime graphical tool
a designtime graphical tool that can be used in creating alignments between ontologies
we also investigate how such a model helps in expressing the mappings in a logical language based on the semantic relationships
the semantic relationships identified using the graphical toolranking is an important concept to avoid empty or overfull and unordered result sets
however such scoring can only express total orders
total orders which restricts its usefulness when several factors influence result relevance
a more flexible way to express relevance is the notion of preferences
users state which kind of answers they  prefer  by adding soft constraints to they queriesan ontology using the rules
a common approach for reasoning is to work on the closure at query time
the rules specified
a common approach for reasoning is to compute the deductive closure of an ontology
a common approach for reasoning increases the space requirements
a common approach for reasoning reduces the run time complexity
the main reason of this increase is the type statements in the ontology
the main reason of this increase is the subclass statements in the ontology
type statements show a significant percentage in most ontologies
particular type statements relying on this increase
since subclass is a transitive property derivation of other statements in particular type statements gives rise to cyclic repetition
since subclass is a transitive property derivation of other statements in particular type statements gives rise to an excess of inferred type statements
in brief a major part of closure computation is deriving the type statements
the type statements relying on subclass statements
in this paper we propose a syntactic transformation
a syntactic transformation that is based on novel individual grouping constructs
inferred type statements relying on subclass relations
a syntactic transformation that is based on novel individual grouping constructs
a syntactic transformation reduces the number of inferred type statements
thus the space requirement of reasoning is reduced without affecting the soundness
thus the space requirement of reasoning is reduced without affecting the completenessapplications that span over several enterprises by applying techniques
notations offered by business
applications that span over several enterprises by applying methodologies
we present a framework for developing semantic web service applications process modeling
notations offered by web engineering
we present a framework for designing semantic web service applications process modeling
notations offered by software engineering
applications that span over several enterprises by applying notations
powerful methodologies tools and notations  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of wsmo ontologies  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of goals  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of web services  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of wsmo ontologies  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of mediators  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
in particular we propose to exploit existing standards for the specification of bpmn  for modeling the cross enterprise process combined with powerful methodologies tools and notations 
powerful methodologies tools and notations  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of mediators  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of goals  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of semantic descriptions  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of wsmo ontologies  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of wsmo ontologies  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of web services  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of semantic descriptions  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of goals  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of web services  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
in particular we propose to exploit existing standards for the specification of business processes  for modeling the cross enterprise process combined with powerful methodologies tools and notations 
in particular we propose to exploit existing standards for the specification of bpmn  for modeling the cross enterprise process combined with webml 
in particular we propose to exploit existing standards for the specification of business processes  for modeling the cross enterprise process combined with webml 
eg webml  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of mediators  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of semantic descriptions  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
eg webml  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of goals  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
the information crossing the organization boundaries
eg webml  borrowed from the web engineering field for developing semantically rich web applications with semiautomatic elicitation of web services  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of mediators  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the information
powerful methodologies tools and notations  borrowed from the web engineering field for designing semantically rich web applications with semiautomatic elicitation of semantic descriptions  from the design of the applications with huge advantages in terms of efficiency of the design and reduction of the extra work necessary for semantically annotating the informationwith the fast development of semantic web more are shared
with the fast development of semantic web owl ontologies are created
with the fast development of semantic web owl ontologies are shared
with the fast development of semantic web more rdf are shared
with the fast development of semantic web more rdf are created
with the fast development of semantic web more are created
the effective management such as inference of these ontologies on databases gains increasing attention
the effective management such as storage of these ontologies on databases gains increasing attention
the effective management such as inference of these ontologies on databases gains
the effective management such as query of these ontologies on databases gains increasing attention
the effective management such as storage of these ontologies on databases gains
the effective management such as query of these ontologies on databases gains
this paper addresses ontology query answering on databases by means of datalog programs
this paper addresses ontology query
owl that are not covered by datalogstyle rule languages
via epistemic operators integrity constraints are used for conveying semantic aspects of owl
via epistemic operators integrity constraints are introduced
we believe such a processing suitable to capture ontologies in the database flavor while keeping reasoning tractable
here we present a logically equivalent knowledge base whose  complete  inference system appears as a datalog program
here we present a logically equivalent knowledge base whose  sound  inference system appears as a datalog program
sparql query answering on owl ontologies
as such sparql query could be solved in databases
bidirectional strategies taking advantage of both forward chaining
bidirectional strategies are then studied to support this kind of customized datalog programs returning exactly answers to the query within our logical framework
bidirectional strategies taking advantage of both backward chainingour empirical study shows that strong dependencies exist across different types of information  it means that identification of one kind of information can be used for identifying the other kind of information 
the large volume of web content needs to be annotated by ontologies  called semantic annotation 
conditional random fields are the stateoftheart approaches for modeling the dependencies to do better annotation
however as information on a web page is not necessarily linearly laidout the previous linearchain conditional random fields have the previous linearchain conditional random fields limitations in semantic annotation
this paper is concerned with semantic annotation on hierarchical semantic annotation 
this paper is concerned with semantic annotation on hierarchically dependent data 
we propose tcrf  model to better incorporate dependencies across the hierarchically laidout information
we propose a treestructured conditional random field  model to better incorporate dependencies across the hierarchically laidout information
methods for performing the tasks of modelparameter estimation and annotation in tcrfs have been proposed
experimental results indicate that the proposed tcrfs for hierarchical semantic annotation can significantly outperform the existing linearchain conditional random field modelwe claim that user preferences are a component
we claim that user preferences are a key component of web service composition
a component that has largely been ignored
in this paper we propose a means of specifying user preferences into web service composition
in this paper we propose a means of intergrating user preferences into web service composition
to this end we propose a means of performing automated web service composition by exploiting generic procedures together with rich qualitative user preferences
we exploit the agent programming language golog to represent we generic procedures to represent rich qualitative temporal user preferences
we exploit the agent programming language golog to represent we a firstorder preference language to represent rich qualitative temporal user preferences
web service compositions that realize the generic procedure satisfying the users hard constraints
web service compositions that realize the generic procedure optimizing for the users preferences
from these we generate web service compositions
we prove we approach sound
we prove we approach optimal
we system gologpref is interacting with services on the web
we system gologpref is implemented
the language and techniques proposed in this paper
the language and techniques can be integrated into a variety of approaches to grid service composition
the language and techniques can be integrated into a variety of approaches to webthe goal of the work is to obtain large amounts of semistructured data from the web
the work presented in this paper
harvesting semistructured data is a prerequisite to enabling largescale query answering over web sources
we contrast we approach to conventional web crawlers and describe a fivestep pipelined architecture to index data from both the traditional
we contrast we approach to conventional web crawlers and describe a fivestep pipelined architecture to crawl
we contrast we approach to conventional web crawlers and evaluate a fivestep pipelined architecture to index data from both the traditional
we contrast we approach to conventional web crawlers and evaluate a fivestep pipelined architecture to crawl
we contrast we approach to conventional web crawlers and describe a fivestep pipelined architecture to index data from both the semantic web
we contrast we approach to conventional web crawlers and evaluate a fivestep pipelined architecture to index data from both the semantic webautomated composition of web services added web services is one of the most promising challenges in the semantic web service research area
automated composition of the process of forming new value added web services is one of the most promising challenges in the semantic web service research area
semantics is one of the key elements for the automated composition of web services because such a process requires rich machineunderstandable descriptions of services
services that can be shared
semantics enables web service to describe web service capabilities and processes nevertheless there is still some work to be done
indeed web services need a formal context to perform the automated composition of web services
web services described at functional level
the suggested model  is a necessary starting point to apply problemsolving techniques such as regressionbased search for web service composition
ie causal link matrix  is a necessary starting point to apply problemsolving techniques such as regressionbased search for web service composition
the suggested model supports a semantic context in order to find a optimal plan as a solution
ie causal link matrix supports a semantic context in order to find a consistent plan as a solution
the suggested model supports a semantic context in order to find a correct plan as a solution
ie causal link matrix supports a semantic context in order to find a complete plan as a solution
the suggested model supports a semantic context in order to find a complete plan as a solution
ie causal link matrix supports a semantic context in order to find a optimal plan as a solution
the suggested model supports a semantic context in order to find a consistent plan as a solution
ie causal link matrix supports a semantic context in order to find a correct plan as a solution
in this paper an formal model for an ai planningoriented composition is presented
in this paper an innovative model for an ai planningoriented composition is presentedprecisely identifying entities in web documents is essential for document indexing data integration
precisely identifying entities in web documents is essential for document indexing web search
entity disambiguation is the challenge of determining the correct entity out of various candidate entities
our novel method utilizes background knowledge in the form of a populated ontology
data items that can provide strong evidence such as email addresses for disambiguating person names
additionally our novel method does not rely on the existence of any structure in a document
additionally our novel method does not rely on the appearance of data items
originality of our is demonstrated from the ontology to provide clues in determining the correct entity
originality of our is demonstrated in the way our novel method uses different relationships in a document
we demonstrate the applicability of we method by disambiguating names of researchers
researchers appearing in a collection of dbworld posts using a large scale realworld ontology
realworld ontology extracted from the dblp bibliography website
the precision measurements provide encouraging results
the recall measurements provide encouraging resultsthe casual user is typically overwhelmed by the formal logic of the semantic web
the gap between the end user has to be bridged if the semantic web capabilities are to be utilized by the general public
the gap between the logicbased scaffolding has to be bridged if the semantic web capabilities are to be utilized by the general public
this paper proposes that controlled natural languages offer one way to bridge the gap between the logicbased scaffolding
this paper proposes that controlled natural languages offer one way to bridge the gap between the end user
we introduce gino
natural language ontology editor that allows users to edit ontologies in a language akin to english
natural language ontology editor that allows users to query ontologies in a language akin to english
we introduce a guided input natural language ontology editor
a small static grammar which this paper dynamically extends with elements from the loaded ontologies
this paper uses a small static grammar
the usability evaluation shows that gino is wellsuited for novice users when editing ontologies
natural language ontology editor that allows users to query ontologies in a language akin to english
natural language ontology editor that allows users to edit ontologies in a language akin to english
the usability evaluation shows that a guided input natural language ontology editor is wellsuited for novice users when editing ontologies
thehabitability problem which adversely affects most natural language systems
we believe that the use of guided entry overcomes thehabitability problem
additionally the approachs dynamic grammar generation allows for easy adaptation to new ontologieswhen agents communicate agents do not necessarily use the same vocabulary or ontology
the terms used in agents respective ontologies
for agents to interact successfully agents must find correspondences between the terms
while many proposals for matching two agent ontologies have been presented in the literature the resulting alignment may not be satisfactory to both agents
while many proposals for matching two agent ontologies have been presented in the literature the resulting alignment thus may necessitate additional negotiation to identify a mutually agreeable set of correspondencesan approach that unifies browsing by visual features for intuitive exploration of image databases
an approach that unifies browsing by tags for intuitive exploration of image databases
we propose an approach
collaborative tagging sites complemented by simple image analysis
collaborative tagging sites complemented by classification
in contrast to traditional image retrieval approaches we utilise tags provided by users on collaborative tagging sites
this allows us to find new relations between data elements
we introduce the concept of a navigation map
a navigation map that describes links between users
a navigation map that describes links between data elements for the example of the collaborative tagging site flickr
a navigation map that describes links between tags
we show that introducing similarity search based on image features yields additional links on this map
we system using tags from real the collaborative tagging site flickr users
examples provided by we system
these theoretical considerations are supported by examples
we system using data from real the collaborative tagging site flickr userssparql is the w3c candidate recommendation query language for rdf
in this paper we address systematically the formal study of sparql
the formal study of sparql concentrating in sparql graph pattern facility
filters which encompasses all the main issues
we consider for the formal study of sparql simple rdf graphs without a simplified version of filters
we consider for the formal study of sparql simple rdf graphs without special semantics for literals
we provide a compositional semantics prove there are normal forms prove complexity bounds among others that the evaluation of sparql patterns is pspacecomplete compare we semantics to an alternative operational semantics give simple conditions when our semantics coincide optimization procedures
we provide a compositional semantics prove there are normal forms prove complexity bounds among others that the evaluation of sparql patterns is pspacecomplete compare we semantics to an alternative operational semantics give simple conditions when our semantics discuss optimization procedures
we provide a compositional semantics prove there are normal forms prove complexity bounds among others that the evaluation of sparql patterns is pspacecomplete compare we semantics to an alternative operational semantics give natural conditions when our semantics coincide optimization procedures
we provide a compositional semantics prove there are normal forms prove complexity bounds among others that the evaluation of sparql patterns is pspacecomplete compare we semantics to an alternative operational semantics give natural conditions when our semantics discuss optimization proceduresmodular ontology languages such as modular ontology languages such as distributed description logics econnections  offer the use of importing modular ontology languages such as ddl packagebased description logics
modular ontology languages such as distributed description logics  offer the use of importing modular ontology languages such as ddl econnections
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as distributed description logics packagebased description logics
modular ontology languages such as distributed description logics  offer the use of mappings between ontology modules eg
modular ontology languages such as distributed description logics  offer the use of importing modular ontology languages such as distributed description logics packagebased description logics
modular ontology languages such as modular ontology languages such as distributed description logics econnections  offer the use of linkings between ontology modules eg
modular ontology languages such as packagebased description logics  offer two broad classes of approaches to connect multiple ontology modules
modular ontology languages such as distributed description logics  offer the use of importing modular ontology languages such as ddl packagebased description logics
modular ontology languages such as econnections  offer the use of importing modular ontology languages such as distributed description logics econnections
modular ontology languages such as packagebased description logics  offer the use of mappings between ontology modules eg
modular ontology languages such as distributed description logics  offer two broad classes of approaches to connect multiple ontology modules
modular ontology languages such as econnections  offer two broad classes of approaches to connect multiple ontology modules
modular ontology languages such as modular ontology languages such as distributed description logics econnections  offer the use of importing modular ontology languages such as distributed description logics packagebased description logics
modular ontology languages such as packagebased description logics  offer the use of linkings between ontology modules eg
modular ontology languages such as modular ontology languages such as ddl econnections  offer the use of mappings between ontology modules eg
modular ontology languages such as econnections  offer the use of mappings between ontology modules eg
modular ontology languages such as econnections  offer the use of importing modular ontology languages such as distributed description logics packagebased description logics
modular ontology languages such as econnections  offer the use of importing modular ontology languages such as ddl packagebased description logics
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as ddl packagebased description logics
ontology modules distributed description logics and econnections
modular ontology languages such as modular ontology languages such as ddl econnections  offer two broad classes of approaches to connect multiple ontology modules
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as distributed description logics econnections
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as ddl econnections
modular ontology languages such as packagebased description logics  offer the use of linkings between ontology modules eg
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as ddl packagebased description logics
modular ontology languages such as distributed description logics  offer the use of importing modular ontology languages such as distributed description logics econnections
modular ontology languages such as modular ontology languages such as ddl econnections  offer the use of linkings between ontology modules eg
modular ontology languages such as modular ontology languages such as ddl econnections  offer the use of importing modular ontology languages such as ddl packagebased description logics
modular ontology languages such as econnections  offer the use of linkings between ontology modules eg
modular ontology languages such as modular ontology languages such as distributed description logics econnections  offer two broad classes of approaches to connect multiple ontology modules
modular ontology languages such as packagebased description logics  offer the use of mappings between ontology modules eg
modular ontology languages such as econnections  offer the use of importing modular ontology languages such as ddl econnections
modular ontology languages such as modular ontology languages such as distributed description logics econnections  offer the use of importing modular ontology languages such as distributed description logics econnections
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as ddl econnections
modular ontology languages such as modular ontology languages such as ddl econnections  offer the use of importing modular ontology languages such as distributed description logics packagebased description logics
modular ontology languages such as modular ontology languages such as ddl econnections  offer the use of importing modular ontology languages such as ddl econnections
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as distributed description logics econnections
modular ontology languages such as modular ontology languages such as distributed description logics econnections  offer the use of importing modular ontology languages such as ddl econnections
modular ontology languages such as packagebased description logics  offer two broad classes of approaches to connect multiple ontology modules
modular ontology languages such as distributed description logics  offer the use of linkings between ontology modules eg
modular ontology languages such as modular ontology languages such as distributed description logics econnections  offer the use of mappings between ontology modules eg
modular ontology languages such as modular ontology languages such as ddl econnections  offer the use of importing modular ontology languages such as distributed description logics econnections
modular ontology languages such as packagebased description logics  offer the use of importing modular ontology languages such as distributed description logics packagebased description logics
the major difference between the two approaches is on the usage of  foreign terms  at the syntactic level
the major difference between the two approaches is on the usage of  foreign terms  on the local model disjointness at the semantic level
we compare the semantics of linking in econnections
we compare the semantics of importing in such as ddl rrb
we compare the semantics of importing in such as distributed description logics rrb
we compare the semantics of importing in modular ontology languages
we compare the semantics of importing in econnections
we compare the semantics of linking in distributed description logics
we compare the semantics of importing in packagebased description logics within the distributed first order logics framework
the domain disjointness assumption adopted by the linking approach
we investigation shows that the domain disjointness assumption leads to several semantic difficulties
we explore the possibility of avoiding some of these difficulties
these difficulties using the importing approach to linking ontology modulessemantic web browsers are all concerned with the same problem presenting content primarily intended for machine consumption in a humanreadable way
other tools aimed at displaying core rdf data to end users
other tools are all concerned with the same problem presenting content primarily intended for machine consumption in a humanreadable way
information contained in core rdf models
semantic web browsers differ but in the end address the same two highlevel issues no matter the underlying representation paradigm specifying how this information should be presented  content formatting 
semantic web browsers differ but in the end address the same two highlevel issues no matter the underlying representation paradigm specifying what information should be presented  content selection 
other tools aimed at displaying rdf data to end users solutions
other tools differ but in the end address the same two highlevel issues no matter the underlying representation paradigm specifying how this information should be presented  styling 
semantic web browsers differ but in the end address the same two highlevel issues no matter the underlying representation paradigm specifying how this information should be presented  styling 
other tools differ but in the end address the same two highlevel issues no matter the underlying representation paradigm specifying how this information should be presented  content formatting 
other tools differ but in the end address the same two highlevel issues no matter the underlying representation paradigm specifying what information should be presented  content selection 
however each tool currently relies on each tool own ad vocabulary for specifying core rdf presentation knowledge making it difficult to reuse such knowledge across applications
however each tool currently relies on each tool own ad hoc mechanisms
however each tool currently relies on each tool own ad vocabulary for specifying core rdf presentation knowledge making it difficult to share such knowledge across applications
recognizing the general need for presenting core rdf content to users we designed fresnel as a browserindependent vocabulary of core rdf display concepts
wanting to promote the exchange of presentation knowledge we designed fresnel as a browserindependent vocabulary of core rdf display concepts
in this paper we describe fresnels main concepts several rdf browsers
in this paper we describe visualization tools
visualization tools that have adopted the vocabulary so far
in this paper we describe fresnels main present several rdf browsersdata on the semantic web is semistructured
data on the semantic web does not follow one
one fixed schema
faceted browsing is a natural technique for navigating such data partitioning the information space into orthogonal conceptual dimensions
current faceted interfaces have limited query expressiveness
current faceted interfaces are manually constructed
we formally show the improvement over existing interfaces
we develop an expressive faceted interface for semistructured data
secondly we develop metrics for automatic ranking of facet quality
metrics for automatic ranking of facet quality bypassing the need for manual construction of the interface
we develop rdf
experimental evaluation shows improved usability over current interfacesthis paper argues that in order to allow for the representation comparison and assessment of possibly controversial on the web the semantic web effort requires capabilities for other information
this paper argues that in order to allow for the representation comparison and assessment of uncertain information on the web the semantic web effort requires capabilities for the social reasoning about web ontologies
other information acquired from multiple heterogeneous sources
this paper argues that in order to allow for the representation comparison and assessment of possibly controversial on the web the semantic web effort requires capabilities for the social reasoning about web ontologies
this paper argues that in order to allow for the representation comparison and assessment of uncertain information on the web the semantic web effort requires capabilities for other information
as an approach to this we propose formal means for the representation of possibly controversial opinions of groups
as an approach to this we propose formal means for of several other social attitudes regarding information on the web
as an approach to this we propose formal means for the representation of possibly controversial opinions of individuals
doing so we integrate concepts from distributed artificial intelligence with approaches to web semantics aiming for a social semantics of web contentin recent years several measures for the gold standard were proposed
the gold standard based evaluation of ontology learning
several measures for the gold standard can be distinguished by the layers of an ontology  several measures for the gold standard
the gold standard based evaluation of ontology learning
several measures for the gold standard can be distinguished by the layers of lexical term layer  several measures for the gold standard
the gold standard based evaluation of ontology learning evaluate
several measures for the gold standard can be distinguished by the layers of concept hierarchy  several measures for the gold standard
judging several measures for the gold standard we show that there exist some measures sufficient for evaluating the lexical term layer
the gold standard based evaluation of ontology learning with a list of criteria
however existing measures for the evaluation of concept hierarchies fail to meet basic criteria
this paper presents a new taxonomic measure
a new taxonomic measure which overcomes the problems of current approacheswidespread diffusion of portable devices offer novel opportunities for users to share resources anywhere
wireless connectivity of portable devices offer novel opportunities for users to share resources anywhere
widespread diffusion of portable devices offer novel opportunities for users to form adhoc coalitions
wireless connectivity of portable devices offer novel opportunities for users to form adhoc coalitions
widespread diffusion of portable devices offer novel opportunities for users to share resources anytime
wireless connectivity of portable devices offer novel opportunities for users to share resources anytime
resource access control is crucial to leverage these adhoc collaborations
collaborating entities can not be predetermined
in pervasive scenarios
resource availability frequently varies even unpredictably due to userdevice mobility thus complicating resource access control
however
access control policies can not be specified a priori to face any operative run time condition
access control policies require continuous adjustments to adapt to the current situation
access control policies can not be defined based on entitys identitiesroles as in traditional access control solutions
to address these issues this paper advocates contextawareness to control resource access on the basis of context visibility
to address these issues this paper advocates semantic technologies for contextpolicy specification to allow highlevel description and reasoning about policies
to address these issues this paper advocates the adoption of novel access control policy models
to address these issues this paper advocates semantic technologies for contextpolicy specification to allow highlevel description and reasoning about context
to address these issues this paper advocates contextawareness to enable dynamic adaptation of policies depending on context changes
novel access control policy models that follow two main design guidelines
a semantic contextaware policy model that adopts ontologies to express context
a semantic contextaware policy model that supports policy adaptation
a semantic contextaware policy model that adopts ontologies to express contextaware access control policies
a semantic contextaware policy model that adopts rules to express contextaware access control policies
a semantic contextaware policy model that adopts rules to express context
this paper also describes the design of a semantic contextaware policy modelin this paper we describe irsiii
a semantic broker based approach to creating applications from semantic web services by mediating between one service providers
a semantic broker based approach to creating applications from semantic web services by mediating between a service requester
a semantic broker based approach to creating applications from semantic web services by mediating between more service providers
irsiii which takes a semantic broker
business organisations can view semantic web services as the basic mechanism for integrating processes across applications on the web
business organisations can view semantic web services as the basic mechanism for integrating data across applications on the web
this paper extends previous publications on irs by providing an overall description of our framework from the point of view of application development
more specifically we illustrate we approach through a use case on egovernment
more specifically we describe the irsiii methodology for building applications using semantic web serviceswe address the issue of extracting implicit relationships between entities in biomedical text
we address the issue of extracting explicit relationships between entities in biomedical text
we argue that entities seldom occur in text in entities simple form complex forms of entities with each other
we argue that entities seldom occur in text in entities that relationships in text relate the modified complex forms of entities with each other
we present a rulebased method for extraction of such complex entities and relationships between a rulebased method for extraction of the conversion of such relationships into rdf
we present a rulebased method for extraction of such complex entities and relationships between a rulebased method for the conversion of such relationships into rdf
we present a rulebased method for extraction of such complex entities and relationships between a rulebased method for extraction of such complex entities and relationships between them into rdf
furthermore we present results
paths composed of the extracted relationships
results that clearly demonstrate the utility of the generated rdf in discovering knowledge from text corpora by means of locating pathsin our research to use information extraction to help populate the semantic web our have encountered significant obstacles to interoperability between the technologies
our believe significant obstacles to be endemic to quirks of the specific implementations our have worked with
our believe significant obstacles to be endemic to the basic paradigms our have worked with
interoperability that must be addressed to successfully populate semantic web knowledge bases from information extraction systems
in particular we identify five dimensions of interoperability
information extraction systems that are suitable for reasoning
kite in which our are exploring five dimensions of interoperability
our call the task of transforming data into knowledge bases knowledge integration and briefly present a framework called kite
information extraction systems that are suitable for reasoning
interoperability that must be addressed to successfully populate semantic web knowledge bases from information extraction systems
finally our report on the initial results of an experiment in which the knowledge integration process uses the deeper semantics of owl ontologies to improve the precision of relation extraction from textan approach called rs2d v1
in this paper we present an approach to adaptive probabilistic search for semantic web services in unstructured p2p networks
each service agent dynamically learns the averaged queryanswer behavior of each service agent neighbor peers and forwards service requests to those with minimal mixed bayesian risk of doing so in terms of estimated semantic gain
each service agent dynamically learns the averaged queryanswer behavior of each service agent neighbor peers and forwards service requests to those with minimal mixed bayesian risk of doing so in terms of commmunication cost
experimental evaluation shows that the rs2d search mechanism is robust with reasonably high precision compared to other existing relevant approaches
experimental evaluation shows that the rs2d search mechanism is robust against changes in the network compared to other existing relevant approachesthis paper presents the provenance explorer
the data states and events associated with a scientific workflow in order to validate the results
using rdf visualizations this paper enables scientists to view the data states and events
the data states and events associated with a scientific workflow in order to understand the scientific methodology
using graph visualizations this paper enables scientists to view the data states and events
initially the provenance explorer presents a simple coarsegrained view of the scientific process or experiment
however the provenance explorer allows permitted users to expand the system to reveal particular subevents inputs
however the provenance explorer allows permitted users to expand the system to reveal particular subevents outputs
however the provenance explorer allows permitted users to expand the system to reveal more finegrained information about particular subevents
access control is implemented using shibboleth to authenticate xacml to define access control policies
access control is implemented using shibboleth to authenticate users to define access control policies
access control is implemented using shibboleth to identify users to define access control policies
access control is implemented using shibboleth to identify xacml to define access control policies
the system also provides a platform for publishing scientific results
the visualized workflow select particular nodes into an rdf package for publication
the visualized draganddrop select particular nodes into an rdf package for publication
the visualized workflow select particular nodes into an rdf package for elearning
the system enables users to select particular nodes within the
the visualized draganddrop select particular nodes into an rdf package for elearning
the direct relationships between the individual components are inferred by the ruleinference engine
the individual components selected for such packageswith the wider use of ontologies in the semantic web multiple scenarios for ontology maintenance and evolution are emerging
with the wider use of ontologies as part of production systems multiple scenarios for ontology maintenance and evolution are emerging
managers of projects may exercise quality control
examining changes from previous baseline versions is published
successive ontology versions can be posted on the  semantic  web with users
ontologydevelopment in a collaborative environment can be synchronous

users discovering the new versions serendipitously
rejecting managers of projects before a new baseline is published
for example
ontologydevelopment in a collaborative environment can be asynchronous
accepting managers of projects before a new baseline is published
in this paper we present different scenarios for ontology maintenance and evolution that we have encountered in we own projects collaborators
in this paper we present different scenarios for ontology maintenance and evolution that we have encountered in we own in those of we collaborators
we define several features
several features that categorize these scenarios
for each scenario we discuss the highlevel tasks that an editing environment must support
we then present a unified comprehensive set of tools to support different scenarios in a single framework allowing users to switch between different modes easilyinformation integration and retrieval have been important problems for many information systems it is hard to make many information systems
information integration and retrieval have been important problems for many information systems it is hard to combine new information with any other piece of related information we already possess
information integration and retrieval have been important problems for many information systems it is hard to available for application queries
many ontologybased applications are still cautious about retrieving information from natural language  nl  documents preferring structured sources
many ontologybased applications are still cautious about retrieving information from natural language  nl  documents preferring semistructured sources
many ontologybased applications are still cautious about integrating information from natural language  nl  documents preferring structured sources
many ontologybased applications are still cautious about integrating information from natural language  nl  documents preferring semistructured sources
in this paper we investigate how to use ontologies to facilitate querying information on parallel leaf shape descriptions from nl documents
in this paper we investigate how to use ontologies to facilitate integrating information on parallel leaf shape descriptions from nl documents
our approach takes advantage of ontologies to precisely represent the semantics in shape description to integrates parallel descriptions according to parallel descriptions semantic distances
our approach takes advantage of ontologies to answer shaperelated species identification queries
from this highly specialised domain we learn a set of more general methodological rules
more general methodological rules which could be useful in other domainsrecently the use of blogs has been a remarkable means to publish user interests
in order to find suitable information resources from a large amount of blog entries we need an information filtering technique to automatically transcribe user interests to a user profile in detail
blog entries which are published every day
in this paper we first classify user blog entries into service domain ontologies
service domain ontologies that express a users interests semantically as a hierarchy of classes according to interest weight by a topdown approach
extract interest ontologies that express a users interests semantically as a hierarchy of classes according to interest weight by a topdown approach
in this paper we first classify user blog entries into extract interest ontologies
next with a bottomup approach users modify users interest ontologies to update users interests in more detail
furthermore we propose a similarity measurement between ontologies
the interest weight assigned to each class and instance
ontologies considering the interest weight
then we detect innovative blog entries
innovative blog entries that include concepts that the user has not thought about in the past
the past based on the analysis of approximated ontologies of a users interests
we present experimental results
experimental results that demonstrate the performance of we proposed methods using a largescale blog entries
experimental results that demonstrate the performance of we proposed methods using music domain ontologiespartwhole relations typically receive less attention than subsumption relation
partwhole relations are important in many domains
in this paper we describe a method for finding partwhole relations
a method consists of two steps applying phrase patterns for both explicit and implicit partwhole relations to find partwhole relation instances
a method consists of two steps finding phrase patterns for both explicit and implicit partwhole relations
we show results of applying a method to a domain of finding sources of carcinogensthis paper presents an approach for visually modeling owl dl and owl full ontologies based on the wellestablished visual modeling language uml
we discuss a metamodel for owl
owl based on the metaobject facility
we discuss transformations between both
we discuss an associated uml profile as visual syntax
the work we present supports modeldriven development of owl ontologies
the work we present is currently undergoing the standardization process of the object management group
the implementation of we approach showing how the uml profile can be used to improve developing semantic web applications
the implementation of an example showing how the uml profile can be used to improve developing semantic web applications
the implementation of an example showing how the metamodel profile can be used to improve developing semantic web applications
after describing we approach we present the implementation of an example
after describing we approach we present the implementation of we approach
the implementation of we approach showing how the metamodel profile can be used to improve developing semantic web applicationsthe semantic webs need for machine understandable content has led researchers to attempt to automatically acquire such content 
the semantic webs need for machine understandable content has led researchers to attempt to automatically acquire the semantic webs
to date such research has focused on  documentdriven  systems
documentdriven  systems that individually process a small set of documents
a small set of documents annotating each with respect to a given ontology
more fully leverage existing ontological content while scaling to extract comparatively shallow content from millions of documents
this paper introduces an alternative
an alternative that strives to more fully leverage
this paper introduces ontosyphon
ontosyphon operates in an  ontologydriven  manner taking any ontology as input ontosyphon uses the ontology to specify web searches relations
manner taking any ontology as input ontosyphon uses the ontology to specify web searches that identify possible semantic instances
ontosyphon operates in an  ontologydriven  manner taking any ontology as input ontosyphon uses the ontology to specify web searches taxonomic information
redundancy in the semantic webs together with information from the ontology is then used to automatically verify these candidate instances and relations enabling ontosyphon to operate in a fully automated unsupervised manner
a prototype of ontosyphon is fully implemented
experimental results that demonstrate substantial instance learning in a variety of domains based on independently constructed ontologies
we present experimental results
we also demonstrate that new methods improve upon previously known techniques
we also introduce new methods for improving instance verificationwe study the problem of evaluating conjunctive queries stored in distributed hash tables
conjunctive queries composed of triple patterns over rdf data
algorithms that scale to large amounts of rdf data
we goal is to incur little network traffic
we goal is to develop algorithms
we goal is to distribute the query processing load evenly
we present two novel query processing algorithms with these possibly conflicting goals in mind
we evaluate two novel query processing algorithms with these possibly conflicting goals in mind
we setting through a detailed experimental evaluation of the proposed algorithms
we discuss the various tradeoffs
the various tradeoffs that occur in wedata satisfying query conditions with varying degrees of exactness
we explore flexible querying of rdf data with the aim of making it possible to rank the results of a query depending on how  closely  a query satisfy the query conditions
we explore flexible querying of rdf data with the aim of making it possible to return data
we make queries more flexible by logical relaxation of a query conditions based on rdfs ontologies
we make queries more flexible by logical relaxation of a query conditions based on rdfs entailment
we develop a notion of ranking of query answers
we present a query processing algorithm for incrementally computing the relaxed answer of a query
scenarios where there is a lack of understanding of the ontology
the ontology underlying the data
we approach has application in scenarios
we approach where the data objects have heterogeneous sets of irregular structures
we approach where the data objects have heterogeneous sets of propertiessocial networks have recently garnered considerable interest
with the intention of utilizing social networks for the semantic web several studies have examined automatic extraction of social networks
however most methods have addressed extraction of the strength of relations
entities that are embedded in social networks
our goal is extracting the underlying relations between entities
to this end our propose the proposed method
fundamentally the method clusters similar entity pairs according to the method clusters collective contexts in web documents
the descriptive labels for relations are obtained from results of clustering
the proposed method is entirely unsupervised
the proposed method is easily incorporated into existing social network extraction methods
the proposed method also contributes to ontology population by elucidating relations between instances in social networks
our experiments conducted on the entities
our experiments achieved clustering with high precision and recall
our extracted appropriate relation labels to represent the entitiesinstance unification determines whether two instances in an ontology refer to the same object in the real world
more specifically this paper addresses the instance unification problem for person names
the approach combines the use of citation information  with web mining in order to gather additional evidence for the instance unification algorithm
the approach combines the use of titles  with web mining in order to gather additional evidence for the instance unification algorithm
the approach combines the use of abstract  with web mining in order to gather additional evidence for the instance unification algorithm
the approach combines the use of  with web mining in order to gather additional evidence for the instance unification algorithm
the approach combines the use of coauthorship information  with web mining in order to gather additional evidence for the instance unification algorithm
the approach combines the use of initials  with web mining in order to gather additional evidence for the instance unification algorithm
one used in previous work on name disambiguation
the method is evaluated on two datasets one from the bt digital library
the method is evaluated on two datasets one
the information mined from the web
highly ambiguous cases which lowered the performance of previous methods
the results show that the information contributes substantially towards the successful handling of highly ambiguous casesthe worstcase which is a serious problem
reasoning on owl ontologies is known to be intractable in the worstcase because numerous assertions about individuals relations
reasoning on owl ontologies is known to be intractable in the worstcase because numerous assertions about individuals relations
reasoning on owl ontologies is known to be intractable in the worstcase because in practice most owl ontologies have large aboxes
we propose a technique
a technique that uses a summary of the ontology  to reduce reasoning to a small subset of the original abox
a technique that uses a summary of summary abox  to reduce reasoning to a small subset of the original abox
a technique that prove that we techniques are complete
a technique that prove that we techniques are sound
4 ontologies the largest of which has 65 million role assertions
we demonstrate the scalability of this technique for consistency detection in 4 ontologieswe survey nearly 1300 owl ontologies
we survey rdfs schemas
the collection of statistical data allows us to perform analysis
the collection of statistical data allows us to report some trends
though most of the documents are syntactically owl full full very few stay in owl full when most of the documents are syntactically patched by adding type triples
we also report the frequency of the shape of class hierarchies in the ontologies
we also report the frequency of occurrences of owl language constructs
finally we note that of the largest ontologies most do not exceed the description logic expressivity of alc
the largest ontologies surveyed here
