Advances in information extraction have enabled the automatic construction of large knowledge graphs like YAGO
Advances in information extraction have enabled the automatic construction of large knowledge graphs like DBpedia
Advances in information extraction have enabled the automatic construction of large knowledge graphs like Wikidata
Advances in information extraction have enabled the automatic construction of large knowledge graphs like Freebase
These large knowledge graphs are inevitably bound to be incomplete
To fill in the gaps data correlations in the large knowledge graph can be analyzed to infer Horn rules
To fill in the gaps data correlations in the large knowledge graph can be analyzed to predict new facts
However Horn rules do not take into account possible exceptions so that predicting facts via such rules introduces errors
To overcome this problem we present a method for effective revision of learned Horn rules by adding exceptions  into atoms bodies
To overcome this problem we present a method for effective revision of learned Horn rules by adding ie negated atoms  into atoms bodies
This way errors are largely reduced
We apply We method to discover rules with exceptions from realworld large knowledge graphs
We experimental results demonstrate the effectiveness of the developed method
We experimental results demonstrate the effectiveness of the improvements in accuracy for large knowledge graph completion by rulebased fact prediction