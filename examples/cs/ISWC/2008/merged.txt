a constraint graph based matchmaking algorithm
a controlled natural language called Rabbit
a cost  represented as a weight  which depends on a given edge in a path context in the ontology
a cost  represented as a weight  which depends on a given edge in a path position in a path
a cost  represented as a weight  which depends on a given edge in a path type 
a cost  represented as a weight  which depends on a given edge in isa partof 
a directed dependence relation is formed
a disjunctive datalog program that can be used for Abox reasoning
a framework inspired from homogeneous paradigms for integration of rules
a framework inspired from the hybrid for integration of ontologies
a framework inspired from the hybrid for integration of rules
After a satisfiability is converted into an ordered binary decision diagram
a general operator relies on a reformulation of the kernel contraction operator in belief revision
a graphical application that allows users to create users
A large amount of properties  have been published on the Semantic Web by various parties to be shared for describing resources
A large amount of terms  have been published on the Semantic Web by various parties to be shared for describing resources
All these issues make it hard to assess the value of optimization strategies
All these issues make it hard to evaluate the performance of reasoners
All these issues make it hard to reveal the complexity bottlenecks
Along with automated support for service discovery composition support for automated service contracting and enactment is crucial for any large scale service environment
Along with automated support for service discovery negotiation support for automated service contracting and enactment is crucial for any large scale service environment
Along with automated support for service discovery selection support for automated service contracting and enactment is crucial for any large scale service environment
A method for adapting the parameters of the kernel to the knowledge base through stochastic optimization is also proposed
a method that automatically enriches a folksonomy with domain expert knowledge
a modelling paradigm that is especially well suited for developing models of large structurally complex domains such as those
Among other findings of This paper are the proof that current SPARQL W3C semantics can be simplified to a standard compositional oneIn this paper we present the proposed framework
Among other findings of This paper are the proof that negation can be simulated in SPARQL that nonsafe filters are superfluous
a more dynamic and interactive Web where individuals can organise resources
A more systematic characterization is still lacking
an algorithm for datatype reasoning is modular in the sense that an algorithm for datatype reasoning can handle any datatype
an empirical evaluation showed that laconicprecise justifications can be computed in a reasonable time for entailments in a range of ontologies
an evaluation comparing the RoundTrip Ontology Authoring process with a wellknown ontology editor
An evaluation study has been conducted comparing ROO against another popular ontology authoring tool
An evaluation study is discussed focusing on the quality of the resultant ontologiesnovel techniques which allow for efficient querying of large expressive knowledge bases in secondary storage
An evaluation study is discussed focusing on the usability and usefulness of the tool
a new OWL Services construct that can systematically support substitution
a new similarity measure that can take advantage of some special properties of user
a new similarity measure that can take advantage of some special properties of user
a new similarity measure that can take advantage of some special properties of user
a new similarity measure that can take advantage of some special properties of user with a set of articles from Wikipedia
an existing ontology using or shallow  Natural Language Generation
an existing ontology using templatebased  Natural Language Generation
An important implication of the proposed framework is that ontology modules can be developed completely independent of each others signature and language
an ongoing largescale biomedical project that actively uses ontologies at the VA Palo Alto Healthcare System
an optimized algorithm for the nonmonotonic entailment
an ordered binary decision diagram which represents a canonical model for T
A novel family of parametric languageindependent kernel functions is presented
a number of logicbased methods to handle Many problems in this area have emerged in the field of Semantic Web Services
an XMLbased model that is specialized into a number of languages such as EventsML G2
an XMLbased model that is specialized into a number of languages such as EventsML G2
an XMLbased model that is specialized into a number of languages such as NewsML G2
any datatype that supports certain basic operations
any large scale service environment where large numbers of clients interact
any large scale service environment where large numbers of service providers interact
approach when choosing a physical  sort order in We
approach when choosing a predicate subject object  sort order in We
approximate query answering with real ontologies
a probabilistic modeling framework that combines both datadriven topics in a principled manner
a probabilistic modeling framework that combines both humandefined concepts in a principled manner
a probabilistic ontology that has been developed for the reallife domain of breast cancer
a roughly tenfold improved approximation when using the refined ABox and TBox
a satisfiability preserving transformation from SHIQ to the description logic ALCIb the obtained ALCIb Tbox T
a simple triple store built on top of a columnstore DBMS
As part of the NewsML Architecture  an XMLbased model specific controlled vocabularies such as the the International Press Telecommunication Council News Codes are used to categorize news items together with other industrystandard thesauri
As part of the NewsML Architecture  an XMLbased model specific controlled vocabularies such as the the International Press Telecommunication Council News Codes are used to categorize news items together with other industrystandard thesauri
a system integrating the kernelsWe study the problem of query answering on top of distributed hash tables
a tool that facilitates domain experts definition of ontologies in OWL by allowing domain experts to author the ontology in a controlled natural language
a tool that supports many of these requirements such as discussions chats
a translation of extELP to Datalog also enables the seamless integration of DLsafe rules into extELP
a user study comparing extrusion  vs noextrusion 
a user study comparing extrusion  vs noextrusion 
a user study comparing extrusion  vs noextrusion 
a user study comparing extrusion  vs noextrusion 
a user study comparing extrusion vs noextrusion
a user study showed the use of a extrusion interface by subjects led to significant improvement on answering of finegrained questions about this dataset
a Web service that provides RDF as output
a Web service that takes as input a URL to a Google spreadsheet map
a Web service that takes as input a URL to an RDF123 map
a Web service that takes as input a URL to CSV file mapsystems in which users can annotate items
axioms that do not contain any superfluous  parts
better matches are computed first thereby further
better matches are returned first thereby further
breast cancer which poses significant challenges for the stateofart PSHIQ reasoners
Building on previous methodology we undertook an evaluation where previous work required a Language reference manual with several examples in order to use the Controlled Language the use of NLG improves on existing results for basic ontology editing tasksCurrently proposed Semantic Web Services technologies allow the creation of ontologybased semantic annotations of Web services so that software agents are able to discover invoke monitor Web services with a high degree of automation
Building on previous methodology we undertook an evaluation where previous work required a Language reference manual with several examples in order to use the Controlled Language the use of NLG reduces this
Caches however raise new problems of imprecise information
Caches however raise new problems of outdated information
cases where a substantial set of instances was available that was doubly annotated
comparisons required
concept definition driven by data
concept definition driven by prior knowledge
concepts based on this kind of matching distribution as annotations
consistency checking provided by a knowledge representation system based on description logics
constraints applying to several possible ontology distances
constraints applying to such measures
Contextual interviews gave insights on behaviour while event logging did not
Contextual interviews gave insights on behaviour while questionnaires did not
Controlled Language for Ontology Editing tools offer an attractive alternative for naive users
Currently OWL Services services can only be developed independently if one service is unavailable then finding a suitable alternative would require an difficult global searchmatch
Currently OWL Services services can only be developed independently if one service is unavailable then finding a suitable alternative would require an expensive global searchmatch
Currently proposed Semantic Web Services technologies allow the creation of ontologybased semantic annotations of Web services so that software agents are able to discover invoke compose Web services with a high degree of automation
current Semantic Web reasoning systems which are typically based on classical logic
data formatted according to social network data schema or ontology
Different from the importance of concepts reinforce one another in simple yet effective ConceptAndRelationRanking in an iterative manner
Different from the traditional ranking methods reinforce one another in simple yet effective ConceptAndRelationRanking in an iterative manner
Different from the weights of relations reinforce one another in simple yet effective ConceptAndRelationRanking in an iterative manner
discussions integrated with ontologyediting process
DLE  OWL reasoning defining a framework
DLsafe rules based on the Description Logic
domain experts who should lead The process of authoring ontologies
domains the knowledge acquired
download mappings created with other tools
each column representing a property
entailmentbased  OWL reasoning defining a framework
entailments that had more laconicprecise justifications than regular justifications
environment modelling scenarios related to real tasks at the mapping agency of Great Britain
Even many of the ontologies turn out to be inconsistent once some of Even many of the ontologies is made explicit
Even though most of these measures appear very natural most of these measures design often seems to be rather ad hoc
Existing spreadsheettordf tools typically map only to starshaped RDF graphs ie each spreadsheet row is an instance with each column
experiments that quantify how combining humandefined semantic knowledge with datadriven techniques leads to better language models than can be obtained with either aloneA large amount of classes  have been published on the Semantic Web by various parties to be shared for describing resources
exploiting intelligent user interfaces techniques
extELP encompasses an extended notion of the recently proposed DL rules for that logic
extELP is based on the tractable description logic EL
features introduced by the forthcoming OWL 2 such as certain range restrictions
features introduced by the forthcoming OWL 2 such as disjoint roles
features introduced by the forthcoming OWL 2 such as local reflexivity
features introduced by the forthcoming OWL 2 such as the universal role
feedback provided by users such as ontologies experiences in using the ontologies or reviews of the content
Finally since the individuals evolve independently parallel execution is straightforward
Finally This paper presents an
Finally We present an algorithm for datatype reasoning
Finding mappings between compatible ontologies is an important open problem
Firstly The DLE framework disengages the manipulation of the TBox semantics from any incomplete entailmentbased approach using the efficient DL algorithms
Firstly using only concept hierarchy only a few paths can be considered as  semantically corrects  and these paths obey to a given set of rules
Firstly using only object properties only a few paths can be considered as  semantically corrects  and these paths obey to a given set of rules
First the result quality converges with each evolution with arbitrary tradeoff between computation time in addition the level of approximation can be tuned by varying the size of the Bloom filters
First the result quality converges with each evolution with arbitrary tradeoff between query results in addition the level of approximation can be tuned by varying the size of the Bloom filters
First the result quality converges with offering  anytime  behaviour with arbitrary tradeoff between computation time in addition the level of approximation can be tuned by varying the size of the Bloom filters
First the result quality converges with offering  anytime  behaviour with arbitrary tradeoff between query results in addition the level of approximation can be tuned by varying the size of the Bloom filters
First the result quality increases monotonically in addition the level of approximation can be tuned by varying the size of the Bloom filters
flat small axioms which facilitate the generation of semantically minimal repairs
For easing the exchange of news the International Press Telecommunication Council has developed the NewsML Architecture an XMLbased model
Formal definitions for both types of justification are presented
Formal proves of the divergent consistency results when checking either of both are provided
For tasks like synonym detection and discovery of concept hierarchies many researchers introduced these measures
Further each row in the spreadsheet can be mapped with a fairly different RDF scheme
Furthermore inference can be used to improve the visualization as demonstrated with a dataset of biotechnology patents and researchersthe knowledge bottleneck that slows down the full materialization of the Semantic Web
Furthermore previous instancebased mapping techniques were only applicable to cases vocabularies
Furthermore previous instancebased mapping techniques were only applicable to cases with
Furthermore we methods allow to tradeoff computational cost for inferential completeness
further reducing the search engines response time
Given a desired ranking function the search algorithm can retrieve the topk matches progressively
Grounded conjunctive query answering over OWLDL ontologies is intractable in the worst case
hence by classical results SPARQL is equivalent from an expressiveness point of view to Relational Algebra
Here we address this issue a semantic grounding is provided by mapping pairs of similar tags in the folksonomy to pairs of synsets in Wordnet where we use validated measures of semantic distance to characterize the semantic relation between the
Here we address this issue Each measure is computed on data from the social bookmarking system delicious
Here we also generate text in the Language from an existing ontology  NLG 
Here we analyze several measures of tag similarity a semantic grounding is provided by mapping pairs of similar tags in the folksonomy to pairs of synsets in Wordnet where we use validated measures of semantic distance to characterize the semantic relation between the
Here we analyze several measures of tag similarity Each measure is computed on data from the social bookmarking system delicious
However different systems may need different kinds of relations
However efficient methods to deal with inconsistencies are lacking from current Semantic Web reasoning systems
However for the sake of knowledge workflow one needs to find a compromise between the controlled vocabulary of domain experts
However for the sake of knowledge workflow one needs to find a compromise between the more systematic vocabulary of domain experts
However for the sake of knowledge workflow one needs to find a compromise between the uncontrolled nature of folksonomies
However most domain experts find it hard to follow logical notations in OWL
However most domain experts lack knowledge modelling skills
However most of the other currently discussed formalisms for Semantic Web Services such as SAWSDL has yet to define a concrete mechanism of establishing inheritance relationships among services
However most of the other currently discussed formalisms for Semantic Web Services such as SAWSDL has yet to define a selfcontained mechanism of establishing inheritance relationships among services
However most of the other currently discussed formalisms for Semantic Web Services such as SAWSDL has yet to define human organization of services into a taxonomylike structure
However most of the other currently discussed formalisms for Semantic Web Services such as WSMO has yet to define a concrete mechanism of establishing inheritance relationships among services
However most of the other currently discussed formalisms for Semantic Web Services such as WSMO has yet to define a selfcontained mechanism of establishing inheritance relationships among services
However most of the other currently discussed formalisms for Semantic Web Services such as WSMO has yet to define human organization of services into a taxonomylike structure
However OWL Services has yet to define a concrete mechanism of establishing inheritance relationships among services
However OWL Services has yet to define a selfcontained mechanism of establishing inheritance relationships among services
However OWL Services has yet to define human organization of services into a taxonomylike structure
However robust methods to deal with inconsistencies are lacking from current Semantic Web reasoning systems
However such methods have not at present been widely investigated in ontology mapping compared to linguistic techniques
However such methods have not at present been widely investigated in ontology mapping compared to structural techniques
However the service service signature concepts are not sufficient to discover web services accurately
hybrid modelling building models in which part of the model exists
hybrid modelling building models in which part of the model exists
hybrid modelling building models in which part of the model is developed directly in Java
hybrid modelling building models in which part of the model is developed directly in The Web Ontology Language
hybrid modelling that is
hydrology modelling scenarios related to real tasks at the mapping agency of Great Britain
Identifying potentially important concepts and relations in an ontology is an challenging method
Identifying potentially important concepts and relations in an ontology is an intuitive method
If collections are annotated according to two systems eg with keywords the annotated data can be used for instance
If collections are annotated according to two systems eg with tags the annotated data can be used for instance
In addition since the reasoning services in PSHIQ are mostly query oriented there is no single problem  like classification in classical DL 
In addition since the reasoning services in PSHIQ are mostly query oriented there is no single problem  like realization in classical DL 
In addition to providing search across multiple ontologies the added value of ontology repositories lies in the ontologymapping metadata that users may contain
In a previous paper that nested regular expressions are appropriate to navigate RDF data we study some of the fundamental properties of nSPARQL concerning complexity of evaluation
In a previous paper that nested regular expressions are appropriate to navigate RDF data we study some of the fundamental properties of nSPARQL concerning expressiveness of evaluation
inconsistencies arising from connecting multiple data sources
In contrast to previous work in this area Formal definitions for both types of justification make it clear as to what exactly  parts of axioms  are
individuals within ontologies are easily integrated with efficient statistical learning methods for inducing linear classifiers
In earlier papers we have proposed the use of syntactic relevance functions as a method for reasoning with inconsistent ontologies
In essence we are using the implicit knowledge
information provided by ontology authors such as intended use
information provided by ontology authors such as ontologies scope
In order to demonstrate the practicability of computing hence precise justifications an algorithm is provided carried out on several published ontologies are presented
In order to demonstrate the practicability of computing hence precise justifications an algorithm results from an empirical evaluation carried out on several published ontologies are presented
In order to demonstrate the practicability of computing laconic justifications an algorithm is provided carried out on several published ontologies are presented
In order to demonstrate the practicability of computing laconic justifications an algorithm results from an empirical evaluation carried out on several published ontologies are presented
In order to make good use of an ontology especially a complex ontology we need methods to help understand methods first
In order to make good use of an ontology especially a new ontology we need methods to help understand methods first
In order to quantitatively assess our method we propose a new benchmark for taskbased ontology evaluation where the quality of the ontologies is measured based on how helpful the ontologies are for the task of personalized information finding
In particular
In particular it is useful to know quickly if two ontologies are close or remote before deciding to match two ontologies
In particular we show that we can effectively answer grounded conjunctive queries without building a full completion forest for a large Abox  unlike state of the art tableau reasoners 
instance based mapping between the vocabularies
instance based mapping of more traditionally developed vocabulariesThe emerging paradigm of serviceoriented computing requires novel techniques for various servicerelated tasks
Instancebased methods for solving this problem have the advantage of focusing on the most active parts of the ontologies
Instancebased methods for solving this problem reflect concept semantics as the most active parts of the ontologies are actually being used
Instead we rely on the completion forest of a dramatically reduced summary of a large Abox
Integration of heterogeneous services is often hardwired in service implementations
In the past different RDF storage strategies have been proposed ranging from simple triple stores to more advanced techniques like clustering
In the past different RDF storage strategies have been proposed ranging from simple triple stores to vertical partitioning on the predicates
In this extended setting knowledge about trust in information sources can be used to compute how well an inferred statement can be trusted
In this extended setting knowledge about trust in information sources can be used to resolve inconsistencies
In this paper
In this paper we analyze the complex network characteristics of the induced vocabulary dependence graph
In this paper we analyze the complex network characteristics of the term dependence graph
In this paper we approach the mapping problem as a classification problem based on the similarity between instances of concepts
In this paper we build upon we previous work
In this paper we define an execution model operating on semantic descriptions of services
In this paper we discuss annotations of changes
In this paper we discuss annotations of ontology components
In this paper we discuss a tool
In this paper we discuss requirements for supporting collaborative ontology development
In this paper we discuss requirements for supporting present Collaborative Protege
In this paper we extend OWL Services with the ability to define inheritance relationships between services
In this paper we extend OWL Services with the ability to maintain inheritance relationships between services
In this paper we extend that work to the use of semantic distances
In this paper we first define four features for potentially important concepts and relation from the ontological structural point of view
In this paper we focus on communitybased method to collect ontology mappings
In this paper we focus on the ontologymapping metadata to collect ontology mappings
In this paper we present an analytical framework for evaluating various OWLJava combination approaches
In this paper we propose a general operator for revising terminologies in description logicbased ontologies
In this paper we propose a new similarity measure generated metadata
In this paper we propose a probabilistic modeling framework
In this paper we propose to address this concern by devising a method to efficiently learn an ontology over the enriched folksonomy
In this paper we propose to address this concern by introducing a novel algorithm based on frequent itemset mining techniques to efficiently learn an ontology over the enriched folksonomy
In this work a system has been tested in experiments on approximate query
Introducing inheritance relationship into OWL Services is a natural solution
It is common nowadays for users to have multiple profiles in various folksonomies thus distributing users tagging activities
It is desirable to have a new OWL Services construct
It was found that in half of the ontologies sampled there were entailments
keywords assigned in a more traditional way
Laconic justifications only consist of axioms 
linear classifiers that offer an alternative way to perform classification wrt deductive reasoning
Many problems in this area involve reasoning
mapping metadata that relates concepts from different ontologies
mappings collected from the user community
Mediaspecific metadata formats such as DIG35 are used to describe the media
Mediaspecific metadata formats such as EXIF are used to describe the media
Mediaspecific metadata formats such as XMP are used to describe the media
modeling general services represented using languages such as WSBPELSeveral ontology repositories provide access to the growing collection of ontologies on the Semantic Web
more ontologies have been published widely on the web
More ontologies have been published widely on the web
More ontologies have been used widely on the web
More specifically we develop a model for representing mappings
More specifically we develop a model for representing the metadata
More surprisingly it was observed that for some ontologies there were fewer laconic justifications than regular justificationsFinding mappings between compatible ontologies is an difficult open problem
naive users wishing to create ontologies
no significant difference was found for broad questions about the overall structure of social network data
no single problem  like classification in classical DL  that could be an obvious candidate for benchmarking
no single problem  like realization in classical DL  that could be an obvious candidate for benchmarking
On the other hand this paper presents an efficient indexbased method for the Semantic Web service discovery
On the other hand this paper presents an scalable indexbased method for the Semantic Web service discovery
Ontologies are becoming so large in Ontologies coverage that a small group of people can develop Ontologies effectively
Ontologies are becoming so large in Ontologies coverage that no single person can develop Ontologies effectively
Ontologies are becoming so large in Ontologies coverage that ontology development becomes a communitybased enterprise
ontologies that vary in complexity
ontologies that vary in size
ontology modules that can access the knowledge bases of the others through the knowledge bases of the others
Our approach relies on two hypotheses
Participants were asked to create ontologies based on environment modelling scenarios
Participants were asked to create ontologies based on hydrology modelling scenarios
Patent Trade Office
Precise justifications are characterised by the fact that Precise justifications consist of flat small axioms
Precise justifications can be derived from laconic justifications
previous work where we used Concurrent Transaction Logic to model about service contracts
previous work where we used Concurrent Transaction Logic to reason about service contracts
previous work which uses standard NLP tools to manipulate an ontology
previous work which uses standard NLP tools to process the Controlled Language
probabilistic reasoning problems that enable evaluation of the reasoning performance
problems resulting from unavailable sources
Propositions about the consistency of the refined ABox wrt the associated TBox are made
prototype that evaluates basic SPARQL queries over arbitrary RDF graphs
prototype that show initial results over large datasetsThere are many reasons for measuring a distance between ontologies
queries considering the semantics of the RDFS vocabulary by directly traversing the input graph
RDF123 on the other hand allows users to define mappings to arbitrary graphs thus allowing much richer spreadsheet semantics to be expressed
RDF that uses nested regular expressions as building blocks
real ontologies collected from standard repositories
Redgraph is capable of handling large datasets as we demonstrate on social network data from the youS
reformalize the Web Ontology Language OWL2 based on logical bilattices to augment OWL knowledge bases with trust
Regarding complexity of evaluation we prove that the evaluation of a nested regular expression E over an RDF graph G can be computed in time Omore ontologies have been used widely on the web
Regarding expressiveness we show that nSPARQL is expressive enough to answer queries
Results show that far richer interest profiles can be generated for usersWe present the first generic virtual reality visualization program for Semantic Web data
Reusing multiple ontologies on the Web is bound to lead to inconsistencies between the combined vocabularies
ROO guides users through the ontology construction process by following a methodology geared towards domain experts involvement in ontology authoring
scalable discovery mechanisms are critical for enabling serviceoriented architectures on the Semantic Web
Scalable distributed RDFS reasoning
Scalable is an essential functionality for providing the scalability and performance that largescale Semantic Web applications require
Second
Secondly following a given edge in a path has a cost  represented as a weight 
Secondly The DLE framework achieves faster application of efficient memory usage comparing The DLE framework to the conventional entailmentbased approaches due to the domainspecific nature of the entailmentsthe profile based service signature matching
Secondly The DLE framework achieves faster application of efficient memory usage comparing The DLE framework to the conventional entailmentbased approaches due to the low complexity
Secondly The DLE framework achieves faster application of the ABoxrelated entailments comparing The DLE framework to the conventional entailmentbased approaches due to the domainspecific nature of the entailments
Secondly The DLE framework achieves faster application of the ABoxrelated entailments comparing The DLE framework to the conventional entailmentbased approaches due to the low complexity
Secondly through Bloom filter compression we can fit large graphs in main memory reducing the need for disk IO during query evaluation
Second these two algorithms are developed to instantiate a general operator
services allowing flexible integration of services with solving data where necessary
services allowing flexible integration of services with solving process conflicts where necessary
services which we believe is very important for discovery of Web services
services which we believe is very important for the automated annotation
she would light on what makes reasoning in PSHIQ hard in practice
Since in general these two algorithms are computationally too hard we propose a third algorithm as a more efficient alternative
Since justifications respect the syntactic form of axioms in an ontology syntactically nor semantically minimal
Since justifications respect the syntactic form of axioms in they are usually neither syntactically nor semantically minimal
Since This paper is a new formalism for handling uncertainty in DL ontologies no such methodology has been proposed
social network data constructed from institutions from the United States Patent in order to explore networks of innovation in computing
social network data constructed from institutions from Trademark Office in order to explore networks of innovation in computing
social network data constructed from inventors from the United States Patent in order to explore networks of innovation in computing
social network data constructed from inventors from Trademark Office in order to explore networks of innovation in computing
social network data constructed from patents from the United States Patent in order to explore networks of innovation in computing
social network data constructed from patents from Trademark Office in order to explore networks of innovation in computing
Some repositories collect ontologies automatically by crawling the Semantic Web in other repositories users submit ontologies users
standard similarity measures proposed for this task in the literature
Statistical learning techniques provide an alternative automated approach to concept definition
subsequent semantic modelling of two popular social networking sites interests
subsequent semantic modelling of two popular social networking sites interests utilising Wikipedia as a multidomain model
substitution tracing as well as incremental development
substitution tracing as well as reuse of services
Such an iterative process is proved to be convergent both by experiments
Such an iterative process is proved to be convergent both in principle
Such approaches however fail to scale with respect to the number of service advertisements
Such approaches however fail to scale with respect to the size of the ontologies
Such modules are free to only utilize the required knowledge segments of the others
Tagging has emerged as the defacto standard for the organisation of such resources providing a reactive knowledge management mechanism that users find easy to understand
Tagging has emerged as the defacto standard for the organisation of such resources providing a reactive knowledge management mechanism that users find easy to use
Tagging has emerged as the defacto standard for the organisation of such resources providing a versatile knowledge management mechanism that users find easy to understand
Tagging has emerged as the defacto standard for the organisation of such resources providing a versatile knowledge management mechanism that users find easy to use
tasks where an inductive approach may bridge the gaps of the standard methods due the inherent incompleteness of the knowledge bases
Terms are defined based on other terms
The algorithm admits easy extensions with DLsafe rules
The algorithm admits easy extensions with ground conjunctive queries
The algorithm combines hypothesis testing with consistency checking
The algorithm is worstcase optimal wrt data complexityOntology Editing tools are still required to spend time
The algorithm used to control the approximation
The application of the approach to a geospatial setting results in a roughly tenfold improved approximation
the associated TBox when compared to baseline ABox and TBox
The basis for this kind of matching is an appropriate similarity measure between concepts
The benefits of the proposed method are demonstrated through experimental evaluation on both real data
The benefits of the proposed method are demonstrated through experimental evaluation on both synthetic dataThis paper describes the first steps towards developing a methodology for testing
The continued increase in Web usage in particular participation in folksonomies reveals a trend towards a more dynamic and interactive Web
the Controlled Language
The corresponding semantic web service matchmaker performs not only the profiles semantic matching with the help of a constraint graph
The corresponding semantic web service matchmaker performs the matching of The corresponding semantic web service matchmaker semantic constraints with the help of a constraint graph
the current OWL 2 Working Draft
the Description Logic Programming fragment of OWL 2parametric languageindependent kernel functions defined for individuals within ontologies
The distributed nature brings with The Semantic Web inconsistencies between autonomous knowledge bases
The distributed nature brings with The Semantic Web sources between autonomous knowledge bases
The DLE framework enhances the entailmentbased OWL reasoning paradigm in two directions
The emergence of web raises the question of the semantic interoperability between vocabularies
The experiment results are encouraging when applying the semantic constraint to discover semantic web services on the service retrieval test collection OWLSTC v2A justification for an entailment in an OWL ontology is a minimal subset of the ontology
the first generic virtual reality visualization program for Semantic Web data is capable of handling large datasets as we demonstrate on social network data from the youS
The first is a graphical application
the framework towards FOURT allowing for multiple levels of trust on data sources
The graphs analyzed in the experiments
The graphs are constructed from a large data set that contains 1278233 terms in 3039 vocabularies
The growing popularity of social tagging systems promises to alleviate the knowledge bottleneck since social tagging systems allow ordinary users to create knowledge in a simple cheap representation usually known as folksonomy
The growing popularity of social tagging systems promises to alleviate the knowledge bottleneck since social tagging systems allow ordinary users to create knowledge in a simple scalable representation usually known as folksonomy
The growing popularity of social tagging systems promises to alleviate the knowledge bottleneck since social tagging systems allow ordinary users to share knowledge in a simple cheap representation usually known as folksonomy
The growing popularity of social tagging systems promises to alleviate the knowledge bottleneck since social tagging systems allow ordinary users to share knowledge in a simple scalable representation usually known as folksonomy
The idea is to combine the scalability of the rule paradigm over large ABoxes
The idea is to combine the TBox inferencing capabilities of the DL algorithms over large ABoxes
the implicit knowledge hidden in the Web for explicit reasoning purposes
the interfacebased modular ontology formalism which theoretically present the proposed framework
the interfacebased modular ontology formalism which theoretically supports the proposed framework
the lexical base WordNet using partof relation with two different benchmarks
The main result is that nonrecursive safe Datalog with negation have equivalent expressive power
The main result is that SPARQL have equivalent expressive power
The majority of currently existing approaches focuses on centralized architectures typically by precomputing concepts
The majority of currently existing approaches focuses on centralized architectures typically by storing the results of the semantic matcher for all possible query concepts
The majority of currently existing approaches focuses on deals with efficiency typically by precomputing concepts
The majority of currently existing approaches focuses on deals with efficiency typically by storing the results of the semantic matcher for all possible query concepts
the mapped tags
the metadata associated with the mapping
The methodology we propose is based on applications of statistical topic models  also known as latent Dirichlet allocation models 
the mixed DL defining a framework
the model using we WSMO a case scenario from the B2B domain of the SWS Challenge
the model using we WSMO technology from the B2B domain of the SWS Challengea framework inspired from homogeneous paradigms for integration of ontologies
Then a simple yet effective ConceptAndRelationRanking algorithm is proposed to simultaneously rank the importance of concepts
Then a simple yet effective ConceptAndRelationRanking algorithm is proposed to simultaneously rank the importance of relations
the news production chain also excludes linking to existing web knowledge resources
the news production chain also impedes the construction of uniform enduser interfaces for browsing news contentWe describe RDF123 for translating spreadsheet data to RDF
the news production chain also impedes the construction of uniform enduser interfaces for searching news content
Then We evaluate experimentally some of several possible ontology distances in order to assess some of speed
Then We evaluate experimentally some of several possible ontology distances in order to assess some of them accuracy
Then We evaluate experimentally some of such measures in order to assess some of speed
Then We evaluate experimentally some of such measures in order to assess some of them accuracyCollaborative tagging systems have nowadays become important data sources for populating semantic web applications
the ontologies involved
the ontologies that are in use today
the ontologies that are in use today implicit knowledge
the ontologymapping metadata may include feedback
the ontologymapping metadata may include information
the ontologymapping metadata may include mapping metadata
the ontology that is sufficient for an entailment in an OWL ontology to hold
The OWL Services ontology is an upper ontology in OWL language providing essential vocabularies to semantically describe Web services
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology edit the text as required
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology edit the text as then turn the text back into the ontology in the previous work environment
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology modify the text as required
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology modify the text as then turn the text back into the ontology in the previous work environment
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the edit the text as required
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the edit the text as then turn the text back into the ontology in the previous work environment
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the modify the text as required
the previous work authoring process combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the modify the text as then turn the text back into the ontology in the previous work environment
The process of authoring ontologies requires the active involvement of domain experts
The proposed inheritance framework has also been implementedRevision of a description logicbased ontology deals with the problem of incorporating newly received information consistently
the prototype will be briefly evaluated as well
There are no sufficiently large probabilistic ontologies to be used as test suites
The results are significantly better than those
The results characterize connectivity
The results characterize degree distributions
The results characterize reachabilityWe present a technique for answering queries over RDF data through an evolutionary search algorithm using Bloom filters for rapid approximate evaluation of generated solutions
The results characterize the current status
The results illustrate the efficiency and generality of this methodThe Web Ontology Language provides a modelling paradigm
The results using a new similarity measure
The second is a Web service
The semantic constraints are extracted automatically from the parsing results of the service description text by a set of heuristic rules
The semantic constraints described in a constraint graph
The Semantic Web failing data
the Semantic Web service discovery that allows for fast selection of services at query time
the Semantic Web service discovery that is suitable for both centralized environments
the Semantic Web service discovery that is suitable for both P2P environments
The study of term dependence is a foundation work
The study of term dependence is important for many other tasks such as distributed reasoning on the Web scale
The study of term dependence is important for many other tasks such as integration
The study of term dependence is important for many other tasks such as ontology maintenance
The test results show that a mixed syntacticsemantic approach can significantly improve reasoning performance over the purely syntactic approach
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology edit the text as required
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology edit the text as then turn the text back into the ontology in the previous work environment
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology modify the text as required
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with an existing imported ontology modify the text as then turn the text back into the ontology in the previous work environment
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the edit the text as required
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the edit the text as then turn the text back into the ontology in the previous work environment
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the modify the text as required
The text generator combine to form a RoundTrip Ontology Authoring environment one can start with one originally produced using previous work  re  produce the modify the text as then turn the text back into the ontology in the previous work environment
the underlying assumptions on the notion of similarity are not made explicit
The use of different metadata formats in a single production process leads to interoperability problems within the news production chain the news production chain
The Web Ontology Language however is not a programming language so using these models in applications necessitates both a technical means of integrating The Web Ontology Language models with considerable methodological sophistication in knowing how to integrate The Web Ontology Language models
The Web Ontology Language however is not a programming language so using these models in applications necessitates both a technical means of integrating The Web Ontology Language models with programs in knowing how to integrate The Web Ontology Language models
The Web Ontology Languages declarative nature combined with powerful reasoning tools has effectively supported the development of clinical ontologies
The Web Ontology Languages declarative nature combined with powerful reasoning tools has effectively supported the development of disease
The Web Ontology Languages declarative nature combined with powerful reasoning tools has effectively supported the development of very large and complex anatomy
This allows us to analyse how the system was used for Personal Information Management
This an is turned into a disjunctive datalog program
This an ordered binary decision diagram
This enables the exploitation of statistical learning in a variety of tasks
This exposes important features of the investigated similarity measuresEfficient discovery mechanisms are critical for enabling serviceoriented architectures on the Semantic Web
This fact has motivated several authors to propose RDF query languages with navigational capabilities
This has the advantage that no doubly annotated instances are required so that the method can be applied to any two corpora annotated with two own vocabularies
This indicates which ones are better suited in the context of a given semantic application
this learning curve for users
This paper addresses explains a systematic approach to generating a series of probabilistic reasoning problems
This paper addresses these important problems by making the following contributions First describes a probabilistic ontology
This paper addresses these important problems by making the following contributions This paper addresses describes a probabilistic ontology
This paper describes the first steps towards evaluating the performance of reasoners for the probabilistic description logic PSHIQ
This paper extends previous work
This paper positive impact on performance is demonstrated using our evaluation methodologyan XMLbased model that is specialized into a number of languages such as NewsML G2
This paper presents a new method to enhance the semantic description of semantic web service by using the semantic constraints of service service signature concepts in specific context
This paper presents a new semantic relatedness measure on ontologies
This paper presents a tool
This paper presents ROO
This paper presents two new subclasses of justifications laconic justifications
This paper presents two new subclasses of justifications precise justifications
this task in the literature correlates better with human judgments
those found in Health Care
those found in the Life Sciences
those obtained using standard similarity measures
Through the definition of an additional  inheritance profile  inheritance relationships can be reasoned about
Through the definition of an additional  inheritance profile  inheritance relationships can be stated about
Thus extELP extends EL with a number of features
time learning the correct syntactic structures and vocabulary in order to use the Controlled Language properly
to improve performance caching can be used
To reduce problems caching can be used
To that extent a distance between ontologies must be quickly computable
Towards this end we define The DLE framework
trust based reasoning
Two interfaces are available
Two participants continued using the open source software prototype
Two participants were interviewed after two years in 2008 to show Two participants longterm usage patterns
Two types of IRs are allowed to grant service developers the choice to respect the  contract  between not
Two types of IRs are allowed to grant service developers the choice to respect the  contract  between services
Typical relations are equivalence
Typical relations are subsumption
upload mappings created with other toolsCorrespondences in ontology alignments relate two ontology entities with a relation
Users have found the new tool effective as an environment for carrying out discussions
Users have found the new tool effective as an environment for recording references for design rationale
Users have found the new tool effective as an environment for recording references for the information sourcesdomain experts who should lead The process of providing the relevant conceptual knowledge
users mapping in an intuitive manner
users when multiple tagclouds are combined
Using the open source software prototype Gnowsis we evaluated the approach in a two month case study in 2006 with eight participants
Using this dataset results of a user study are presented
validation of tag similarity in terms of formal representations of knowledge is still lacking
Various semantic web service discovery techniques have been proposed many of which perform the profile
vocabularies originating from collaborative annotation processes
vocabularies originating from keywords
vocabularies originating from often called folksonomies
Ways to automate the detection of falsely calculated relations are discussedWe propose a novel method for reasoning in the description logic SHIQ
Ways to further improve the approximation are discussed
We also argue that certain datatypes from the list of normative datatypes in the current OWL 2 are inappropriate
We also argue that certain datatypes from the list of normative datatypes in the current OWL 2 should be replaced with different ones
We also describe the realworld design and implementation of the proposed framework for creating modular ontologies by extending OWLDLthe Semantic Web Rule Language that admits reasoning in polynomial time
We also describe the realworld design and implementation of the proposed framework for modifying the Swoop interfaces and reasoners
we also show how the search engines can be performed efficiently in a suitable structured P2P overlay network
we also show that nesting is necessary to obtain this last result
We also study the timespace tradeoff exhibited by the algorithms analytically
We also study the timespace tradeoff experimentally by evaluating We algorithms on PlanetLabontologies which considers especially the object properties between the concepts
we also validate a model by extending BioPortala repository of biomedical ontologies that we have developed to enable users to create single concepttoconcept mappings in a model graphical user interface to download mappings to comment on the mappings and to discuss other tools and to visualize the corresponding metadata
we also validate a model by extending BioPortala repository of biomedical ontologies that we have developed to enable users to create single concepttoconcept mappings in a model graphical user interface to download mappings to comment on the mappings and to discuss other tools and to visualize the mappings
we also validate a model by extending BioPortala repository of biomedical ontologies that we have developed to enable users to create single concepttoconcept mappings in a model graphical user interface to upload mappings to comment on the mappings and to discuss other tools and to visualize the corresponding metadata
we also validate a model by extending BioPortala repository of biomedical ontologies that we have developed to enable users to create single concepttoconcept mappings in a model graphical user interface to upload mappings to comment on the mappings and to discuss other tools and to visualize the mappings
we analyse the advantages and disadvantages of hybrid modelling both by means of a case study of a large medical records systemThe Semantic Desktop is a means to support users in Personal Information Management
we analyse the advantages and disadvantages of hybrid modelling both in comparison to other approaches
We analyze the datatype system of OWL
We analyze the datatype system of OWL 2
We applied Redgraph to social network data
We applied the first generic virtual reality visualization program for Semantic Web data to social network data
We approach to visualizing Semantic Web data takes advantage of userinteraction in an immersive environment to bypass a number of difficult issues in 3dimensional graph visualization layout by relying on users users themselves to interactively extrude the nodes and links of a 2dimensional graph into the third dimension
We argue that a new similarity measure also has benefits for instance
web based systems
We conclude that future research is necessary to further bring forward RDF data managementcombining multiple ontologies on the Web is bound to lead to inconsistencies between the combined vocabularies
We conduct experiments on real data
we demonstrate the effectiveness of this approach in Aboxes with up to 45 million assertionsWe discuss certain nontrivial consequences of the datatype system of OWL 2 definition such as the extensibility of the set of supported datatypes and complexity of reasoning
We demonstrate the utility of this general framework in two ways
We describe a highly flexible opensource tool for translating spreadsheet data to RDF
We describe the interfacebased modular ontology formalism distinctive features compared to the exiting modular ontology formalisms
We develop a Semantic Web vocabulary of virtual reality terms compatible with GraphXML to map graph visualization into the Semantic Web the Semantic Web
we discovered that in the personal environment isrelated relations are sufficient for refind information
we discovered that in the personal environment isrelated relations are sufficient for users to fileThis paper studies the expressive power of SPARQL
we discovered that in the personal environment simple hasPart are sufficient for refind information
we discovered that in the personal environment simple hasPart are sufficient for users to file
we discovered that the personal semantic wiki was used creatively to note information
We discuss certain nontrivial consequences of the datatype system of OWL such as the extensibility of the set of supported datatypes and complexity of reasoning
We discuss how users can be offered additional information about the reliability of inferred information based on the availability of the corresponding information sources
We employ a novel encoding of the service descriptions allowing the match between a request and an advertisement to be evaluated in constant time and we index these representations to prune the search space reducing the number of comparisons
We evaluate how much can be learned from such sites
We evaluate in which domains the knowledge is focussed
We evaluate the resulting classifiers on one with heterogeneous instances
We evaluate the resulting classifiers on one with homogeneous
We evaluate the resulting classifiers on two realworld use cases
We evolutionary approach has several advantages compared to traditional databasestyle query answering
we experimental results show that simple yet effective ConceptAndRelationRanking has a similar convergent speed as a more reasonable ranking resultEfficient RDF data management is one of the cornerstones in realizing the Semantic Web vision
we experimental results show that simple yet effective ConceptAndRelationRanking has a similar convergent speed as the PageRanklike algorithms
we experiment shows that we only have to give up a little quality to obtain a high performance gaina more dynamic and interactive Web where individuals can share resources
we extend the proof theory of Concurrent Transaction Logic to enable reasoning about such contracts
we first define we revision operator for terminologies
We first illustrate how The methodology we propose can be used to automatically tag Web pages with concepts from a known set of concepts without any need for labeled documents
we first show that our revision operator satisfies some desirable logical properties
We founded semantics on the basis of FOURTHumandefined concepts are fundamental buildingblocks in constructing knowledge bases such as ontologies
We goal in this paper is to compare two wellknown approaches to RDFS reasoning forward chaining on top of distributed hash tables
We goal in this paper is to compare two wellknown approaches to RDFS reasoning namely backward on top of distributed hash tables
We goal in this paper is to evaluate two wellknown approaches to RDFS reasoning forward chaining on top of distributed hash tables
We goal in this paper is to evaluate two wellknown approaches to RDFS reasoning namely backward on top of distributed hash tables
we have argued in a previous paper that nested regular expressions are appropriate to navigate RDF data
we have developed a software framework for what we call hybrid modelling
we have evaluated a new similarity measure
we have evaluated Collaborative Protege in the context of ontology development in an ongoing largescale biomedical project
we have implemented this approach as part of the PION reasoning system
we have proposed the nSPARQL query language for RDF
we implemented these two algorithms
we implement the model
We introduce extELP as a decidable fragment of the Semantic Web Rule Language
We introduce the notion of DLE  OWL reasoning
We introduce the notion of entailmentbased  OWL reasoning
We introduce the notion of the mixed DL
We observe that in terms of performance a simple triple store is competitive to the vertically partitioned approach scenario with realworld queries none of the approaches scales to documents containing tens of millions of RDF triples
We observe that in terms of scalability a simple triple store is competitive to the vertically partitioned approach scenario with realworld queries none of the approaches scales to documents containing tens of millions of RDF triples
We observe that none of the approaches can compete with a purely relational model
we present a method for the automatic consolidation of user profiles across two popular social networking sites
We present an experimental comparison of existing storage strategies on top of the SP2Bench SPARQL performance benchmark suite
We present a reasoning algorithm based on a translation of extELP to Datalog
We present a technique for answering queries over RDF data through an evolutionary search algorithm using fingerprinting for rapid approximate evaluation of generated solutions
We present constraints
We present explicit generic rules of the transformations in both directions
we present novel techniques
We present Redgraph 
We present We prototype
We propose an evaluation of We measure on the lexical base WordNet
We propose to distinguish between cached information when reasoning on The Semantic Web by extending the well known FOUR bilattice of knowledge orders to FOURC taking into account cached information
We propose to distinguish between cached information when reasoning on The Semantic Web by extending the well known FOUR bilattice of truth orders to FOURC taking into account cached information
We propose to distinguish between certain information when reasoning on The Semantic Web by extending the well known FOUR bilattice of knowledge orders to FOURC taking into account cached information
We propose to distinguish between certain information when reasoning on The Semantic Web by extending the well known FOUR bilattice of truth orders to FOURC taking into account cached information
We propose to use the concepts of algebra of relations in order to express the relations between ontology entities in a general way
we provide evaluation results on these two algorithms effectiveness in the context of two application scenarios Incremental mapping revision
we provide evaluation results on these two algorithms effectiveness in the context of two application scenarios Incremental ontology learning
we provide evaluation results on these two algorithms efficiency in the context of two application scenarios Incremental mapping revision
we provide evaluation results on these two algorithms efficiency in the context of two application scenarios Incremental ontology learning
we provide evaluation results on these two algorithms meaningfulness in the context of two application scenarios Incremental mapping revision
we provide evaluation results on these two algorithms meaningfulness in the context of two application scenarios Incremental ontology learningNavigational features have been largely recognized as fundamental for graph database query languages
We put the results into context by comparing the results to a purely relational model of the benchmark scenario
We redefine the stable model
we report on experiments with several realistic ontologies
we show how Google distances can be used to develop semantic relevance functions to reason with inconsistent ontologies
We show how to implement both the algorithms
We show how to implement certain basic operations for number datatypes
We show how to implement certain basic operations for string datatypesIntegration of heterogeneous services is often hardwired in workflow implementations
We show how to prove Bamboo correctness
We show that in this context our measure outperforms the classical semantic measuresAn approach to improve an RCCderived geospatial approximation is presented which makes use of concept inclusion axioms in OWL
We show the benefits in amalgamating alignments with relations of different granularity
We show the benefits in composing alignments
We show the benefits in doing so in expressing disjunctive relations
We show the benefits in merging alignments in different ways
We show the effectiveness of We approachThe Semantic Web is a distributed environment for knowledge representation and reasoning
we significantly extend the modeling power of the previous work by allowing iterative processes in the specification of service contracts
we study the expressiveness of the combination of nested regular expressions
we study the expressiveness of the combination of SPARQL operators
We study the problem of distributed RDFS reasoning on top of distributed hash tables
We then extend the framework towards FOURT
We then perform a series of experiments
we use a model to bring together more than 30000 mappings from 7 sources
When users touch nodes in the virtual reality environment users retrieve data
While news is still mainly in the form of textbased stories these are often illustrated with graphics
While news is still mainly in the form of textbased stories these are often illustrated with images
While news is still mainly in the form of textbased stories these are often illustrated with videos
While reasoning with DLsafe rules as such is already highly intractable we show that DLsafe rules can be admitted in extELP without losing tractability
Wikipedia which are both annotated by users of the bookmarking service delicious
Wikipedia which are both classified according to the topic structure of Wikipedia
Within the context of the proposed framework an ontology can be defined and developed as a set of ontology modules welldefined interfaces
With this extension we logicbased approach is capable of modeling general services
