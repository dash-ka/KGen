Benchmarking is indispensable when aiming to assess technologies with respect to Benchmarking suitability for given tasks
While benchmark generation frameworks have been developed to evaluate triple stores Benchmarking mostly provide a onefitsall solution to the benchmarking problem
While several benchmarks have been developed to evaluate triple stores Benchmarking mostly provide a onefitsall solution to the benchmarking problem
This approach to benchmarking is however unsuitable to evaluate the performance of a triple store for a given application with particular requirements
We address this drawback by presenting query logs
We address this drawback by presenting an automatic approach for the generation of benchmarks out of the query history of applications
We address this drawback by presenting FEASIBLE
the generation of benchmarks out of the query history of applications is achieved by selecting prototypical queries of a userdefined size from the input set of queries
We evaluate We approach on two query logs
We evaluate We show that the benchmarks our approach generates are accurate approximations of the input query logs
we compare four different triple stores with benchmarks
benchmarks generated using our approach
Moreover
the types of queries posed
we show that four different triple stores behave differently based on the data four different triple stores contain
Our results suggest that FEASIBLE generates better sample queries than the state of the art
In addition the better query selection used lead to triple store rankings
triple store rankings which partly differ from the rankings
the rankings generated by previous works
In addition the larger set of query types used lead to triple store rankings