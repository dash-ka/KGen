ABoxes consisting of proper KBs
a certain normal form which includes positive queries possibly extended with a controlled form of negation
Ackermann has been implemented in Java using the OWL API
Ackermann is an adaptation and improvement of a secondorder quantifier elimination method developed for modal logics
Ackermann is an adaptation and improvement of a secondorder quantifier elimination method used for computing correspondence properties for modal axioms
Ackermann is extended with a new case splitting inference rule
Ackermann is extended with several simplification rules
a coherent research framework called HypTrails
a comprehensive visualization model facilitating the automatic binding between data
a comprehensive visualization model facilitating the automatic binding between visualization parameters
a domainindependent instance matching benchmark generator
a framework that enables identifying analysing these dynamics
a framework that enables identifying understanding these dynamics
a framework where the model selection design process is represented as a factor graph
Afterwards we evaluate the disambiguation algorithmInstance retrieval computes all instances of a given concept in a consistent description logic  ontology
Afterwards we show that the disambiguation algorithm also achieves superior disambiguation accuracy with respect to alternative stateoftheart graphbased algorithms
Algebras of relations make it possible to aggregate alignments conjunctively
Algebras of relations make it possible to aggregate alignments disjunctively
all qualitative taxonomical relations that occur between concepts
all qualitative taxonomical relations that occur between individuals
a lowcost serverside interface when high numbers of clients need to evaluate sparql queries
Although Instance retrieval is a popular task for ontology reasoning there is no scalable method for instance retrieval for negated concepts by now
Although previous empirical investigations have produced a series of interesting insights previous empirical investigations were aimed at gauging the problem space only
Although previous empirical investigations have produced a series of interesting insights previous empirical investigations were exploratory in nature
a manner that enables easy navigation among versions automated processing and analysis of changes crosssnapshot queries  spanning across different versions 
a manner that enables easy navigation among versions queries
a manner that enables efficient navigation among versions automated processing and analysis of changes crosssnapshot queries  spanning across different versions 
a manner that enables efficient navigation among versions queries
a metareasoner that automatically combines
analysis tools that select the best mapping
An analysis over 25 GB of experimental data indicates that the proposed biases can improve efficiency by over 65The Web of Data has been introduced as a novel scheme for imposing structured data on The Web of Data
an anytime algorithm that induces sets of GCIs
an approach exploiting a result of Ackermann
An important feature inherited from the modal approach
An important feature is that the inference rules are guided by an ordering compatible with the elimination order of the concept symbols
an inverted index built on top of a Knowledge Graph 
an inverted index built on top of eg DBpedia 
an ontology that acts as a conceptual integrated view of the data
an ontology that acts as a conceptual integrated view of the data
an ontology that acts as a conceptual integrated view of the data to the data sources
an ontology that acts over the relational database schema
an optimized retrieval model
a novel approach which improves on we earlier work on addresses the aforementioned limitations
a novel approach which improves on we earlier work on automatic generation of semantic topic networks
a novel concept called link pattern
archiving scientific results is for the most part still considered the task of classical publishing companies despite the fact that classical forms of publishing centered around printed narrative articles no longer seem wellsuited in the digital age
A rewritingbased method for retrieving instances of a negated concept is proposed for IFOrewritable ontologies
As a direct application we then use The graph to hypothesize about potential unexploited biases
As each of the tractable OWL profiles is motivated by different application cases extending the tool to the other profiles is of particular interest also because the other profiles preserve the polynomial data complexity of the combined formalism
As opposed to the majority of stateoftheart systems entities we use we approach to disambiguate both common nouns
As opposed to the majority of stateoftheart systems entities we use we approach to disambiguate both entities
As the Web of Data is growing steadily the demand for userfriendly means for exploring visualizing Linked Data is also increasing
a structured summary called knowledge card
a target dataset implementing test cases of varying levels of difficulty
a tool called RECAP
attention for the statistical modeling of knowledge graphs showing promising results in tasks
Automated acquisition
Automated acquisition of ontologies has attracted research attention because Automated acquisition of ontologies can give domain experts new insights into domain experts data
Automated acquisition of ontologies has attracted research attention because Automated acquisition of ontologies can help ontology engineers build ontologies
Automated acquisition of ontologies has attracted research attention because Automated acquisition of ontologies can help ontology engineers build ontologies
a weighted gold standard which allows a more finegrained analysis of the performance of instance matching tools
Based on a novel combination of existing concepts we present a server network to decentrally store and archive data in the form of an RDFbased format to represent scientific data
Based on a novel combination of existing concepts we present a server network to decentrally store and archive data in the form of nanopublications to represent scientific data
Based on a novel combination of technologies we present a server network to decentrally store and archive data in the form of an RDFbased format to represent scientific data
Based on a novel combination of technologies we present a server network to decentrally store and archive data in the form of nanopublications to represent scientific data
because of unexpected data transfers the traditional optimizethenexecute paradigm is not always applicable in this context
benchmark generator which focuses on benchmarking instance matching systems for Linked Data
benchmarks generated using our approach
Besides storing facts about the world schemabased knowledge graphs are backed by rich semantic descriptions of entities
Besides storing facts about the world schemabased knowledge graphs are backed by rich semantic descriptions of relationtypes
Besides there is a necessity for navigation paradigm to take into account
Besides there is entitysetoriented transition
Besides there is singleentityoriented transition
Between the sparql protocol lies a largely unexplored axis of possible interfaces to each with the sparql protocol own combination of tradeoffs
Between uri dereferencing lies a largely unexplored axis of possible interfaces to each with the sparql protocol own combination of tradeoffs
Between uri dereferencing lies a largely unexplored axis of possible interfaces to Linked Data own combination of tradeoffs
both problems are therefore not applicable to concepts
But this reduction is no longer possible when We associate proper KBs with extitDLLite  core TBoxes
cards representing the same entity
Choosing the right framework for this purpose remains tedious as current instance fail to provide end users and developers with the necessary insights
classes which occur in alignments
Clientside query processing techniques that rely on the materialization of fragments of the original RDF dataset
Compared to related forgetting interpolation methods for description logics Ackermann can handle inverse roles nominals and ABoxes
Compared to related uniform interpolation methods for description logics Ackermann can handle inverse roles nominals and ABoxes
Compared to the modal approach Ackermann improves the success rates
Compared to the modal approach Ackermann is more efficient in time
complex semanticsaware test cases that take into account expressive OWL constructs
compositional inference using this algebra
concepts that do not have a rich textual description
creating Ontologies requires significant expertise and effort
Current automated methods for generating ontologies of research areas also present a number of limitations such as i  Current automated methods for generating ontologies of research areas do not consider the rich amount of indirect semantic relationships
Current automated methods for generating ontologies of research areas also present a number of limitations such as i  Current automated methods for generating ontologies of research areas do not consider the rich amount of indirect statistical relationships
current instance matching benchmarks
data integration proposed by Falconer
datasets which make entity retrieval a challenging task
data that can be used to feed a contentbased recommender system
declarative mappings that connect an ontology
disambiguation are fundamental problems for linking text documents to the Web of Data
DLLite has the notable property that conjunctive query answering over standard description logic ABoxes is reducible to formula evaluation over the ABox only
DLLite has the notable property that conjunctive query answering over TBoxes is reducible to formula evaluation over the ABox only
Each engine offers an online knowledge graph service to display highly relevant information about the query entity in form of a structured summary
Each such selection then provides highconfidence guidance for the next iteration of the integration tool
Effectively querying this distributed data source is an important open problem in the Semantic Web area
Effectively this enables remote applications to  subscribe  to relevant datasets and consistently reflect the necessary changes locally without the need to frequently replace the entire dataset  or a relevant subset 
eg focus on Automated acquisition descriptions for given classes require intense supervision
ELbased ontologies which are defeasible in the sense that such a mapping only applies to individuals if this does not because an inconsistency
entities defined in some Knowledge graph combinations
entities defined in some Knowledge graph relatedness
entities retrieved by a given user query
entities retrieved by the BM25F retrieval approach
entities that allow machines to understand the notion of machines semantic relationships
entities that allow machines to understand the notion of things semantic relationships
entity disambiguation that makes use of graphbased relatedness
errors affecting millions of statements
Evaluation of the current small network shows that this system is efficientRecently Web search engines have empowered Web search engines search with knowledge graphs to satisfy increasing demands of complex information needs about entities
Evaluation of the current small network shows that this system is reliable
existing approaches to ontology Automated acquisition are considerably limited
existing methods implemented in stateoftheart DL systemsKnowledge graphs are browsing
Experimental results show that the order affects efficiency
Experimental results show that the order affects the success rateAlgebras of relations were shown useful in managing ontology alignments
Experimental results show that The proposed approach is effectiveWe introduce optimization techniques for reasoning in DLN a recently introduced family of nonmonotonic description logics whose characterizing features appear wellsuited to model the examples naturally arising in biomedical domains
Experimental results suggest that Fedra in the stateoftheart federated query engines ANAPSID efficiently solves the source selection problem with fragment replication reducing the number of selected SPARQL endpoints
Experimental results suggest that Fedra in the stateoftheart federated query engines ANAPSID efficiently solves the source selection problem with fragment replication reducing the size of query intermediate results
Experimental results suggest that Fedra in the stateoftheart federated query engines FedX efficiently solves the source selection problem with fragment replication reducing the number of selected SPARQL endpoints
Experimental results suggest that Fedra in the stateoftheart federated query engines FedX efficiently solves the source selection problem with fragment replication reducing the size of query intermediate resultsBetween the sparql protocol lies a largely unexplored axis of possible interfaces to Linked Data own combination of tradeoffs
Experimental studies suggest that the network of Linked Data Eddies outperforms static Web query schedulers in scenarios with data distributionsdata integration proposed by Noy
Experimental studies suggest that the network of Linked Data Eddies outperforms static Web query schedulers in scenarios with unpredictable transfer delays
experiments showing our scalability
Explicit crossdataset links for instance to indicate coreferences can significantly improve entity retrieval
Explicit crossdataset links for instance to indicate related entities can significantly improve entity retrieval
explicit information is available about which records in the different databases refer to the same real world entity
Extracting the semantics of Web tables to produce machineunderstandable knowledge has become an active area of research
Finally We perform value deduplication to group equivalent values of the aligned properties as value clusters
Finally we rerank the expanded result
Finally We use the semantic relatedness of the introduced types to improve the stateoftheart techniques by splitting
First given a pair of entities defined in some Knowledge graph find an explanation of a pair of entities
For a given set of endpoints with a SPARQL query the source selection problem with fragment replication  is to select the endpoints
For a given set of endpoints with a SPARQL query the source selection problem with the source selection problem with fragment replication  is to select the endpoints
For a given set of endpoints with replicated fragments the source selection problem with fragment replication  is to select the endpoints
For a given set of endpoints with replicated fragments the source selection problem with the source selection problem with fragment replication  is to select the endpoints
For a given set of entities we further expand the result
For the first time response times compatible with realtime reasoning are obtained with nonmonotonic KBs of this sizeinstances that refer to the same realworld entity
For this reason property paths were introduced in SPARQL 11
four different recommendation approaches exploiting both DBpedia in the music domain
four different recommendation approaches exploiting both Freebase in the music domainanalytics which can provide important insights into the research activity
Furthermore substring matching can be used to support other filters such as complete regular expressionsNoHR allows the user to query the combined knowledge base
Furthermore substring matching can be used to support other filters such as range queries
Furthermore to help users quickly find target entities topK link patterns are selected for entity navigation
Furthermore We show that the formal semantics for the defeasible mappings actually is strongly related to the idea of answer sets for logic programsAutomated acquisition of ontologies has attracted research attention because Automated acquisition of ontologies can give domain experts new insights into domain experts data
Given the evolving nature of the authoritative datasets to ensure consistent replicas frequent replacements are required at a great cost
Given the evolving nature of the authoritative datasets to ensure uptodate replicas frequent replacements are required at a great cost
Given the evolving nature of the original datasets to ensure consistent replicas frequent replacements are required at a great cost
Given the evolving nature of the original datasets to ensure uptodate replicas frequent replacements are required at a great cost
graphpatternbased interest expressions that is used to filter interesting parts of updates from the source
Half of the tested queries from a WatDiv benchmark test set could be executed with up to a third fewer http requests with only marginally higher server cost
Here we introduce a new algebra of relations which first solves the limitation of the previous one and second incorporates all qualitative taxonomical relations including the relations  is a  and  is not 
Here we investigate whether such a property extends to ABoxes
Here we propose to design scientific data publishing as a Webbased bottomup process without topdown control of central authorities such as publishing companies
However
However
However compositional inference is sound only if we assume that classes have nonempty extensions
However existing federated query engines are not designed to support replication are not designed to support replication
However existing federated query engines are not designed to support replication are not replicated data performance
However existing federated query engines are not replicated data can negatively impact existing federated query engines are not designed to support replication
However existing federated query engines are not replicated data can negatively impact existing federated query engines are not replicated data performance
However only a small fraction of entities are interlinked through explicit statements
However proper KBs represent extensional knowledge only
human involvement make assumptions about data do not fully respect background knowledge
identifiable entities that appear in the text
IFOrewritable ontologies that are not firstorder rewritable
In addition the better query selection used lead to triple store rankings
In addition the larger set of query types used lead to triple store rankingsLarge knowledge bases such as DBpedia are most often created heuristically due to scalability issues
In addition to reducing http requests such functions allow to achieve full result recall earlier when temporarily allowing lower precision
In addition we framework allows the persistent representation of the detected changes between versions in a manner
In addition we propose a joint approach to entity disambiguation
In addition we propose a joint approach to wordsense disambiguation
In a first  we cluster entities based on spectral clustering algorithms
In a first  we cluster entities based on the xmeans
Increasing a clients efficiency means lowering the number of requests
Indeed We show that in the latter case query answering even for conjunctive queries becomes coNPhard in data complexityEntity navigation over Linked Data often follows semantic links by using Linked Data browsers
In description logic terms proper KBs correspond to ABoxes
indirect semantic relationships which can help to understand the relation between two topics
indirect statistical relationships which can help to understand the relation between two topics
In offline preprocessing step we cluster entities based on spectral clustering algorithms
In offline preprocessing step we cluster entities based on the xmeans
In order to accomplish this we propose a largely automatic workflow which guides users through binding data to visualization parameters
In order to accomplish this we propose a largely automatic workflow which guides users through the process of creating visualizations by automatically categorizing
In order to explore this largescale body of knowledge we need an accurate ontology of research topics
In order to explore this largescale body of knowledge we need an comprehensive ontology of research topics
In order to explore this largescale body of knowledge we need an uptodate ontology of research topics
In order to make sense of we need an accurate ontology of research topics
In order to make sense of we need an comprehensive ontology of research topics
In order to make sense of we need an uptodate ontology of research topics
In particular Klink2 analyses networks of research entities  including authors  to infer three kinds of semantic relationships between topics
In particular Klink2 analyses networks of research entities  including papers  to infer three kinds of semantic relationships between topics
In particular Klink2 analyses networks of research entities  including technologies  to infer three kinds of semantic relationships between topics
In particular Klink2 analyses networks of research entities  including venues  to infer three kinds of semantic relationships between topics
in particular of Linked Data has led to a diverse landscape of datasets
In particular there exist currently agreedupon methods for publishing scientific datasets
In particular there exist currently no efficient reliable for publishing scientific datasets
In particular We show that LDQL is strictly more expressive than the query formalisms
Instance retrieval computes all instances of a given concept in DL  ontology
integration tools that generate analysis tools
integration tools that generate potential schema mappings and users
In the building process both random errors may occur
In the building process both systematic errors may occur
In the second step we propose an precomputed clusters
In this paper we augment proper KBs with DLLite TBoxes expressing ie of the domain 
In this paper we augment proper KBs with DLLite TBoxes expressing intensional knowledge 
In this paper we augment proper KBs with DLLite TBoxes expressing the ontology of the domain 
In this paper We compare the performance of sparql queries on multiple implementations including caseinsensitive fmindex
In this paper We compare the performance of sparql queries on multiple implementations including Elastic Search
In this paper We discuss the clientserver setup
In this paper we focus on antipatterns in DBpedia
In this paper we focus on finding systematic errors in DBpedia
In this paper we formulate the source selection problem with fragment replication
In this paper we introduce an approach for interestbased RDF update propagation
In this paper we investigate how the choice of one of the two datasets may influence the performance of a recommendation engine not only also in terms of These latter diversity and novelty
In this paper we investigate how the choice of one of the two datasets may influence the performance of a recommendation engine not only in terms of precision of the results
In this paper we present a domainindependent instance
In this paper we present a novel approach by taking advantage of a variety of knowledge sources available on the web
In this paper we present Klink2 by taking advantage of a variety of knowledge sources available on the web
In this paper we present lance
In this paper we present R  2O  2 a metareasoner and selects from a number of stateoftheart OWL 2 DL reasoners to achieve high efficiency making use of performance prediction models
In this paper we present R  2O  2 a metareasoner and selects from a number of stateoftheart OWL 2 DL reasoners to achieve high efficiency making use of ranking models
In this paper we present R  2O  2 ranks and selects from a number of stateoftheart OWL 2 DL reasoners to achieve high efficiency making use of performance prediction models
In this paper we present R  2O  2 ranks and selects from a number of stateoftheart OWL 2 DL reasoners to achieve high efficiency making use of ranking models
In this paper we present the first effort to work on knowledge cards fusion
In this paper we propose a declarative language to query Linked Data on the Web
In this paper we propose a framework
In this paper we propose a general purpose recursion operator to be added to SPARQL
In this paper we propose a general purpose recursion operator to develop algorithms for evaluating SPARQL in practical scenarios
In this paper we propose a general purpose recursion operator to formalize SPARQL syntax
In this paper we propose a twofold entity retrieval approach
In this paper we propose LDQL 
In this paper we provide the nontrivial solution for the extension of NoHR to OWL 2 QL by directly translating the ontology into rules without any prior classification
In this paper we show that although the addition of property paths has no impact on query evaluation property paths do make the containment problems substantially more difficult
In this paper we show that although the addition of property paths has no impact on query evaluation property paths do make the subsumption problems substantially more difficultSemantic relatedness are fundamental problems for linking text documents to the Web of Data
In this paper we show that semantic relatedness can also be accurately computed by analysing only the graph structure of the knowledge base
In this paper we tackle all of these problems
In this work we aim to advance the state of knowledge in this domain by systematically comparing a set of hypotheses about how users edit ontologies
In this work we aim to advance the state of knowledge in this domain by systematically defining a set of hypotheses about how users edit ontologies
In this work we study how typeconstraints can generally support the statistical modeling with latent variable models
In we experiments we first show that our relatedness measure performs better than related stateoftheart graph
In we experiments we first validate we relatedness measure on ground truth datasets
In we experiments we first validate we relatedness measure on multiple knowledge bases
It follows an approach adapted to description logics
It has been shown both empirically that performing core reasoning tasks on expressive ontologies in OWL 1 is resourceintensive
It has been shown both empirically that performing core reasoning tasks on expressive ontologies in OWL 2 is resourceintensive
It has been shown both empirically that performing core reasoning tasks on expressive ontologies in OWL 2 is timeconsuming
It has been shown both empirically that performing core reasoning tasks on large ontologies in OWL 1 is resourceintensive
It has been shown both empirically that performing core reasoning tasks on large ontologies in OWL 1 is timeconsuming
It has been shown both empirically that performing core reasoning tasks on large ontologies in OWL 2 is resourceintensive
It has been shown both empirically that performing core reasoning tasks on large ontologies in OWL 2 is timeconsuming
It has been shown both theoretically that performing core reasoning tasks on expressive ontologies in OWL 1 is resourceintensive
It has been shown both theoretically that performing core reasoning tasks on expressive ontologies in OWL 1 is timeconsuming
It has been shown both theoretically that performing core reasoning tasks on expressive ontologies in OWL 2 is resourceintensive
It has been shown both theoretically that performing core reasoning tasks on expressive ontologies in OWL 2 is timeconsuming
It has been shown both theoretically that performing core reasoning tasks on large ontologies in OWL 1 is resourceintensive
It has been shown both theoretically that performing core reasoning tasks on large ontologies in OWL 1 is timeconsuming
It has been shown both theoretically that performing core reasoning tasks on large ontologies in OWL 2 is resourceintensive
It has been shown both theoretically that performing core reasoning tasks on large ontologies in OWL 2 is timeconsuming
Knowledge graphs are a key ingredient for searching
Knowledge graphs are knowledge discovery activities
lance is the first Linked Data benchmark generator to support complex semanticsaware test cases
lance is the first Linked Data benchmark generator to support the standard test cases
lance produces a weighted gold standard
lance supports the definition of matching tasks with varying degrees of difficulty
Large knowledge graphs increasingly add value to various applications as in question answering systems
Large knowledge graphs increasingly add value to various applications as in search answering systems
Latent variable models have increasingly gained attention for the statistical modeling of knowledge graphs
Levesques proper knowledge bases  correspond to infinite sets of ground negative facts with the notable property that for FOL formulas in a certain normal form entailment reduces to formula evaluation
Levesques proper knowledge bases  correspond to infinite sets of ground positive facts with the notable property that for FOL formulas in a certain normal form entailment reduces to formula evaluation
Linked Data Eddies that is able to adjust query execution schedulers to data availability
Linked Data Eddies that is runtime conditions
logical inconsistencies that may be caused due to the traditional type of mappings
machine learning methods proving especially effective
many approaches dealing with both most of both problems rely on concept distribution over Wikipedia
many approaches dealing with both most of both problems rely on word distribution over Wikipedia
many approaches dealing with both problems rely on concept distribution over Wikipedia
many approaches dealing with both problems rely on word distribution over Wikipedia
Many data products rely on full local LOD replications to ensure faster processing
Many data products rely on full local LOD replications to ensure faster querying
Many data products rely on partial local LOD replications to ensure faster processing
Many data products rely on partial local LOD replications to ensure faster querying
Many LOD datasets such as DBpedia are process large amounts of requests from diverse applications
Many LOD datasets such as DBpedia are voluminous
Many LOD datasets such as LinkedGeoData are voluminous
measures that evaluate logical quality of a set of GCIs
measures that evaluate statistical quality of a set of GCIs
membership subqueries which check the presence of a specific triple
merging coreference clusters
Moreover
Moreover due to optimisation techniques each reasoner may be efficient for ontologies with different characteristics
Moreover due to the different reasoning algorithms each reasoner may be efficient for ontologies with different characteristics
Moreover Our findings are strikingly consistent across all ontologyengineering projects in our study with only minor exceptions for one of the smaller datasets
Moreover our investigate how our solution can be made to scale up to large enterprise datasets
Moreover this algebra covers relations only between classes
More precisely we integrated prior knowledge in form of typeconstraints in various state of the art latent variable approaches
Motivated by the need to harness knowledge available in a variety of Knowledge graphs we face the following two problems
Nodes in this bipartite graphical model represent opportunities for explicitly introducing bias
NoHR allows the user to combine an OWL 2 EL ontology with a set of logic programming  rules suitable
NoHR allows the user to combine an OWL 2 EL ontology with a set of nonmonotonic  rules suitable
NoHR allows the user to express defaults
NoHR allows the user to express exceptions
no theoretical studies examining how property paths addition to the language affects main computational tasks such as query containment
no theoretical studies examining how property paths addition to the language affects main computational tasks such as query evaluation
no theoretical studies examining how property paths addition to the language affects main computational tasks such as query subsumption
noun phrases that coreference identifiable entities
Offering the substring feature on Triple Pattern Fragment servers allows users to obtain faster responses for filterbased sparql queries
One of the main challenges in the Data Web is the identification of instances
One of the novelties of LDQL is that One of the novelties of LDQL expresses separately patterns
One of these interfaces is Triple Pattern Fragments
One of these interfaces studies Bloom filters as extra metadata
One of these interfaces studies Golombcoded sets as extra metadata
One of these interfaces studies the impact of providing approximate membership functions as extra metadata
ontologies specified in the description logic ALCOI
ontology alignment which is actually an onthefly online data fusion based on the users needs
Ontologybased data access is a recent paradigm for accessing data sources through declarative mappings
ontology languages that comprises all OWL 2 profiles
ontology languages that comprises OWL 2
ontology languages that examine mapping languages of different expressiveness over relational databases
optimisation techniques employed
other  entities sharing a similar relatedness perspective
our believe that our results are important for ontology tools builders
our believe that our results are important for project managers
our carried out an extensive set of experiments
Our findings suggest that the hierarchical structure of an ontology exercises the strongest influence on the semantic distance of classes in the ontology
Our findings suggest that the hierarchical structure of an ontology exercises the strongest influence on user editing behavior
our formally treat several fundamental questions in this context how links over database identifiers can be represented in terms of owl sameAs statements how to check consistency
our formally treat several fundamental questions in this context how links over database identifiers can be represented in terms of owl sameAs statements how to recover rewritability of SPARQL into SQL  lost because of owl 
our formally treat several fundamental questions in this context how links over database identifiers can be represented in terms of owl sameAs statements how to recover rewritability of SPARQL into SQL  lost because of sameAs statements 
our have implemented the approachMaking available is for the most part still considered the task of classical publishing companies despite the fact that classical forms of publishing centered around printed narrative articles no longer seem wellsuited in the digital age
Our results suggest that FEASIBLE generates better sample queries than the state of the art
pairs of  entities sharing a similar relatedness perspective
performance of clientside execution plans can be negatively affected by live conditions where rate at which data arrive from sources changes
potential semantic annotations that can be added to the identified mentions
Preliminary experimental results on retrieving instances of all atomic negations show that A rewritingbased method for retrieving instances of a negated concept is significantly more efficient than existing methods
problems related to the description and analysis of the evolution of RDF datasets
project managers who can potentially leverage this information to create user interfaces and processes
propagation which propagates only interesting parts of updates from the source to the target dataset
proper KBs  correspond to infinite sets of ground negative facts with the notable property that for FOL formulas in a certain normal form entailment reduces to formula evaluation
proper KBs  correspond to infinite sets of ground positive facts with the notable property that for FOL formulas in a certain normal form entailment reduces to formula evaluation
publishing scientific datasets which have become increasingly important for science
queries for which a complete execution is not computationally feasible over the Web
queries involving both changes
queries involving both data
queries satisfying a syntactic sufficient condition
queries that use sparql filters
Query times however did not improve likely due to slower metadata generation and transfer
Questions can then be asked in terms of the concepts in the overarching ontology
R  2O  2 also shows a 14
R  2O  2 also speedup over KoncludeThe increasing amount of data on the Web particular of Linked Data has led to a diverse landscape of datasets
R  2O  2 also speedup over the current dominant OWL 2 DL reasoner
RDF datasets which are important to a large number of domains such as
RDF datasets which are important to a large number of users such as
RECAP which is based on RDF
RECAP which is based on SPARQL
related stateoftheart graph based measures
relationtypes that allow machines to understand the notion of machines semantic relationships
relationtypes that allow machines to understand the notion of things semantic relationships
Replicating data fragments from different Linked Data sources facilitates data reorganization to better fit federated query processing needs of data consumers
requests which can among others be achieved through additional metadata in responses
retrieval model which takes advantage of we
Scalability is achieved by moving part of the query execution to the client at the cost of elevated query times
Second given a pair of entities find other  entities
Second given a pair of entities find pairs of  entities
separately patterns that describe the expected query result
separately patterns that describe Web navigation paths
services rely on full local LOD replications to ensure faster processing
services rely on full local LOD replications to ensure faster querying
services rely on partial local LOD replications to ensure faster processing
services rely on partial local LOD replications to ensure faster querying
Since the Triple Pattern Fragments interface purposely does not support complex constructs such as sparql filters queries need to be executed mostly on the client resulting in long execution times
Specifically we consider extitDLLite  core roughly corresponding to OWL 2 QL
Specifically we consider extitDLLite  rdfs
Specifically we consider roughly corresponding to RDFS
Specifically we consider two DLLite variants
Specifically We focus on noun phrases the challenge in this context is to improve the coreference resolution by leveraging potential semantic annotations
Specifically We focus on the problem of identifying mapping inconsistency and redundancy 
Specifically We focus on the problem of identifying two of the most important anomalies for mappings in Ontologybased data access
Speedups exceed 1 order of magnitude
stateoftheart systems that target mainly named
Such a problem can be considered as a new branch of ontology alignment
Such biases tend to be exploited by practitioners in a piecemeal fashion
Such optimizations are validated experimentally on large KBs with more than 30K axioms
Surprisingly to the best of our knowledge there has been no attempt to extend the standard OntologyBased Data Access
tasks related to cleaning
tasks related to knowledge graph completion
The amount of scholarly data available on the web is steadily increasing enabling different types of analytics
The approach is based on a comprehensive visualization model
The approach is based on a heuristic analysis of the structure of the input data
the BM25F retrieval approach shows significant improvements compared to the baseline and state of the art approachesBenchmarking is indispensable when aiming to assess technologies with respect to Benchmarking suitability for given tasks
The cards from different engines might be complementary
the case where mappings from many possibly heterogeneous ontologies are oneway links towards an overarching ontology
the Data Web accompanying schema as input to produce a target dataset
the Data Web can accept any linked dataset
the Data Web can accept the Data Web
the decision problems associated with mapping inconsistency and redundancy
the different reasoning algorithms employed
The dynamic nature of Web data gives rise to a multitude of problems the curators of biological information where changes are interrelated
the endpoints that minimize the number of tuples to be transferred
the expanded result set with respect to the relevance to the query
The experimental results show that We approach outperforms the state of the art ontology alignment algorithms in terms of precision
The experimental results show that We approach outperforms the state of the art ontology alignment algorithms in terms of recallWe present Ackermann for forgetting concept symbols in ontologies
the Fedra source selection algorithm that approximates the source selection problem with fragment replication
the firstorder rewritable class which guarantees that answering a CQ is reducible to answering a disjunction of CQs over the ABox regardless of the TBox
The formal approach realized in NoHR has been shown that even very large health care ontologies such as SNOMED CT can be handled
The formal approach realized in NoHR is polynomial 
The formal approach realized in NoHR is wrt data complexity 
the generation of benchmarks out of the query history of applications is achieved by selecting prototypical queries of a userdefined size from the input set of queries
The graph is first used to unify common biases in the design of existing instance matchers
The graph is first used to visualize common biases in the design of existing instance matchers
The high expressiveness allows LDQL to define queries
The hypotheses are evaluated by training 1032 neural networks on three instance matching tasks on Microsoft Azures cloudbased platform
The IFOrewritable class called IFOrewritable  class is identified
The IFOrewritable class called the inconsistencybased firstorder rewritable  class is identified
The IFOrewritable class guarantees that instance retrieval for an atomic negation can be reduced to answering a disjunction of conjunctive queries  CQs  over the ABox
The IFOrewritable class is more expressive than the firstorder rewritable class
The interactions between integration tool in CogMap presents highquality property alignments to analysis tool
The interactions between integration tool in CogMap presents highquality property alignments to the potential schema mappings and users
The interactions between integration tool in CogMap presents The interactions between integration tool in CogMap consequences to analysis tool
The interactions between integration tool in CogMap presents The interactions between integration tool in CogMap consequences to the potential schema mappings and users
The interactions between integration tool in CogMap uses the instance alignment from the previous iteration to create highquality property alignments
The iterative user interaction approach for data integration can be generalized to consider interactions between integration tools
The key challenge for visualizing Linked Data consists in providing a clear overview of Linked Data
The key challenge for visualizing Linked Data consists in supporting nontechnical users in finding suitable visualizations while hiding technical details of Linked Data
The key challenge for visualizing Linked Data consists in supporting nontechnical users in finding suitable visualizations while hiding technical details of visualization configuration
the modal approach on which Ackermann is based
the necessary insights pertaining to how current frameworks behave when dealing with real data
Then We propose an approach to type noun phrases
the order in which the concept symbols are eliminated significantly
The previously considered algebra of relations
The previously contains taxonomical relations between classes
The proposed approach is implemented in a prototype system
The proposed approach is then compared with two Linked Data browsers via a user study
the query formalisms that have been proposed previously for Linked Data on the Web
the rankings generated by previous works
There are many approaches
The recent boom in Linked Data facilitates a new stream of dataintensive applications that leverage the knowledge available in semantic datasets such as DBpedia
The recent boom in Linked Data facilitates a new stream of dataintensive applications that leverage the knowledge available in semantic datasets such as Freebase
Therefore it is necessary to fuse knowledge cards from different engines to get a comprehensive view
The resulting assignments are presented to the user
The resulting assignments are ranked to the user
the result set with relevant entities by considering features of entities
the result set with relevant entities by considering features of the precomputed clusters
the result set with relevant entities by considering features of the queries
These latter are well known encyclopedic collections of data
the standard OntologyBased Data Access setting to take into account these DB links for consistency checking
the standard OntologyBased Data Access setting to take into account these DB links for SPARQL queryanswering
the standard test cases related to structure transformations
the standard test cases related to value transformations
the stateoftheart federated query engines ANAPSID and empirically evaluate We performance
the stateoftheart federated query engines FedX and empirically evaluate We performance
the traditional optimizethenexecute paradigm used by existing approaches
the types of queries posed
The Web of Linked Data is composed of tons of RDF documents
This approach to benchmarking is however unsuitable to evaluate the performance of a triple store for a given application with particular requirements
this generalized a matching system for both property
this generalized approach in CogMap
this generalized instance alignments between heterogeneous data
This indicates that approximate membership functions can partly improve the clientside query process with minimal impact on the server interface
This indicates that approximate membership functions can partly improve the clientside query process with minimal impact on the serverIn this paper we tackle the problem of answering SPARQL queries over virtually integrated databases
This is partly because the OWL builtin owl sameAs property  is not included in OWL 2 QL 
This is partly because the OWL builtin owl sameAs property  is not included in the de facto ontology language for the standard OntologyBased Data Access
This is partly because the OWL builtin owl the most natural representation of links between data sets is not included in OWL 2 QL 
This is partly because the OWL builtin owl the most natural representation of links between data sets is not included in the de facto ontology language for the standard OntologyBased Data Access
this paper also identifies ambiguous keywords
this paper also separates ambiguous keywords into the appropriate distinct topics
This paper introduces a framework
This paper studies a new approach to instance retrieval for negated concepts
This paper studies a new approach to instance retrieval for negated concepts based on query rewriting
This provides more control over the inference process and reduces nondeterminism resulting in a smaller search space
this provides the advantage of avoiding logical inconsistencies
this provides the advantage of handling exceptions automatically
This renders data easily understandable by human beings by machines at the same time
This renders data seamlessly processable by machines at the same time
To enhance performance taskspecific knowledge is typically used to introduce bias in the model selection problem
To facilitate entity navigation we propose a novel concept and introduce link pattern lattice to organize semantic links when browsing an entity
To facilitate entity navigation we propose a novel concept and introduce link pattern lattice to organize semantic links when browsing a set of entities
to propagate alignments within a network of ontologies
Towards that end we study the user editing trails of four realworld ontologyengineering projects
Triple Pattern Fragments which allows clients to execute sparql queries against lowcost servers at the cost of higher bandwidth
triple store rankings which partly differ from the rankings
Two sufficient conditions are proposed to detect IFOrewritable ontologies
type noun phrases using an inverted index
Unfortunately human crafted classifications do not satisfy these criteria as human crafted classifications evolve too slowly
Unfortunately human crafted classifications do not tend to be too coarsegrained
up to date there are no theoretical studies
user editing behavior followed by the entity similarity
user interfaces and processes that better support the observed editing patterns of usersIt has been shown both empirically that performing core reasoning tasks on expressive ontologies in OWL 1 is timeconsuming
Using a coherent research framework we derive formal definitions of hypotheses from the literature and systematically compare previous empirical investigations with each other
value of we approachRecently Triple Pattern Fragments were introduced as a lowcost serverside interface
various applications that require machines to recognize Large knowledge graphs semantics
various applications that require machines to recognize queries
various applications that require machines to understand Large knowledge graphs semantics
We address this drawback by presenting an automatic approach for the generation of benchmarks out of the query history of applications
We address this drawback by presenting FEASIBLE
We address this drawback by presenting query logs
we also show how to implement recursion as a plugin on top of existing systems
we also show how to test a plugin performance on several real world datasetsThe original SPARQL proposal was often criticized for The original SPARQL proposal inability to navigate through RDF
we approach is based on a formal definition for graphpatternbased interest expressions
we approach is flexible enough to capture the peculiarities and needs of different applications on dynamic data while being formally robust due to the satisfaction of the completeness properties
we approach is flexible enough to capture the peculiarities and needs of different applications on dynamic data while being formally robust due to the satisfaction of the unambiguity properties
We argue that this architecture could be used for the Semantic Web in general
we assume that the entity resolution problem has already been solved
Web navigation paths that select the data sources to be used for computing the result
Web tables contains an estimated 154 million HTML tables of relational data with Wikipedia alone containing 16 million highquality tables
we compare four different triple stores with benchmarks
we comprehensive evaluation on a large ontology corpus shows that R  2O  2 consistently outperforms 6 stateoftheart OWL 2 DL reasoners on average performance with an average speedup of up to 14x
we comprehensive evaluation on a large ontology corpus shows that R  2O  2 significantly outperforms 6 stateoftheart OWL 2 DL reasoners on average performance with an average speedup of up to 14x
We consider a wide range of ontology languages
We consider the case
We describe an implementation of We ideas in a tool
We devise the Fedra source selection algorithm
We establish tight complexity bounds for the decision problems
We evaluate SANAPHOR on CoNLL datasets
We evaluate We approach on two query logs
We evaluate We show that the benchmarks our approach generates are accurate approximations of the input query logs
we evaluation shows encouraging results
We evaluations indicate that these improvements allow for faster query execution without significantly increasing the load on the server
we experimental evaluation shows that the ability of Klink2 to generate topics with accurate contextual meaning yields significant improvements over other algorithms in terms of both precision and recall
we experimental evaluation shows that the ability of Klink2 to integrate a high number of data sourcesWeb tables form a valuable source of relational data
we experimental results show that prior knowledge on relationtypes significantly improves Latent variable models up to 77We present a novel approach to denote mappings between ELbased ontologies
We experiments show that multiple iterations serve to improve the final alignmentsvarious applications that require machines to understand queries
We experiments show that the interplay between instance alignment serve to improve the final alignments
We experiments show that the interplay between property alignment serve to improve the final alignments
We experiments show that We can acquire interesting sets of GCIs
We experiments show that We can provide insights into the structure of the search spaceThe dynamic nature of Web data gives rise to a multitude of problems the curators of biological information where changes are constant
We formalize the notion of relatedness explanation
We formally provide a syntactic sufficient condition to avoid this problem queries are ensured to have a procedure to be effectively evaluated over The Web of Linked DataFederated query engines provide a unified query interface to federations of SPARQL endpoints
We formally study this issue queries are ensured to have a procedure to be effectively evaluated over The Web of Linked Data
We have implemented this
we have implemented we approachOntologybased data access is a recent paradigm for accessing data sources through an ontology
We implement Fedra in the stateoftheart federated query engines
we implement the approach in the iRap framework
We introduce different criteria to build explanations based on a pair of entities
We introduce different criteria to build explanations based on diversity
We introduce different criteria to build explanations based on informationtheory
We introduce measures
We introduce optimization techniques for reasoning in DLN a recently introduced family of nonmonotonic description logics whose characterizing features appear wellsuited to model the examples naturally arising in semantic web access control policies
We investigate the problem of general terminology induction ie Automated acquisition sets of general class inclusions GCIs from background knowledge
We investigate the problem of general terminology induction ie Automated acquisition sets of general class inclusions GCIs from data
We noted that typical sparql query evaluations against Triple Pattern Fragments require a significant portion of membership subqueries
We noted that typical sparql query evaluations against Triple Pattern Fragments require a variable pattern
we perform a comprehensive evaluation based on DBpedia Live updates to confirm the validity
we perform a thorough experimental evaluation on BTC12  dataset
we perform a thorough experimental evaluation on the Billions Triple Challenge  dataset
We present a formal syntax and semantics prove equivalence rules
We present a network of Linked Data Eddies
We present methods to compute an anytime algorithm
We present methods to compute these measures
We propose a novel probabilistic scoring algorithm for card disambiguation to select the most likely entity a card should refer to
We prove that this algebra is coherent with respect to the simple semantics of alignmentsClientside query processing techniques provide a promising solution for Web query processing
We provide a comparative analysis with lance benchmarks to assess the capabilities of state of the art instance matching an evaluation to demonstrate the scalability of lances test case generatorAs the Web of Data is growing steadily the demand for userfriendly means for exploring analyzing Linked Data is also increasing
We provide a comparative analysis with lance benchmarks to assess the capabilities of state of the art instance matching systems to demonstrate the scalability of lances test case generator
We provide a comparative analysis with lance benchmarks to identify the capabilities of state of the art instance matching an evaluation to demonstrate the scalability of lances test case generator
We provide a comparative analysis with lance benchmarks to identify the capabilities of state of the art instance matching systems to demonstrate the scalability of lances test case generator
We provide a comparison with related systems on realworld dataa certain normal form which includes conjunctive queries
We provide algorithms
We provide an evaluation of RECAP
We provide the formal semantics for the defeasible mappings
We results prove that in We general framework such forms of mapping analysis enjoy nice computational properties in the sense that such forms of mapping analysis are not harder than standard reasoning tasks over an ontologyOntologies are complex intellectual artifacts
We show how this approach allows researchers to publish retrieve verify and recombine datasets of nanopublications in a reliable manner
We show how this approach allows researchers to publish retrieve verify and recombine datasets of nanopublications in a trustworthy manner
We show how We techniques consistently improve the state of the art in coreference resolutionRDF documents interlinked to each other forming a huge repository of distributed semantic data
we show that by aligning the DBpedia ontology to the foundational ontology DOLCEZero errors can be identified at a minimal workload for the knowledge base designerWe tackle the problem of resolving coreferences in textual content by leveraging Semantic Web techniques
we show that by combining clustering of the reasoning results errors can be identified at a minimal workload for the knowledge base designer
we show that by combining reasoning of the reasoning results errors can be identified at a minimal workload for the knowledge base designer
we show that four different triple stores behave differently based on the data four different triple stores contain
We show that reasoning under such a setting is decidable even when the defeasible axioms apply to unknowns
We show that when a extitDLLite  rdfs TBox is coupled with a proper KB a extitDLLite  rdfs TBox can be compiled away reducing query answering to evaluation on the proper KB alone
We study the expressiveness of the language
We study the formal analysis of mappings in Ontologybased data access
We system SANAPHOR first applies stateoftheart techniques to extract candidate coreferences
We system SANAPHOR first applies stateoftheart techniques to extract entities
We system SANAPHOR first applies stateoftheart techniques to extract noun phrases
We tackle adaptivity for clientside query processing
we tested four different recommendation approaches
We then design a learningbased method to align properties from cards
We therefore investigated the impact of adding a literal substring matching feature to the Triple Pattern Fragments interface with the goal of improving query performance while maintaining low server cost
we work exhibits good scalability properties
we work is evaluated using real Linked Open DataInstance matching has emerged as an important problem in the Semantic Web with machine learning methods
While benchmark generation frameworks have been developed to evaluate triple stores Benchmarking mostly provide a onefitsall solution to the benchmarking problem
While existing ontologyediting tools propose ways of building ontologies in a normative way empirical investigations of how experts actually construct ontologies  in the wild  are rare
While methodologies propose ways of building ontologies in a normative way empirical investigations of how experts actually construct ontologies  in the wild  are rare
While several benchmarks have been developed to evaluate triple stores Benchmarking mostly provide a onefitsall solution to the benchmarking problem
With LinkDaViz we demonstrate the feasibility by an extended userMany LOD datasets such as LinkedGeoData are process large amounts of requests from diverse applications
With LinkDaViz we demonstrate the feasibility by performance evaluation
With LinkDaViz we provide a webbased implementation of the approach
With the increasing volume of Linked Data the diverse links make it difficult for users to find target entities
With the increasing volume of Linked Data the diverse links make it difficult for users to traverse the link graph
With the increasing volume of Linked Data the rich links make it difficult for users to find target entities
With the increasing volume of Linked Data the rich links make it difficult for users to traverse the link graph
wordsense disambiguation that makes use of graphbased relatedness
Yet a straightforward adaptation of the existing approach to OWL 2 QL turns out to not be viable
Yet understanding actual user behavior can play an important role in the design of effective tool support
