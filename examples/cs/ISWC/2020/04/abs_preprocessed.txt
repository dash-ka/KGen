there is a variety of available approaches to learn graph node embeddings
one of their common underlying task is the generation of  biased  random walks that are then fed into representation learning techniques
some techniques generate biased random walks by using structural information
other approaches also rely on some form of semantic information
while the former are purely structural thus not fully considering knowledge available in semantically rich networks the latter require leverage node types
leverage node types that may not be available
while the former are purely structural thus not fully considering knowledge available in semantically rich networks the latter require complex inputs 
while the former are purely structural thus not fully considering knowledge available in semantically rich networks the latter require eg metapaths 
the goal of this paper is to overcome these limitations by introducing node embeddings via semantic proximity 
the goal of this paper is to overcome these limitations by introducing nesp 
node embeddings via semantic proximity  which features two main components
nesp  which features two main components
the first provides four different ways of biasing random walks by leveraging semantic relatedness between predicates
the second component focuses on existing  embeddings by leveraging the notion of semantic proximity
the second component focuses on refining  embeddings by leveraging the notion of semantic proximity
node embeddings imposing the embeddings of semantic neighboring nodes of a node to lie within a sphere of fixed radius
the second component iteratively refines an initial set of node embeddings
we discuss an extensive experimental evaluation and comparison with related work