a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm in terms of weighted semanticlexical relations particularly the inhibition relation between senses
actions that should be recorded in Privacy audit logs
a decomposed backwards chaining algorithm for ontologymediated queries
a dedicated programming language enabling Semantic Web programmers to directly define functions on RDF graphs
a dedicated programming language enabling Semantic Web programmers to directly define functions on RDF terms
a dedicated programming language enabling Semantic Web programmers to directly define functions on SPARQL results
a deep Convolutional Neural Network  CNN  model designed for identifying the category of information
a firstorder query which is then executed using a conventional SQL database system
aggregation which poses limitations in practice
a granular manner which has been successfully applied to a number of scientific datasets
a hybrid adaptive distributed RDF Stream Processing engine has been designed to guarantee important industrial properties such as acceptable latency
a hybrid adaptive distributed RDF Stream Processing engine has been designed to guarantee important industrial properties such as fault tolerance
a hybrid adaptive distributed RDF Stream Processing engine has been designed to guarantee important industrial properties such as high availability
a hybrid adaptive distributed RDF Stream Processing engine has been designed to guarantee important industrial properties such as high throughput
a hybrid adaptive distributed RDF Stream Processing engine has been designed to guarantee important industrial properties such as scalability
a hybrid method that significantly outperforms individual methods on all the benchmarks
a joint attributepreserving embedding model for crosslingual entity alignment jointly embeds the structures of two entities in two knowledge bases into a unified vector space
a key constraint that is valid in only a part of the data
a languageagnostic approach that builds machine learning models only from languageindependent features
a languageagnostic approach that exploits background knowledge from the graph instead of languagespecific techniques
a languageindependent logical form based on Dependencybased Underspecified Discourse Representation Structures 
a languageindependent logical form based on DUDES 
A large collection of 10 wellknown reasoners are studied
A large collection of ontologies are studied
a Linked Data based method of utilizing blockchain technology to create tamperproof audit logs
a lookupbased method which relies on the minimal entity context
a machine learning model to predict reference quality on a largescale
a meta structurebased relevance measure which can retrieve entities related to those in input
an approach known as CQdriven Ontology Authoring
an approach known as CQdriven Ontology Authoring
an approach known as CQdriven Ontology Authorings understanding of CQs matches users understanding quite well especially for inexperienced ontology authors
an approach that uses statistics
an evaluation that shows that almost all acyclic DL ontologies do indeed satisfy these general restrictionsA prominent approach to implementing ontologymediated queries is to rewrite into a firstorder query
an evaluation using real test bases from W3C
a new largescale benchmark created using Wikipedia tables
a new reasoner that supports a pragmatic nontrivial fragment of the logic LARS
a new reasoner that supports a pragmatic nontrivial fragment of the logic LARS
an extension of the SPARQL language does not add expressivity
an extensive experimental evaluation which confirms the suitability of We proposal from both effectiveness point of view
an extensive experimental evaluation which confirms the suitability of We proposal from both the efficiency of viewThe disjunctive skolem chase is complete  algorithm that can be used to solve conjunctive query answering over DL ontologies and programs with disjunctive existential rules
an implementation of LARS which runs on the Programming
an ontology matching method which exploits instance information of entities available both in a KB
an ontology matching method which exploits instance information of entities available both in a Web table
an ontology matching method which exploits schematic information of entities available both in a KB
an ontology matching method which exploits schematic information of entities available both in a Web table
An outcome of this research is the suggestion that ontology axioms may be better presented in symbolic description logic
An outcome of this research is the suggestion that ontology axioms may be better presented in The Manchester OWL Syntax
a novel cardinality estimation that takes into account all such SPARQL query answering in ontologybased data access components
a novel evaluation procedure is responsible for significantly better runtimes than the ones of an implementation of LARS solver Clingo
a novel evaluation procedure is responsible for significantly better runtimes than the ones of other stateoftheart systems like CQELS solver Clingo
a novel evaluation procedure is responsible for significantly better runtimes than the ones of other stateoftheart systems like CSPARQL solver Clingo
a novel evaluation procedure which annotates formulae to avoid the recomputation of duplicates at multiple time points
a novel evaluation procedure which annotates formulae to avoid the recomputation of duplicates at multiple time points
An underlying common requirement is to annotate the rows of Web tables with semantically rich descriptions of entities
any SPREFQL query can be transformed to an equivalent standard SPARQL query
approaches performance is usually evaluated by comparing the produced alignments to a reference alignment in terms of Fmeasure
approaches performance is usually evaluated by comparing the produced alignments to a reference alignment in terms of precision
approaches performance is usually evaluated by comparing the produced alignments to a reference alignment in terms of recall
a  PREFER  clause that expresses  soft  preferences over the query
a  PREFER  clause that expresses  soft  preferences over the query
A prominent approach to implementing ontologymediated queries  combines a reduction with a
A prominent approach to implementing ontologymediated queries  combines a reduction with a
a RandomForest classifier trained only on languageindependent features
As a proof of concept for We approach We evaluate our approach on the QALD6 datasets for English German SpanishIn this paper we present perceived usability for SemwidgQL
As a result we propose a hybrid methodA conditional key is a key constraint
a semantic embeddings method that exploits a vectorial representation of the rich entity context in a KB to identify the most relevant subset of entities in the Web table
a shared latent representation that integrates information across those modalities
a statistical semantic model using link prediction methods
At Laser a new reasoner Laser implements a novel evaluation procedure
a typing mechanism called shapes against which nodes of the graph can be checked
a user study in which participants wrote a set of queries in both languages
a visual tool called MEKoNG
a wide Convolutional Neural Network  CNN  model designed for identifying the category of information
a word sense alignment algorithm called JdMBabelizer that
Bad references were often links
Based on which trust values for each integrated data source respective signature elements are computed
Based on which trust values for each integrated data source respective signature elements are computed
But the more data are available from heterogeneous sources the higher the risk is of inconsistency
By conducting a betweengroup empirical study involving 60 novice participants we found that symbolic description logic is just as effective as The Manchester OWL Syntax for peoples understanding of axioms
Crosslingual taxonomy alignment which brings two novel category correlation based bilingual topic models
Crosslingual taxonomy alignment which brings two novel category correlation based called CCBiLDA
Crosslingual taxonomy alignment which brings two novel category correlation based CCBiBTM
crucially when background knowledge is available as RDF Schema ontological constraints we take advantage of the literature to devise mathtt lgg  s as we experiments on the popular DBpedia dataset showAutomated acquisition of ontologies from data has attracted research interest because Automated acquisition  Automated acquisition  of ontologies from data can complement manual expensive construction of ontologies
crucially when background knowledge is available as RDF Schema ontological constraints we take advantage of the literature to devise much more precise  s as we experiments on the popular DBpedia dataset show
data stemming from different sources
data stemming from that
data streams emanating from sensors
Dependencybased Underspecified Discourse Representation Structures  that are then mapped to a SPARQL query as a deterministic second step
description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations
developing methods that overcome the lexical gap
developing methods that present a novel combination of machine translation for this purpose
developing methods that present a novel combination of word embedding approaches for this purpose
different implementations and approaches comparing in Java compilation
different implementations and approaches comparing in particular
different implementations and approaches comparing in script interpretation
DUDES  that are then mapped to a SPARQL query as a deterministic second step
entities published in Web KBs
Entity comparison is a widely used functionality available in many information systems such as product comparison websites
Entity comparison is a widely used functionality available in many information systems such as universities
Even though acyclicity notions can be used to ensure chase termination for a large subset of realworld knowledge bases the complexity of reasoning over acyclic theories still remains high
Existing approaches such as RDF2Vec use local information rely on local sequences
Existing approaches use local information rely on local sequences
Existing faceted search systems however do not allow users to construct queries with aggregation
Existing faceted search systems however do not allow users to construct queries with recursion
Experiments on the two Wikipedia data sets of EnglishChinese show that proposed approach can achieve high F1measure 854 percent respectively on the two data sets
Experiments on the two Wikipedia data sets of EnglishChinese show that proposed approach can achieve high F1measure 855 percent
Experiments on the two Wikipedia data sets of EnglishFrench show that proposed approach can achieve high F1measure 854 percent respectively on the two data sets
Experiments on the two Wikipedia data sets of EnglishFrench show that proposed approach can achieve high F1measure 855 percent
Experiments on two realworld datasets show our proposed models significantly outperform the stateoftheart baselines on Crosslingual taxonomy alignment the idea to execute queries over several distributed knowledge bases lies at the core of the semantic web vision
Experiments on two realworld datasets show our proposed models significantly outperform the stateoftheart baselines on Crosslingual taxonomy at least 109 percent in each evaluation metric 
Experiments with realworld ontologies show promising resultsLinked Data when servers provide different interfaces to access servers data
expressive reasoning which is challenging to compute on large streams
factor graphs that rely on features
features extracted from corresponding semantic representations
features extracted from the dependency graph
Federated querying  lies at the core of the semantic web vision
Finding the commonalities between descriptions of data is a foundational reasoning problem of Machine Learning
First We perform a crowdsourced evaluation of references
For example before exposing a new type of LDFs in some server can we formally say something about how this new LDF interface compares to other interfaces previously implemented in the same server
For instance
For this we combine techniques from key mining with techniques from rule mining
For word embeddings global techniques such as GloVe have been proposed as an alternative
French built on a crowdsourcing principle as a game with a purpose
From the client side given a client with some restricted capabilities in terms of computational power which is the best type of LDFs to complete a given task
From the client side given a client with some restricted capabilities in terms of network connection which is the best type of LDFs to complete a given task
From the client side given a client with some restricted capabilities in terms of time constraints which is the best type of LDFs to complete a given task
From those we can extract 16 M new relations in DBpedia at a level of precision of 95percent using a RandomForest classifier
functional properties associated to RDF resources as functions
functional properties associated to the definition of procedural attachments as functions
functions assigned to OWL classes with the selection of the function to be applied to a resource depending on the type of a resource
functions assigned to RDFS classes with the selection of the function to be applied to a resource depending on the type of a resource
Further adoption of these techniques however was probably hindered by the fact that nanopublications can lead to an explosion in the number of triples due to auxiliary information about the structure of each nanopublication
Further adoption of these techniques however was probably hindered by the fact that nanopublications can lead to an explosion in the number of triples due to auxiliary information about the structure of repetitive provenance and metadata
Further empirical studies are needed to explain These surprising results
Further empirical studies are needed to see whether Further empirical studies hold for other types of taskA growing number of highly optimized reasoning algorithms have been developed to allow inference tasks on expressive ontology languages such as OWL
Furthermore reference alignments are often unavailable which makes the comparative exploration of alignments at different levels of granularity even more important
Furthermore The experimental results proves that our introduced ranking method could effectively be evolved to a competitive metareasonera provenanceaware manner which has been successfully applied to a number of scientific datasets
Furthermore we show an exemplary geographical breakdown of the information
further refines a joint attributepreserving embedding model for crosslingual entity alignment by leveraging attribute correlations in the entities in two knowledge bases
Further work should focus on implementing our approach in Wikidata to help editors find bad referencesCrosslingual taxonomy alignment refers to mapping each category in the source taxonomy of one language onto a ranked list of most relevant categories in the target taxonomy of another language
Gathering both statistical evidence generated by inconsistency detection and resolution we create a Markov network to facilitate the application of Gibbs sampling to compute a probability for each conflicting assertion
Gathering both the conflict graph generated by inconsistency detection and resolution we create a Markov network to facilitate the application of Gibbs sampling to compute a probability for each conflicting assertion
global objectification of able to express inclusion dependencies is equipped with both ABox axioms
global objectification of able to express inclusion dependencies is equipped with both TBox axioms
global objectification of external uniqueness dependencies is equipped with both ABox axioms
global objectification of external uniqueness dependencies is equipped with both TBox axioms
global objectification of functional dependencies is equipped with both ABox axioms
global objectification of functional dependencies is equipped with both TBox axioms
global objectification of key dependencies is equipped with both ABox axioms
global objectification of key dependencies is equipped with both TBox axioms
global objectification of relations dependencies is equipped with both ABox axioms
global objectification of relations dependencies is equipped with both TBox axioms
Hence we study these general restrictions
hockey players do not have children
However as the different language versions of Wikipedia evolve independently it is a challenging problem to find correspondences between infobox attributes in different language editions
However as the different language versions of Wikipedia evolve independently it is a promising problem to find correspondences between infobox attributes in different language editions
However bilingual topic models ignore explicit category correlations such as correlations between the categories among the categories of ancestordescendant relationships in a taxonomy
However bilingual topic models ignore explicit category correlations such as the categories among the categories of ancestordescendant relationships in a taxonomy
However bilingual topic models only model the textual context of categories
However clearly separating preferences from the  filters in the  WHERE  clause gives queries where the intention of the client is more cleanly expressed an advantage for both human readability
However clearly separating preferences from the  filters in the  WHERE  clause gives queries where the intention of the client is more cleanly expressed an advantage for both machine optimization
However clearly separating preferences from the  hard  patterns  WHERE  clause gives queries where the intention of the client is more cleanly expressed an advantage for both human readability
However clearly separating preferences from the  hard  patterns  WHERE  clause gives queries where the intention of the client is more cleanly expressed an advantage for both machine optimization
However collusion may occur between the auditors and participants to obfuscate actions
However comparison depends on a fixed set of aspects to compare
However comparison is typically domainspecific
However little attention has been paid so far to the problem of updating Ontologybased Data Access systems
Howeverontologybased systems that process data is received over time as in contextaware systems
However visual attributes of those entities like those entities like color concerning their usage in color concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in color concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in color concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in natural language shape concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in natural language shape concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in natural language shape concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in pragmatic aspects concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in pragmatic aspects concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like color concerning their usage in pragmatic aspects concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in color concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in color concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in color concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in natural language shape concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in natural language shape concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in natural language shape concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in pragmatic aspects concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in pragmatic aspects concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like pragmatic aspects concerning their usage in pragmatic aspects concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in color concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in color concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in color concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in natural language shape concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in natural language shape concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in natural language shape concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in pragmatic aspects concerning those entities like color concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in pragmatic aspects concerning those entities like pragmatic aspects concerning their usage in natural language usage in natural language are not covered
However visual attributes of those entities like those entities like their shape concerning their usage in pragmatic aspects concerning those entities like their shape concerning their usage in natural language usage in natural language are not covered
huge text corpora which capture word embeddings distributional semantics
images associated scene description
In addition to the existing standards Semantic Web programmers could really benefit from a dedicated programming language
In an ongoing industrial project a 24 7 available stream processing engine usually faces dynamically changing data
In an ongoing industrial project a 24 7 available stream processing engine usually faces dynamically changing workload characteristics
in an RDF graph about drugs we may want to compare Ibuprofen
in an RDF graph about drugs we may want to compare Metamizole
in an RDF graph about drugs we may want to find out that Ibuprofen are similar in that Ibuprofen are both analgesics
in an RDF graph about drugs we may want to find out that Ibuprofen are similar in that Metamizole are both analgesics
in an RDF graph about drugs we may want to find out that Metamizole are similar in that Ibuprofen are both analgesics
in an RDF graph about drugs we may want to find out that Metamizole are similar in that Metamizole are both analgesics
In by contrast to the literature
incompleteness which may result in the wrong estimation of the quality of mined rules
 in contrast to Metamizole Ibuprofen also has a considerable antiinflammatory effect
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of a given Competency Question  an approach 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of a given Competency Question  an approach 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of a given Competency Question  construction 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of a given Competency Question  construction 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of the interface to test whether a given Competency Question  is able to be answered by the ontology at a given stage of a given Competency Question  construction 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of the interface to test whether a given Competency Question  is able to be answered by the ontology at a given stage of CQ  construction 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of the interface to test whether a given Competency Question  is an approach 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of the interface to test whether CQ  is able to be answered by the ontology at a given stage of a given Competency Question  construction 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of the interface to test whether CQ  is able to be answered by the ontology at a given stage of CQ  construction 
In earlier work we proposed that an ontology authoring interface can be improved by allowing the interface to test whether a given Competency Question is able to be answered by the ontology at a given stage of the interface to test whether CQ  is an approach 
In many applications there is an increasing need for the new types of RDF data analysis
In many cases however data may be available from multiple sources
In modelling realworld knowledge there often arises reason with metaknowledge
In ontologybased systems reasoning needs to cope with the temporal dimension
In ontologybased systems reasoning should be resilient against inconsistencies in the data
In particular
In particular
In particular We approach learns to map universal syntactic dependency representations to a languageindependent logical form
In particular we investigate complexity of query containment problems
In particular we investigate complexity of the query answeringOntology alignment is an area of active research where many algorithms and approaches are being developed
instance when defining SPARQL extension functions
In the interest of interoperability we propose a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm anchors JeuxDeMots senserefinements to synsets in the lemon edition of BabelNet
In the interest of interoperability we propose a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm anchors JeuxDeMots senserefinements to the Linguistic Linked Open Data cloud
In the interest of reuse we propose a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm anchors JeuxDeMots senserefinements to synsets in the lemon edition of BabelNet
In the interest of reuse we propose a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm anchors JeuxDeMots senserefinements to the Linguistic Linked Open Data cloud
In this paper we consider scene descriptions
In this paper we consider the relationship between eg manridingelephant manwearinghat 
In this paper we consider the relationship between them 
In this paper we evaluate three unsupervised annotation methods a lookupbased method
In this paper we evaluate three unsupervised annotation methods an ontology matching method
In this paper we evaluate three unsupervised annotation methods a semantic embeddings method
In this paper we introduce SemCNN a deep Convolutional Neural Network  CNN  model contained in crisisrelated social media content
In this paper we introduce SemCNN a wide Convolutional Neural Network  CNN  model contained in crisisrelated social media content
In this paper we introduce the notion of subsumption justification as an extension of justification  a minimal set of axioms needed to preserve a logical consequence  to capture the subsumption knowledge between all other terms in the vocabulary
In this paper we introduce the notion of subsumption justification as an extension of justification  a minimal set of axioms needed to preserve a logical consequence  to capture the subsumption knowledge between a term in the vocabulary
In this paper we present an approach
In this paper we present an empirical comparison of user performance
In this paper we present Odyssey
In this paper we present our introduced ranking method
In this paper we present perceived usability for a pathoriented Rdf query language
In this paper we present perceived usability for Sparql
In this paper we present SPREFQL an extension of the SPARQL language  soft  preferences over the query results obtained by the main body of the query
In this paper we present SPREFQL we formally define the semantics of an extension of the SPARQL language
In this paper we present SPREFQL we formally define the syntax
In this paper we propose 8 effective features for cross lingual infobox attribute matching
In this paper we propose a formal framework for domainindependent entity comparison over RDF graphs
In this paper we propose a joint attributepreserving embedding model for crosslingual entity alignment
In this paper we propose a Linked Data
In this paper we propose a unified solution to encode category correlations into bilingual topic modeling for Crosslingual taxonomy alignment
In this paper we propose mechanisms to properly handle updates in this context
In this paper we show how such keys can be mined automatically on large knowledge bases
In this paper we show how the idea of global embeddings can be transferred to RDF embeddingsJeuxDeMots is a rich collaborative lexical network in French represented in an adhoc tabular format
In this paper we show that the results are competitive with traditional local techniques like RDF2Vec
In this work we extend faceted search over RDF with these functionalities
In this work we show that translating to UCQs is not always the best choice
In this work we show that under certain conditions on the interplay between the mappings alternative translations can be evaluated much more efficiently
In this work we show that under certain conditions on the interplay between the ontology alternative translations can be evaluated much more efficiently
In this work we show that under certain conditions on the interplay between the statistics of the data alternative translations can be evaluated much more efficiently
In this work we study the corresponding query language
It can be used to constrain the admissible properties for nodes in that graph
It can be used to constrain the admissible values for nodes in that graph
It can be used to describe the structure of an RDF graph
It can be used to describe the vocabulary
it is believed to be more effective for users
It was formalized in the early 70s as computing a least general generalization   mathtt lgg   of such descriptions
knowledge discovery tasks ranging from relatedness explanation to data retrieval
Knowledge graphs  are widely used in entity recognition
Knowledge graphs  are widely used in entity recognition
Knowledge graphs  are widely used in other important tasks
Knowledge graphs  are widely used in other important tasks
Knowledge graphs  are widely used in question answering
Knowledge graphs  are widely used in question answering
Knowledge graphs  are widely used in structured search
Knowledge graphs  are widely used in structured search
knowledge that go beyond todays Knowledge Graphs
Largescale knowledge graphs such as DBpedia can be enhanced by relation extraction from text using distant supervision
Largescale knowledge graphs such as Wikidata can be enhanced by relation extraction from text using distant supervision
Largescale knowledge graphs such as Wikidata can be enhanced by relation extraction from text using the data in the knowledge graph as training data
Largescale knowledge graphs such as YAGO can be enhanced by relation extraction from text using distant supervision
Largescale knowledge graphs such as YAGO can be enhanced by relation extraction from text using the data in the knowledge graph as training data
LDF  framework has been proposed as a uniform view to explore the tradeoffs of consuming Linked Data
leading to erroneous beliefs such as all artists have won an award
links that changed
links that either stopped working or pointed to other pages
local objectification of able to express inclusion dependencies is equipped with both ABox axioms
local objectification of able to express inclusion dependencies is equipped with both TBox axioms
local objectification of external uniqueness dependencies is equipped with both ABox axioms
local objectification of external uniqueness dependencies is equipped with both TBox axioms
local objectification of functional dependencies is equipped with both ABox axioms
local objectification of functional dependencies is equipped with both TBox axioms
local objectification of key dependencies is equipped with both ABox axioms
local objectification of key dependencies is equipped with both TBox axioms
local objectification of relations dependencies is equipped with both ABox axioms
local objectification of relations dependencies is equipped with both TBox axioms
local sequences generated for nodes in the RDF graph
Making such comparisons efficient calls for a  humanintheloop  approach best supported through interactive visual representations of alignments
many algorithms is usually evaluated by comparing the produced alignments to a reference alignment in terms of Fmeasure
many algorithms is usually evaluated by comparing the produced alignments to a reference alignment in terms of precision
many algorithms is usually evaluated by comparing the produced alignments to a reference alignment in terms of recall
mathcalDLRpm  nary description logic is able to encode more thoroughly conceptual data models such as ever
mathcalDLRpm  nary description logic is able to encode more thoroughly conceptual data models such as ORM
mathcalDLRpm  nary description logic is able to encode more thoroughly conceptual data models such as UML
Meta structures are useful in a variety of knowledge discovery tasks
methods based on machine translation
Moreover for two types of inference problems symbolic description logic supported significantly better task performance than The Manchester OWL Syntax yet The Manchester OWL Syntax never significantly outperformed symbolic description logic
more than 30percent of ENZH Wikipedia existing crosslingual links
Motivated by such settings this paper addresses the problem of handling inconsistent data in a temporal version of ontologybased query answering
multiple sources resulting in a combinatorially growing number of alternative allocations of subqueries to sources
Nanopublications are a concept to represent Linked Data in a granular manner
Nanopublications are a concept to represent Linked Data in a provenanceaware manner
Nevertheless optimal plans may still exhibit a high number of high execution times because of heuristics
Nevertheless optimal plans may still exhibit a high number of high execution times because of inaccurate cost estimations
Nevertheless optimal plans may still exhibit a high number of intermediate results because of heuristics
Nevertheless optimal plans may still exhibit a high number of intermediate results because of inaccurate cost estimations
Nevertheless there is broad agreement that a reasoner could be optimized for all the ontologies
Nevertheless there is broad agreement that a reasoner could be optimized for some
novel measures designed to rigorously evaluate the quality of general expressive TBox axioms while respecting the standard semantics of OWL
object detection based on convolutional neural networks with a latent variable model for link prediction
Often a timely extraction of nontrivial knowledge requires expressive reasoning
one benchmark data set
One of the main advantages of link prediction methods is that We can also generalize to triples
One such important analysis task is determining what are differences between two given entities in an RDF graph
One such important analysis task is determining what are similarities between two given entities in an RDF graph
One such important analysis task is entity comparison
only correct general expressive TBox axioms can be interestingAuthoring Tests derived from Competency Questions
ontology alignment evaluation that can benefit from interactive visualization
ontology axioms when presented to nonexperts
Ontologybased Data Access is gaining importance both scientifically
ontologymediated queries based on atomic queries
ontologymediated queries based on conjunctive
ontologymediated queries that are based on the simpler atomic queries also illuminating the relationship between firstorder rewritings of ontologymediated queries
Optimizing queries in such scenarios is particularly challenging not only because of the large variety of possible query execution plans also because there is only limited access to statistics about instance data of remote sources
Optimizing queries in such scenarios is particularly challenging not only because of the large variety of possible query execution plans also because there is only limited access to statistics about schema data of remote sources
Optimizing queries in such scenarios is particularly challenging not only because of the large variety of possible query execution plans that correctly answer the query
Other families of use cases include the definition of functional properties
other stateoftheart systems like CQELS which runs on the Programming
other stateoftheart systems like CSPARQL which runs on the Programming
Our approach extends a recent tool  used for visualizing dense dynamic networks
Our approach extends Matrix Cubes used for visualizing dense dynamic networks
Our conduct an infobox completion experiment on complement 76498  more than 30percent of ENZH Wikipedia  pairs of corresponding articles with more than one attributevalue pairsKnowledge Graphs effectively capture explicit relational knowledge about individual entities
Our conduct an infobox completion experiment on EnglishChinese Wikipedia  more than 30percent of ENZH Wikipedia  pairs of corresponding articles with more than one attributevalue pairs
Our demonstrate the usefulness of Alignment Cubes by describing visual exploration scenarios showing how Alignment Cubes support common tasks
Our experimental results on realworld datasets show that this approach could be complemented with methodsOntologybased Data Access is gaining importance both practically
Our experimental results on realworld datasets show that this approach significantly outperforms the stateoftheart embedding approaches for crosslingual entity alignment
Our experimental results show that Odyssey produces query execution plans
Our experiments show execution time gains of at least 25 times on average
Our experiments using the FedBench benchmarkStructured scene descriptions of images are useful for the automatic processing and querying of large image databases
Our first identify use cases for ontology alignment evaluation
Our produce a reference alignment dataset for BabelNet that Our use to evaluate the quality of a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm
Our produce a reference alignment dataset for JeuxDeMots that Our use to evaluate the quality of a conversion algorithm for JeuxDeMots following the Ontolex model along with a word sense alignment algorithm
Our proposed approach finds 23923 new infobox attribute mappings between Chinese Wikipedia
Our proposed approach finds 23923 new infobox attribute mappings between English Wikipedia
Our solution combines and adjusts multilabel classification
Our solution combines and adjusts multitarget regression techniques
OWL is recognized as the de facto standard notation for ontology engineering
parameters using a ranking objective
performance bandwidth needs caching Several practical challenges
PREFER  clause that expresses
previous models which mainly rely on the lexical representations of words in the text
projections sharing common attributes in a  the language decidable with the same computational complexity as  knowledge base
proposed temporal query language that combines conjunctive queries with operators of propositional linear temporal logic
proposed temporal query language that extend to this
queries that are orders of magnitude more efficientThe Web of Data is an inherently distributed environment where ontologies are subject to constant changes
queries that are orders of magnitude the cost model we propose
query execution plans that are better in terms of data execution time than stateoftheart optimizers
query execution plans that are better in terms of data transfer time than stateoftheart optimizers
RDF graphs that is the foundation of Shape Expressions Language 20
real cases where a dedicated language can support maintenance of the code
real cases where a dedicated language can support modularity of the code
Reasoning is affected by constant changes
Recent approaches encode such knowledge by learning em beddings  separately in computational linguistics word embeddings are extracted from huge text corpora
Recent approaches encode such knowledge by learning em beddings  separately In computer vision visual object features are learned from large image collections
Recent approaches encode such knowledge by learning latent representations  separately in computational linguistics word embeddings are extracted from huge text corpora
Recent approaches encode such knowledge by learning latent representations  separately In computer vision visual object features are learned from large image collections
Recently vector similarities depending on bilingual topic models have achieved the stateoftheart performance on Crosslingual taxonomy alignment
recursion which poses limitations in practice
researchers have embarked in solving researchers mainly by experimentationWhen crises hit many flog to social media to share information related to the event
Results indicate that SemwidgQL is easier to learn more efficient
Results indicate that SemwidgQL is easier to learn preferred by learners
Results show that the proposed model consistently outperforms the baselinesKnowledge graphs are huge collections of primarily encyclopedic facts
Rule mining is commonly applied to discover patterns in Knowledge graphs
Running a federated query on all possible sources might not be very lucrative from a users point of view if extensive execution times or fees are involved in accessing all possible sources data
scene descriptions which are represented as a set of subject predicate object 
scene descriptions which are represented as a set of triples 
Second We use the judgements
semantics that represents the named entities in the text
Shapes can be combined using Boolean operators
Shapes can use possibly recursive references to other shapesvaluable sources of information for various applications ranging from Web search to Knowledge Base  KB  augmentation
Social media these posts tend to provide valuable reports on affected people donation offers help requests advice provision Automatically identifying the category of eg reports on affected individuals donations and volunteers  contained in these posts is vital for these posts efficient handling and consumption by concerned organisations
Social media these posts tend to provide valuable reports on affected people donation offers help requests advice provision Automatically identifying the category of eg reports on affected individuals donations and volunteers  contained in these posts is vital for these posts efficient handling and consumption by effected communities organisations
Social media these posts tend to provide valuable reports on affected people donation offers help requests advice provision Automatically identifying the category of information  contained in these posts is vital for these posts efficient handling and consumption by concerned organisations
Social media these posts tend to provide valuable reports on affected people donation offers help requests advice provision Automatically identifying the category of information  contained in these posts is vital for these posts efficient handling and consumption by effected communities organisations
So far most systems proposed are monolingual and rely on a set of hardcoded rules to interpret map most systems into a SPARQL query
So far most systems proposed are monolingual and rely on a set of hardcoded rules to interpret questions most systems into a SPARQL query
Standard translation techniques try to transform the user query into a union of conjunctive queries following the heuristic argument that UCQs can be efficiently evaluated by modern relational database engines
statistics that allow for a more accurate cost estimation for federated queries
statistics that therefore enables Odyssey to produce better query execution plans
Stream Processing engine that optimizes logical query plan according to the state of data streams
Stream Processing engine that optimizes logical query plan according to the state of data streams
Strider has been designed to guarantee important industrial properties such as acceptable latency
Strider has been designed to guarantee important industrial properties such as fault tolerance
Strider has been designed to guarantee important industrial properties such as high availability
Strider has been designed to guarantee important industrial properties such as high throughput
Strider has been designed to guarantee important industrial properties such as scalability
subject predicate object  where each triple consists of a pair of visual objects
subjectpropertyvalue triples which can be enhanced with references to add provenance information
subontologies that preserve all entailments over a given vocabulary
such updating mechanisms based on nonrecursive DatalogRDF data analysis that are not covered by standard reasoning tasks such as SPARQL query answering
support common tasks identified in the use casesIn modelling realworld knowledge there often arises a need to represent
tamperproof audit logs that provide proof of log manipulation and nonrepudiation
The ability to capitalize complex SPARQL filter expressions into extension functions are real cases
The ability to define dedicated aggregates are real cases
The ability to reuse dedicated aggregates are real cases
the baselines which consist of nonsemantic deep learning models
the baselines which consist of statistical deep learning models
the categories cooccurring words in correlations
the categories cooccurring words in text
the de facto approach for exploration of data in ecommerce has been recently adapted to the context of RDF
the description logic underlying OWL 2 description logic
The disjunctive skolem chase is albeit nonterminating  algorithm that can be used to solve conjunctive query answering over DL ontologies and programs with disjunctive existential rules
The disjunctive skolem chase is a sound
The efficiency as well as the correctness are our main ranking criteria
the existing standards dedicated to representation
The experimental results show that our introduced ranking method performs significantly better than several stateoftheart ranking solutions
The experiments presented in the present paper suggest that the interface to test whether a given Competency Question  is able to be answered by the ontology at a given stage of a given Competency Question  construction an approachthe SPARQL language that allows appending a  PREFER  clause
The experiments presented in the present paper suggest that the interface to test whether a given Competency Question  is able to be answered by the ontology at a given stage of CQ  construction an approach
The experiments presented in the present paper suggest that the interface to test whether CQ  is able to be answered by the ontology at a given stage of a given Competency Question  construction an approach
The experiments presented in the present paper suggest that the interface to test whether CQ  is able to be answered by the ontology at a given stage of CQ  construction an approach
the extent and significance of this dependency is not wellstudied yet
the extraction of relations from Wikipedia abstracts using the twelve largest language editions of Wikipedia
The features chosen for The machine
The features learning models were related to reference editing the triples referred to
The features learning models were related to reference the semantics of the triples the triples referred to
the first multilingual QALD pipeline that induces a model from training data for mapping a natural language question into logical form as probabilistic inference
the information extractedFaceted search is the de facto approach for exploration of data in ecommerce the de facto approach for exploration of data in ecommerce allows users to construct queries in an intuitive way without a prior knowledge of formal query languages
the judgements collected in the first stage to train a machine
The key implementation goal consists in efficiently handling massive incoming data streams
The key implementation goal consists supporting advanced data analytics services like anomaly detection
the knowledge regarding the vocabulary by allowing for a degree of semantic loss
The language defines a typing mechanism
The language includes a choice operator for the number of allowed occurrences of a property
The language includes an algebraic grouping operator for the number of allowed occurrences of a property
The language includes cardinality constraints for the number of allowed occurrences of a property
The Linked Data Fragment  framework has been proposed as a uniform view to explore the tradeoffs of consuming Linked Data
the logic LARS which extends Answer Set Programming for streams
the logic LARS which extends Answer Set Programming  for streams core
the logic LARS which extends Programming  for streams core
The machine learning models outperformed the baseline
The machine learning models were able to accurately predict nonauthoritative references
The machine learning models were able to accurately predict nonrelevant references
The Manchester OWL Syntax was developed as an alternative to symbolic description logic
the minimal entity context provided in Web tables to discover correspondences to the KB
the most relevant knowledge contained in large ontologies
The  nary description logic is able to encode more thoroughly conceptual data models such as everAn increasing number of use cases require a timely extraction of nontrivial knowledge from semantically annotated data streams especially on the Web and for the Internet of Things
The  nary description logic is able to encode more thoroughly conceptual data models such as ORM
The  nary description logic is able to encode more thoroughly conceptual data models such as UML
then detail how Our Alignment Cubes support interactive exploration of multiple ontology alignments
The obtained
The obtained results are comparable to those of state of the art approachesPrivacy audit logs are used to capture the actions of participants in a data sharing environment in order for auditors to check compliance with privacy policies
the Ontolex model along with a word sense alignment algorithm called JdMBabelizer that anchors JeuxDeMots senserefinements to synsets in the lemon edition of BabelNet
the Ontolex model along with a word sense alignment algorithm called JdMBabelizer that anchors JeuxDeMots senserefinements to synsets in the lemon edition of BabelNet exploits the richness of JeuxDeMots
the Ontolex model along with a word sense alignment algorithm called JdMBabelizer that anchors JeuxDeMots senserefinements to the Linguistic Linked Open Data cloud
the Ontolex model along with a word sense alignment algorithm called JdMBabelizer that anchors JeuxDeMots senserefinements to the Linguistic Linked Open Data cloud exploits the richness of JeuxDeMots
the Ontolex model along with a word sense alignment algorithm called JdMBabelizer that that Our make available to the community
the present paper explores whether Authoring Tests accurately represent the expectations of ontology authors
the problem of General Terminology Induction in OWL ie acquiring general expressive TBox axioms from an ABox 
the problem of General Terminology Induction in OWL ie acquiring general expressive TBox axioms from data 
the relational knowledge captured in Knowledge Graph
The results show that the measures capture different quality aspects
These approaches often suffer from the uneven quality of translations between languages
These changes impact a 24 7 available stream processing engine usually performance
These changes impact a 24 7 available stream processing engine usually reliability
These findings encourage further research towards capturing types of knowledgethe existing standards dedicated to querying
These guarantees are obtained by designing a 24 7 available stream processing engine usually architecture with stateoftheart Apache components such as Kafka
These guarantees are obtained by designing a 24 7 available stream processing engine usually architecture with stateoftheart Apache components such as Spark
These measures however do not reveal commonalities between alignments at a finergrained level such as
These measures however do not reveal differences between alignments at a finergrained level such as
These measures however do not reveal individual mappings
These measures however do not reveal regions
These measures however only provide an overall assessment of the quality of the alignments
the SERVICE keyword that allows one to allocate subqueries to servers
These surprising results suggest that the belief that The Manchester OWL Syntax is more effective than symbolic description logic at least for these types of task is unfounded
the SPARQL language that allows appending a  PREFER  clause
the SPARQL language that allows appending a  PREFER  clause
The task of answering natural language questions over RDF data consists of mapping a natural language question to an executable form  so that answers from a given KB can be extracted
The task of answering natural language questions over RDF data consists of mapping a natural language question to eg SPARQL so that answers from a given KB can be extracted
the typical queries performed on Linked DataThis paper investigates meta structures schemalevel graphs that abstract connectivity information among a set of entities in a knowledge graph
The Web of Data is an inherently distributed environment where ontologies are located in remote locations
This enables the application of expressive logicbased reasoning to large streamsVector space embeddings have been shown to perform well when using RDF data in data machine learning tasks
This is an essential issue if we want to be able to cope with modifications of data both at the ontology and at the source level while maintaining the independence of the data sources
This is especially the case for instance
this new LDF interface has this new LDF interface own particular properties regarding performance bandwidth needs arise
This opens the door to a wider range of stream reasoning use cases
This paper sets out to derive inferences from people
This paper sets out to test that belief from two perspectives by evaluating how accurately and quickly people understand the informational content of axioms
This particular fact makes it hard to select the best performing reasoner to handle a given ontology especially for novice users
this setting three inconsistencytolerant semantics
this shortcoming federated joincardinality approximation techniques
This yields two stateoftheart methods for computing all best excerpts which we evaluate over large biomedical ontologiesSPARQL query answering in ontologybased data access is carried out by translating into SQL queries over the data source
This yields two stateoftheart methods for computing all minimal modules excerpts which we evaluate over large biomedical ontologies
three inconsistencytolerant semantics that have been introduced for querying inconsistent description logic knowledge bases
To accommodate the semantic web vision SPARQL provides the SERVICE keyword
To address these needs we define a Linked Data script language on top of the SPARQL filter expression language
To address these needs we define LDScript 
To address this problem this paper presents an empirical study on how the distribution of ontological data on The Web of Data affects the outcome of reasoning
To address this shortcoming have been proposed to narrow down the number of possible allocations to a few most promising  onesAnswering queries over a federation of SPARQL endpoints requires combining data from more than one data source
To address this shortcoming have been proposed to narrow down the number of possible allocations to or resultsyielding  ones
To assess the applicability of SemwidgQL in real applications we analyzed its expressiveness based on a large corpus of observed Sparql queries showing that the language covers more than 90percent of the typical queries
Today there are only a few formal theoretical tools to help answer other practical questions
Today there are only a few formal theoretical tools to help answer these
To equip description logics for dealing with such ontologies we allow concept inclusions to express constraints on annotations
To equip description logics for dealing with such ontologies we enrich description logic concepts and roles with finite sets of attributevalue pairs called annotations
To find the best translation we devise a cost model together with a novel cardinality estimation
To overcome these challenges most federated query engines rely on dynamic programming strategies to produce optimal plans
To overcome these challenges most federated query engines rely on heuristics to reduce the space of possible query execution plans
To tackle this challenge in federated knowledge bases we propose a fully automated approach for computing trust values at different levels of granularity
To this end certain small number of axioms that best capture the knowledge  have been proposed
To this end excerpts  have been proposed
To this end minimal modules  have been proposed
To this end subontologies  have been proposed
triples  where each triple consists of a pair of visual objects
triples which have never been observed in the training data
two knowledge bases that represent the same realworld object
typical subsets can be referenced efficiently with optimized persistenceThe task of answering natural language questions over RDF data has received wide interest in recent years in particular in the context of the series of QALD benchmarks
typical subsets can be referenced efficiently with optimized precision
typical subsets can be referenced efficiently with optimized reliability
typical subsets can be retrieved efficiently with optimized persistence
typical subsets can be retrieved efficiently with optimized precision
typical subsets can be retrieved efficiently with optimized reliability
typical subsets that researchers use for the total size and overhead of evolving scientific datasets analyses
Understanding the quality of Wikidata is key to Wikidata widespread adoption as a knowledge resource
unlike in traditional association rule mining Knowledge graphs provide a setting with a high degree of incompleteness
Unlike previous models the proposed model integrates an additional layer of semantics into a deep CNN network
Unlike previous models the proposed model integrates an additional layer of semantics into a wide CNN network
Vector space embeddings have been shown to perform well when using RDF data in data mining
visual objects which appear in the image
we address the literature for the entire class of conjunctive SPARQL queries aka Basic Graph Pattern Queries
We also provide a benchmark and perform an evaluation with different implementations and approachesWikidata is a collaborativelyedited knowledge graph Wikidata expresses knowledge in the form of subjectpropertyvalue triples
we also provide a practical implementation of such
we also provide empirical evidence that optimizations specific to SPREFQL improve runtime efficiency by comparison to the usually applied optimizations on the equivalent standard SPARQL queryWe present proof of soundness for an expressive schema language for RDF graphs
we also provide experimental validation of the scalability of we solution using an existing Linked Data privacy audit log modelFinding the commonalities between descriptions of knowledge is a foundational reasoning problem of Machine Learning
we also show that the conditional keys we we can improve the quality of entity linking by up to 47percent pointsEntity alignment is the task of finding entities in two knowledge bases
We analyse one aspect of Wikidata quality provenance in terms of authoritativeness of Wikidata external references
We analyse one aspect of Wikidata quality provenance in terms of relevance of Wikidata external references
We apply multiple stateoftheart link prediction methods
Web tables constitute valuable sources of information for various applications
We combine a standard visual model for object detection
We combined approach achieves superior performance compared to the stateoftheart method from the Stanford computer vision groupEnsuring access to the most relevant knowledge has been identified as an important challenge
We compare We capability for visual relationship detection
We consider a recently proposed temporal query language
We consider the case where the actual query is a conjunctive query
We consider the case where the ontology is formulated in the description logic
we cover  mathcal SROIQ 
we cover the description logic
We define novel measures
We demonstrated in previous work how We can establish reliable identifiers for nanopublications thereof
We demonstrated in previous work how We can establish reliable identifiers for sets thereof
We demonstrated in previous work how We can establish verifiable identifiers for nanopublications thereof
We demonstrated in previous work how We can establish verifiable identifiers for sets thereof
We demonstrate here that this significant overhead disappears once We allow users to deal with the specific subsets users need
We demonstrate here that this significant overhead disappears once We take the version history of nanopublication datasets into account calculate incremental updates
We demonstrate the extraction of relations from Wikipedia abstracts
we describe a tractable fragment based on mathcal EL 
we describe a tractable fragment based on the lightweight description logic 
We developed SemwidgQL to enable nonspecialist developers to integrate Linked Data into standard web applications
We developed SemwidgQL to enable nonspecialist developers to integrate other semantic data sources into standard web applications
We developed SemwidgQL to enable web authors to integrate Linked Data into standard web applications
We developed SemwidgQL to enable web authors to integrate other semantic data sources into standard web applications
We developed SemwidgQL to facilitate the formulation of Rdf queries
We devise efficient automatabased algorithms
We empirically evaluate the quality measures on two corpora of ontologies and run a case study with a domain expert to gain insight into applicability of the measures and acquired general expressive TBox axioms
We empirical results show that a joined concept representation provides measurable benefits for semantic similarity benchmarks since a joined concept representation shows a higher correlation with the human notion of similarity than uni or bimodal representations and entitytype prediction tasks since a joined concept representation clearly outperforms plain Knowledge Graph embeddings
We evaluate We approach on a large distributed dataset from the domain of library scienceLargescale knowledge graphs such as DBpedia can be enhanced by relation extraction from text using the data in the knowledge graph as training data
we experimental evaluation is conducted using two existing benchmark data sets in addition to a new largescale benchmark
We experimental results on the recently published Stanford Visual Relationship a challenging real world dataset show that the integration of a statistical semantic model can significantly improve visual relationship detection
We experimental results on the recently published Stanford Visual Relationship dataset  show that the integration of a statistical semantic model can significantly improve visual relationship detection
we experiments confirm that alternatives to the best translation might produce hence is well suited to select the best translation
we experiments confirm that alternatives to the best translation might produce queries is faithful to the actual query evaluation cost
We focus lies on developing methods
We follow a twostaged approach
We formalize the meta structure computation problem
We furthermore complete the picture for the consistent caseRealtime processing of data streams is becoming a common task in Internet of Things scenarios
we generates a recommendation in the form of reasoner ranking
We highlight eg on a single machine machine up to 60x gain on throughput compared to a throughput of 31 million triplessecond on a 9 machines cluster a major breakthrough in this systems category  of Strider on realworld sets
We highlight eg on a single machine machine up to 60x gain on throughput compared to a throughput of 31 million triplessecond on a 9 machines cluster a major breakthrough in this systems category  of Strider on synthetic data sets
We highlight eg on a single machine machine up to 60x gain on throughput compared to stateoftheart systems on a 9 machines cluster a major breakthrough in this systems category  of Strider on realworld sets
We highlight eg on a single machine machine up to 60x gain on throughput compared to stateoftheart systems on a 9 machines cluster a major breakthrough in this systems category  of Strider on synthetic data setsWikipedia infoboxes are thus a very rich source of structured knowledge
We highlight the efficiency  of Strider on realworld sets
We highlight the efficiency  of Strider on synthetic data sets
we identify cases where this increased expressivity can be achieved without incurring increased complexity of reasoning
weighted semanticlexical relations particularly the inhibition relation between senses that are specific to JeuxDeMots
We implemented We machineries in a visual tool
we include an evaluation
We introduce a meta structurebased relevance measure
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and global objectification of able to express inclusion dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and global objectification of external uniqueness dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and global objectification of key dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and global objectification of relations dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and local objectification of able to express inclusion dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and local objectification of external uniqueness dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and local objectification of functional dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and local objectification of key dependencies
We introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and local objectification of relations dependencies
We investigate their complexity for DLLite  temporal knowledge bases
We investigate their complexity for  mathcal R  temporal knowledge bases
We investigate the potential of complementing the relational knowledge embeddings with knowledge from text documents and images by learning a shared latent representation
We investigate the problem of General Terminology Induction in OWL ie
We measured both objective performance to a set of questionnaire items
We measured both subjective responses to a set of questionnaire items
We model builds on factor graphs
We model differences between entities as SPARQL queries satisfying certain additional properties and propose algorithms for computing certain additional propertiesThe federation of different data sources gained increasing attention due to the continuously growing amount of data
We model similarities between entities as SPARQL queries satisfying certain additional properties and propose algorithms for computing certain additional properties
We performed a user study
We present a formal semantics for an expressive schema language for RDF graphs
We present a formal semantics for shapes schemas
We present algorithms for computing subsumption justifications based on a simulation notion developed for the problem of deciding the logical difference between ontologies
We present proof of soundness for shapes schemas
We present the first multilingual QALD pipeline
We propose a hybrid adaptive distributed RDF Stream Processing engine
We propose an informed datadriven algorithm that constructs class expressions for general expressive TBox axioms in guarantees completeness
We propose an informed datadriven algorithm that constructs class expressions for general expressive TBox axioms in OWL completeness
We propose entityattribute factor graph to consider not only individual features
We propose entityattribute factor graph to consider not only the correlations among attribute pairs
We propose Laser a new reasoner
We propose Strider
We provide the formal grammar of the Natural Semantics inference rules of the semantics of the language
We provide the formal grammar of the syntax inference rules of the semantics of the language
We rely on approximate inference techniques Markov Chain Monte Carlo methods in particular Rank to update parameters
We rely on approximate inference techniques Markov Chain Monte Carlo methods in Sample Rank to update parameters
We report on an extensive experimental evaluation
we results show that we novel lookupbased method outperforms stateoftheart lookupbased methods the semantic embeddings method outperforms lookupbased methods in one benchmark data and the lack of a rich schema in Web tables can limit the ability of ontology matching tools in performing highquality table annotation
We revisit this wellestablished problem in the SPARQL query language for RDF graphs
We show how a simple syntactic restriction on the appearance of projections makes reasoning in the language decidable with the same computational complexity as
We show how subsumption justifications can be used to compute best excerpts by additionally employing a partial MaxSAT solver
We show how subsumption justifications can be used to obtain minimal modules
We show how the combination of a statistical semantic model can improve on the task of mapping images to images
We show how the combination of a visual model can improve on the task of mapping images to images
We show that rewritings of such ontologymediated queries can be efficiently computed in practice in a sound
We show that rewritings of such ontologymediated queries can be efficiently computed in practice in complete way
We show that the total size and overhead of evolving scientific datasets is reduced
we show that this may lead to even undecidability
we show that this may lead to increased complexity
we show that updating data both at the ontology level is firstorder rewritable
we show that updating data both at the source level is firstorder rewritable
we show that we method can scale to large knowledge bases of millions of facts
We study to what degree datasets depend on external ontologies
We study to what extent the inclusion of additional ontological information via IRI dereferencing leads to new derivations
We study to what extent the inclusion of imports directive to the input datasets leads to new derivationsWe introduce  the language decidable with the same computational complexity as  an extension of the nary propositionally closed description logic  the language decidable with the same computational complexity as  to deal with attributelabelled tuples  generalising the positional notation  projections of relations and global objectification of functional dependencies
We study to what extent the inclusion of the owl leads to new derivations
When crises hit many flog to social media to consume information related to the event
When facing entities in two knowledge bases in different natural languages conventional crosslingual entity alignment methods rely on machine translation to eliminate the language barriers
While most existing approaches use languagespecific methods  usually for English  we present a languageagnostic approach
While recent embeddingbased techniques do not need machine translation for crosslingual entity alignment a significant number of attributes remain largely unexplored
While recent embeddingbased techniques encode entities in the entities in two knowledge bases a significant number of attributes remain largely unexplored
While recent embeddingbased techniques encode relationships in the entities in two knowledge bases a significant number of attributes remain largely unexplored
Wikipedia infoboxes contain information about article entities in the form of attributevalue pairs
8 effective features for cross lingual infobox attribute matching containing categories templates attribute labels
8 effective features for cross lingual infobox attribute matching containing categories templates attribute values
 61percent  of the references evaluated were authoritative
 61percent  of the references evaluated were relevant
31576 between English based on no more than six thousand existing matched infobox attributes
31576 between French based on no more than six thousand existing matched infobox attributes
