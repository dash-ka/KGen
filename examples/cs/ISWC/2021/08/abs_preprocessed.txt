incorporating external knowledge to visual question answering has become a vital practical need
existing methods mostly adopt pipeline approaches with different components for knowledge matching and extraction feature learning however such pipeline approaches suffer when some component does not perform well which leads to error cascading
existing methods mostly adopt pipeline approaches with different components for knowledge matching and extraction feature learning however such pipeline approaches suffer when some component does not perform well which leads to poor overall performance
furthermore the majority of existing approaches ignore the answer bias issue many answers may have never appeared during ie unseen answers  in realword application
furthermore the majority of existing approaches ignore the answer bias issue many answers may have never appeared during training  in realword application
visual question answering
a zeroshot visual question answering algorithm using a maskbased learning mechanism for better
to bridge these gaps in this paper we propose a zeroshot visual question answering algorithm
a zeroshot visual question answering algorithm using knowledge graph for better
better incorporating external knowledge
to bridge these gaps in this paper we propose present new answerbased zeroshot visual question splits for the fvqa dataset
zeroshot visual question answering with unseen answers
experiments show that our method can achieve stateoftheart performance in zeroshot visual question meanwhile dramatically augment existing endtoend models on the normal fvqa task