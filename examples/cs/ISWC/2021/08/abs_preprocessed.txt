Incorporating external knowledge to Visual Question Answering has become a vital practical need
Existing methods mostly adopt pipeline approaches with different components for knowledge matching and extraction feature learning However such pipeline approaches suffer when some component does not perform well which leads to poor overall performance
Existing methods mostly adopt pipeline approaches with different components for knowledge matching and extraction feature learning However such pipeline approaches suffer when some component does not perform well which leads to error cascading
Furthermore the majority of existing approaches ignore the answer bias issue many answers may have never appeared during training  in realword application
Furthermore the majority of existing approaches ignore the answer bias issue many answers may have never appeared during ie unseen answers  in realword application
better incorporating external knowledge
a Zeroshot Visual Question Answering algorithm using a maskbased learning mechanism for better
Visual Question Answering
To bridge these gaps in this paper we propose present new answerbased Zeroshot Visual Question splits for the FVQA dataset
To bridge these gaps in this paper we propose a Zeroshot Visual Question Answering algorithm
a Zeroshot Visual Question Answering algorithm using knowledge graph for better
Zeroshot Visual Question Answering with unseen answers
Experiments show that our method can achieve stateoftheart performance in Zeroshot Visual Question meanwhile dramatically augment existing endtoend models on the normal FVQA task