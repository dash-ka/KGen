traditional computer vision approaches based on neural networks
traditional computer vision approaches are typically trained on a large amount of image data
by minimizing the crossentropy loss between a given class label the neural networks visual embedding space are learned to fulfill a given task
by minimizing the crossentropy loss between a prediction the neural networks are learned to fulfill a given task
by minimizing the crossentropy loss between a given class label the neural networks are learned to fulfill a given task
by minimizing the crossentropy loss between a prediction the neural networks visual embedding space are learned to fulfill a given task
however due to the sole dependence on the image data distribution of the training domain these models tend to fail when applied to a target domain
a target domain that differs from these models source domain
the training using imagedatainvariant auxiliary knowledge
to learn a more robust neural networks to domain shifts we propose the knowledge graph neural network a neurosymbolic approach
a neurosymbolic approach that supervises the training
respective concepts relationships which is then transformed into a dense vector representation via an embedding method
the auxiliary knowledge is first encoded in a knowledge graph with respective concepts
the auxiliary knowledge is first encoded in a knowledge graph with respective concepts relationships
respective concepts which is then transformed into a dense vector representation via an embedding method
using a contrastive loss function neural network learns to adapt its visual embedding space
using a contrastive loss function neural network learns to its weights according to the imagedata invariant knowledge graph embedding space
classification using road sign recognition datasets from china
classification using the miniimagenet dataset
we evaluate neural network on visual transfer
visual transfer learning tasks for classification
classification using road sign recognition datasets from germany
classification using its derivatives
the results show that a visual model outperforms a model
particular when the domain gap increases
a visual model trained with a knowledge graph as a trainer
a model trained with crossentropy in all experiments in particular
besides stronger robustness to these neural network adapts to multiple datasets and classes without suffering heavily from catastrophic
besides better performance
catastrophic forgetting
besides stronger robustness to domain shifts to multiple datasets and classes without suffering heavily from catastrophic