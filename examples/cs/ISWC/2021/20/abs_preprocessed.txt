Traditional computer vision approaches based on neural networks
Traditional computer vision approaches are typically trained on a large amount of image data
By minimizing the crossentropy loss between a prediction the neural networks are learned to fulfill a given task
By minimizing the crossentropy loss between a given class label the neural networks are learned to fulfill a given task
By minimizing the crossentropy loss between a prediction the neural networks visual embedding space are learned to fulfill a given task
By minimizing the crossentropy loss between a given class label the neural networks visual embedding space are learned to fulfill a given task
However due to the sole dependence on the image data distribution of the training domain these models tend to fail when applied to a target domain
a target domain that differs from these models source domain
a neurosymbolic approach that supervises the training
To learn a more robust neural networks to domain shifts we propose the knowledge graph neural network a neurosymbolic approach
the training using imagedatainvariant auxiliary knowledge
respective concepts relationships which is then transformed into a dense vector representation via an embedding method
respective concepts which is then transformed into a dense vector representation via an embedding method
The auxiliary knowledge is first encoded in a knowledge graph with respective concepts
The auxiliary knowledge is first encoded in a knowledge graph with respective concepts relationships
Using a contrastive loss function neural network learns to its weights according to the imagedata invariant knowledge graph embedding space
Using a contrastive loss function neural network learns to adapt its visual embedding space
We evaluate neural network on visual transfer
classification using its derivatives
classification using road sign recognition datasets from China
classification using road sign recognition datasets from Germany
classification using the miniImageNet dataset
visual transfer learning tasks for classification
particular when the domain gap increases
a model trained with crossentropy in all experiments in particular
The results show that a visual model outperforms a model
a visual model trained with a knowledge graph as a trainer
Besides stronger robustness to domain shifts to multiple datasets and classes without suffering heavily from catastrophic
Besides stronger robustness to these neural network adapts to multiple datasets and classes without suffering heavily from catastrophic
Besides better performance
catastrophic forgetting