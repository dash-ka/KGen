Visual Question Answering is concerned with answering freeform questions about an image
Since an image requires a deep semantic understanding of the question to associate an image with various objects an image requires multimodal reasoning from natural language processing
Since an image requires a deep linguistic understanding of the question to associate an image with various objects an image is an ambitious task
Since an image requires a deep linguistic understanding of the ability to associate an image with various objects an image is an ambitious task
Since an image requires a deep semantic understanding of the ability to associate an image with various objects an image requires multimodal reasoning from both computer vision
Since an image requires a deep linguistic understanding of the question to associate an image with various objects an image requires multimodal reasoning from both computer vision
Since an image requires a deep semantic understanding of the ability to associate an image with various objects an image is an ambitious task
Since an image requires a deep semantic understanding of the question to associate an image with various objects an image requires multimodal reasoning from both computer vision
Since an image requires a deep semantic understanding of the question to associate an image with various objects an image is an ambitious task
Since an image requires a deep linguistic understanding of the question to associate an image with various objects an image requires multimodal reasoning from natural language processing
Since an image requires a deep linguistic understanding of the ability to associate an image with various objects an image requires multimodal reasoning from both computer vision
Since an image requires a deep linguistic understanding of the ability to associate an image with various objects an image requires multimodal reasoning from natural language processing
various objects that are present in the image
Since an image requires a deep semantic understanding of the ability to associate an image with various objects an image requires multimodal reasoning from natural language processing
a novel method that approaches the task by integrating knowledge graph reasoning
a novel method that approaches the task by integrating natural language processing techniques
a novel method that approaches the task by integrating computer vision
We propose Graphhopper a novel method
Concretely our method is based on performing contextdriven sequential reasoning based on the scene entities semantic relationships
Concretely our method is based on performing contextdriven sequential reasoning based on the scene entities spatial relationships
Concretely our method is based on performing contextdriven sequential reasoning based on the scene entities
a scene graph that describes their attributes
As a first step we derive a scene graph
a scene graph that describes their mutual relationships
a scene graph that describes the objects in the image
a reinforcement learning agent
Subsequently a reinforcement is trained to autonomously navigate in a multihop manner over the extracted scene graph to generate reasoning paths
reasoning paths which are the basis for deriving answers
We conduct an experimental study on the challenging dataset GQA based on both automatically generated scene graphs
We conduct an experimental study on the challenging dataset GQA based on both manually curated
We results show that We keep up with human performance on manually curated scene graphs
Moreover We find that Graphhopper outperforms another stateoftheart scene graph reasoning model on both generated scene graphs by a significant margin
Moreover We find that Graphhopper outperforms another stateoftheart scene graph reasoning model on both manually curated