owl 2 rl was standardized as a less expressive subset of owl 2
owl 2 rl was standardized as a less scalable subset of owl 2
owl 2 that allows a forwardchaining implementation
2  efficiently update inference for additions remains a challenge
an enterprisescale forwardchaining based inference engine
however
building an enterprisescale forwardchaining that can 1  take advantage of modern multicore computer architectures
in this paper we present an owl 2 rl inference engine implemented inside the oracle database system using novel techniques for parallel processing
parallel processing that can readily scale on multicore machines and clusters
additionally we have added support for efficient incremental maintenance of the inferred graph after triple additions
a hybrid inmemorydisk based approach to efficiently compute compact equivalence closures
finally to handle sameas relationships present in semantic web datasets we have provided a hybrid inmemorydisk
finally to handle the increasing number of owl  we have provided a hybrid inmemorydisk
we have done extensive testing to evaluate these new techniques the test results demonstrate that we inference engine is capable of performing efficient inference over ontologies with billions of triples
triples using a modest hardware configuration