OWL 2 RL was standardized as a less expressive subset of OWL 2
OWL 2 that allows a forwardchaining implementation
OWL 2 RL was standardized as a less scalable subset of OWL 2
building an enterprisescale forwardchaining that can 1  take advantage of modern multicore computer architectures
2  efficiently update inference for additions remains a challenge
However
an enterprisescale forwardchaining based inference engine
In this paper we present an OWL 2 RL inference engine implemented inside the Oracle database system using novel techniques for parallel processing
parallel processing that can readily scale on multicore machines and clusters
Additionally we have added support for efficient incremental maintenance of the inferred graph after triple additions
Finally to handle sameAs relationships present in Semantic Web datasets we have provided a hybrid inmemorydisk
Finally to handle the increasing number of owl  we have provided a hybrid inmemorydisk
a hybrid inmemorydisk based approach to efficiently compute compact equivalence closures
we have done extensive testing to evaluate these new techniques the test results demonstrate that we inference engine is capable of performing efficient inference over ontologies with billions of triples
triples using a modest hardware configuration