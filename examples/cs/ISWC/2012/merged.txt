a classification methodology for federated SPARQL queries can be used by developers of federated querying approaches to compose a set of test benchmarks
a dynamic algorithm are presented which use The costs to find near optimal execution orders for the atoms of a query
a dynamic algorithm are presented which use The costs to find optimal optimal execution orders for the atoms of a query
a golden standard that has been built online by a group of selected users
a golden standard that has been evaluated in a user studyModelling various contexts of users is important to enable personalised selection of Web APIs in directories such as Programmable Web
a heuristic called SPLODGE for automatic generation of benchmark queries
a hybrid query execution approach that returns fresher results from a broader range of sources vs the centralised scenario
A key issue in semantic reasoning is the computational complexity of inference tasks on expressive ontology languages such as OWL DL
A key problem in instance matching of types however is scaling the matching algorithm to handle types with a large number of instances
A key problem in instance matching of types however is scaling the matching algorithm to match a large number of type pairs
a knowledge base that hosts this structured information about domain entities
a largescale relation extraction  system detects both binary relations
a largescale relation extraction  system detects both nary relations
a largescale relation extraction  system which learns grammarbased RE rules from the Web by utilizing large numbers of relation instances as seed
a largescale relation extraction  system which learns grammarbased RE rules from the Web by utilizing large numbers of relation instances as seed
algorithm optimized for native RDF stores
algorithm that replicates tuples
all the matching eg thousands  even if eg ten  are requested
all the matching eg thousands  even if only a limited number k  are requested
all the matching solutions  even if eg ten  are requested
all the matching solutions  even if only a limited number k  are requested
Already a strong combination of DLLite with the lowresolution calculus RCC3 does not allow for FOL rewritabilityA key issue in semantic reasoning is the computational complexity of inference tasks on expressive ontology languages such as OWL 2 DL
Although several lossless approaches have been developed for this exact purpose Timeefficient algorithms do not offer theoretical guarantees with respect to Timeefficient algorithms performance
a materializethensort processing scheme that computes all the
a method relying on both external knowledge to detect temporal relations between research areas
a method relying on the ability to detect temporal relations between research areasthe main tasks when creating knowledge bases
a model abstraction built by an OWL reasoner
a music listening history
an algorithm has been tuned against a golden standard
an approach that fills this gap by a  predicting follower edges within a directed social network by exploiting concept graphs
an approach that fills this gap by a  significantly outperforming a random baseline
and even more so PhD students  evolve slowly
an enduser study to evaluate its acceptance by discusses the lessons learned about both our methodology of exposing nonexperts to semantic enrichment
an enduser study to evaluate its acceptance by discusses the lessons learned about both the semantic enrichment process of exposing nonexperts to semantic enrichment
an enduser study to evaluate its acceptance by presents the results of an enduser study to evaluate its acceptance by
an enduser study to evaluate its acceptance by presents the results of usability for nonexpert users
a new all other geospatial RDF store that supports the state of the art semantic geospatial query languages stSPARQL
a new approach empowers end users to rapidly model existing servicestasks that arise when trying to discover links on the Web of Data
a new approach empowers end users to use end users to consume linked data
a new approach empowers end users to use end users to produce linked data
a new approach that allows domain experts to rapidly create semantic models of services by demonstration in an interactive webbased interface
a new approach that allows domain experts to rapidly create semantic models of services by demonstration in an interactive webbased interface
a new expressive vocabulary that includes lifting rules
a new expressive vocabulary that includes lowering rules
a new RDF store that supports the state of the art
an extended SPARQL algebra that treats order as a first class citizen enabling efficient splitandinterleave processing schemes
An increasing amount of data is published on the Web according to the Linked Data paradigm
an individual clustering approach that allows for computing the cost functions based on one individual sample from a cluster
an issue which has only been partially addressed
an online service which includes the specifications for consuming
an ontology which are performancedegrading for a given reasoner
a novel classification technique that combines an efficient reasoner for a given fragment in such a way that the bulk of the workload is assigned to the latter
a novel classification technique that combines an OWL 2 reasoner for a given fragment in such a way that the bulk of the workload is assigned to the latter
a novel configurable graphbased method for selection of Web APIs allows users to get more control over users preferences and recommended Web APIs while users can exploit information about users social links and preferences
an RDF graph which is not identified by a URI
a restaurant visit history gathered from a gourmet guide site
a rule system that is complete for many OWL RL ontologies
a rule system that is sound for many OWL RL ontologies
a score for the confidence
a series of The experiments using ontologies from the Ontology Alignment Evaluation
a series of The experiments using reference alignments from the Ontology Alignment Evaluation
a service specification using a new expressive vocabulary
A static are presented which use The costs to find near optimal execution orders for the atoms of a query
A static are presented which use The costs to find optimal optimal execution orders for the atoms of a query
As the reallife provenance records can likely cover thousands of data items one of the pressing challenges becomes development of formal frameworks for thousands of data items automated verification
As the reallife provenance records can likely cover thousands of data items one of the pressing challenges becomes development of formal frameworks for thousands of derivation steps automated verification
As the reallife provenance records can likely cover thousands of derivation steps one of the pressing challenges becomes development of formal frameworks for thousands of data items automated verification
As the reallife provenance records can likely cover thousands of derivation steps one of the pressing challenges becomes development of formal frameworks for thousands of derivation steps automated verificationAn increasing amount of data is consumed on the Web according to the Linked Data paradigm
a subquery for which the have good fresh coverage
a subquery that should instead be run live
a sufficiently expressive query language allowing for FOL rewritability
a supervised generative topic model called feature latent Dirichlet allocation
a supervised generative topic model called feature latent Dirichlet allocation 
a supervised generative topic model called feature latent Dirichlet allocation 
a synthetic benchmark known to generate complex queries
a system is designed to work efficiently on complex queries with many selfjoins over huge datasets avoiding job failures even in the case of joins with unexpected highvalue skew
a system that incrementally executes them on a Hadoop cluster
a system that incrementally executes them on a Hadoop cluster
a system that incrementally executes them on a Hadoop cluster
a system that incrementally translates SPARQL queries to Pig Latin
a system that incrementally translates SPARQL queries to Pig Latin
a system that incrementally translates SPARQL queries to Pig Latin
a system that incrementally translates SPARQL queries to Pig Latinlinked open data obtained from SPARQL
Automatic annotation is not of sufficient quality to enable focused search and retrieval
A variant of distant supervision learns several relations in parallel
a way that allows for finegrained parallelism
a Web API directory graph that captures relationships such as categories
a Web API directory graph that captures relationships such as developers
a Web API directory graph that captures relationships such as mashups
a Web API directory graph that captures relationships such as Web APIs
a Yahoo case of data analysis using RDF data crawled from the web
Based on an abstract definition of temporal information we conduct experiments to evaluate the availability of such information using Linked Data at large scale from the 2011 Billion Triple Challenge  BTC  dataset
benchmark queries that is based on a classification methodology for federated SPARQL queries
benchmark queries that takes into account the number of several complexity parameters
benchmark queries that takes into account the number of sources to be queried
both machine learning methods
building such models is time consuming
building such models requires specialized knowledge of RDF
building such models requires specialized knowledge of SPARQL
careful optimizations that take into account intricacies of modern parallel hardwareExisting approaches for link prediction in the domain of network science exploit a networks topology to predict future connections by inducing links
centralised approaches that can efficiently answer queries over data
changes which are specific to  thus directly affect 
Checking entailment for arbitrary OWL RL class subsumptions is coNPhard
classes that are extracted from a model abstraction
Classification is a fundamental reasoning task in ontology design
classification time using approximate reasoning based on hot spots
combined geothematic logics that provide a sufficiently expressive query language
compare the variously approximated change sets over a series of versions of the NCI Thesaurus
complex attributes or resources whose identity is unknown
computing entailed subclass relationships
concepts meaning altered by a change
constraints that eliminates constraints
constraints that eliminates their ability to infer new facts without requiring the data to be complete ability to infer new facts without requiring the available data to be complete
constraints that reduces constraints
constraints that reduces their ability to infer new facts without requiring the data to be complete ability to infer new facts without requiring the available data to be complete
Currently relationships between users are not clearly understood by existing selection approaches
Currently relationships between users are not clearly utilized by existing selection approaches
Currently relationships between Web APIs are not clearly understood by existing selection approaches
Currently relationships between Web APIs are not clearly utilized by existing selection approaches
data cached from parts of the Web
data that can be exploited to speed up query processing
data that can effectively help improving classification performance
decentralised approaches that can provide fresher results over the entire Web at the cost of slower response times
deducing new facts may be undesirable
deduction rules which operate directly on the RDF syntax of OWL
DeFacto aims to provide an effective way of validating facts by supplying the user with relevant excerpts of webpages DeFacto has in the correctness of the input fact
DeFacto aims to provide DeFacto has in the correctness of the input factThis paper presents an approach to automatically extract relationships from textual documents
DeFacto aims to provide useful additional information DeFacto has in the correctness of the input fact
Despite the rise in popularity of AttentionInformation Networks  no existing work has attempted to exploit the semantics of published content when predicting network links
Despite the rise in popularity of ie microblogging platforms  no existing work has attempted to exploit the semantics of published content when predicting network links
Despite the rise in popularity of the production of content within such platforms no existing work has attempted to exploit the semantics of published content when predicting network links
Detecting much less understanding is challenging for ontology engineers due in part to the possibility of complex nonlocal logic effects of axiom changes
determining the alignments between concepts in refining existing ontologies thus increasing the interoperability in the Linked Open Data CloudWe present Tipalo
Determining trust of data available in the Semantic Web is fundamental for applications in particular for linked open data endpoints
Determining trust of data available in the Semantic Web is fundamental for users in particular for linked open data endpoints
Different from previous work on parallel RDFS reasoning we assume a shared memory architecture
domain knowledge that is used to augment
domain knowledge that is used to train the algorithms
domain knowledge that is used to validate
Due to the high worst case complexity of the core reasoning problem for the expressive profiles of OWL 2 ontology engineers are confused by the performance behaviour of reasoners on ontology engineers ontologies
duplicates that naturally occur in RDFS reasoning and develop strategies towards RDFS reasoning mitigation exploiting all levels of our architecture
each extracted eg iPhone  from tweets
each extracted entity  from tweets
efficient splitandinterleave processing schemes that can be adopted to improve the performance of topk SPARQL queries
EL that does not require such an extreme prioritization
EL that does not require such an extreme prioritization with existing approaches with encouraging results
Emerging solutions are using ontologies for expressive representation of concepts in perception
Emerging solutions are using ontologies for expressive representation of concepts in the domain of sensing
empirically compare a novel technique for EL
Employing an efficient dependency parser the average run time for each relation is only 19 hours
epochs that are dominated by interests similar to the current interests of the active user
equivalent instances that refer to the same realworld object
Even very experienced modellers with a sophisticated grasp of reasoning algorithms do not have a good mental model of reasoner performance behaviour
Existing approaches for link prediction in the domain of network science exploit a networks topology to predict future connections by assessing existing edges and connections
Experiments conducted with an open source implementation of a SPARQLRANK query engine based on ARQ
Experiments show that the evaluation of topk queries can be sped up by orders of magnitudeRecent developments in hardware have shown an increase in parallelism as opposed to clock rates
Extensive experiments on our Web APIs documentation dataset shows that a supervised generative topic model outperforms
Extensive experiments on our Web APIs documentation dataset shows that a supervised generative topic model outperforms three strong supervised baselines
external knowledge which is drawn from a number of resources
feature latent Dirichlet allocation not only also provides a mechanism for incorporating side information such as labelled features automatically learned from data
feature latent Dirichlet allocation not only captures the correspondence between data automatically learned from data
feature latent Dirichlet allocation not only captures the correspondence between the associated class labels automatically learned from data
feature latent Dirichlet allocation  which offers a generic probabilistic framework for automatic detection of Web APIs
feature latent Dirichlet allocation  which offers a generic probabilistic framework for automatic detection of Web APIs
feature latent Dirichlet allocation which offers a generic probabilistic framework for automatic detection of Web APIs
Finally the system saves a service specification
Finally We evaluate different hybrid query plans
Finally We evaluate split positions in a realworld setup
Finally We work is complemented with a functional evaluation on three representative strRS engines CQELS
Finally We work is complemented with a functional evaluation on three representative strRS engines CSPARQL
Finally We work is complemented with a functional evaluation on three representative strRS engines SPARQLStream
First it is often quite difficult to even determine which concepts have had concepts
Firstly we learn various classifiers
First order logic  rewritability is a desirable feature for query answering over geothematic ontologies because in most geoprocessing scenarios one has to cope with large data volumes
First the user provides examples of the service request URLs
First we divide the users transactions into epochs ie time periods
First we identify epochs
Focusing in particular on temporal information we investigate the approaches performing both a qualitative analysis
Focusing in particular on temporal information we investigate the approaches performing both a quantitative
Focusing in particular on temporal information we investigate the approaches proposing guidelines for data consumers
Focusing in particular on temporal information we investigate the approaches proposing guidelines for publishers
Focusing in particular on the representation of temporal metainformation we investigate the approaches performing both a qualitative analysis
Focusing in particular on the representation of temporal metainformation we investigate the approaches performing both a quantitative
Focusing in particular on the representation of temporal metainformation we investigate the approaches proposing guidelines for data consumers
Focusing in particular on the representation of temporal metainformation we investigate the approaches proposing guidelines for publishers
For a given pair of ontologies CrowdMap a model to acquire such human contributions via microtask crowdsourcing translates the alignment problem into microtasks
For a number of years now we have seen the emergence of repositories of research data conceptualized according to a variety of ontologies
For each we add eg  Apple product   as an additional feature
For each we add iPhone semantic concept  as an additional feature
For each we measure the correlation of the representative concept with negativepositive sentiment
For Linked Data query engines there are inherent tradeoffs between centralised approaches
For the dynamic case we improve the performance by exploiting an individual clustering approach
Fortunately many taxonomies are now available on the web because of the spread of the Linked Open Data vision
Freebase for which 3M sentences serve as the basis for learning an average of 40K distinctive rules per relation
Furthermore we employ some transfer to reduce the demand for labeled data
Furthermore we have developed a novel skewresistant join algorithm
Having explored the alignment of conjunctive concepts in Our previous work in Our focus on concept coverings
Having explored the alignment of conjunctive concepts in Our previous work in this paper 
Hence there is a need for combined geothematic logics
Herein we propose a hybrid query execution approach while speeding up results vs the live scenario
However
However an issue is that of characterizing semantically the relations
However an issue is that of generating semantically the relations
However efficiently discovering the relevant documentations on the Web is still a challenging task even with the best resources available on the Web
However efficiently discovering Web APIs is still a challenging task even with the best resources available on the Web
However hardness of reasoning about individual ontologies has not been adequately characterised
However problems arise even for such limited logics as ALC First computation gets more difficult becoming undecidable for logics such as SROIQ the Web Ontology Language
however the available data is meant to be complete in certain ways
However these approaches are usually complete for instance retrieval only
However the widelyused timedecaybased approach worsens the sparsity problem because the widelyused timedecaybased approach deemphasizes old item transactions
however this can not be achieved in any RDFbased rule system
In addition as we move towards a semantic characterization of these relations there is arguably a need for a more sophisticated characterization than a homogeneous taxonomy to reflect the different ways
In addition we compare we approach with Timeefficient algorithms LIMES 05 to runtime
In addition we compare we approach with Timeefficient algorithms LIMES SILK 25 with respect to runtime
In consideration of both publishers and consumers the temporal dimension of data is important
In order to evaluate current federation querying approaches a general methodology for conducting benchmarks is mandatory
In order to fully exploit these new avenues of performance improvement computationally expensive workloads have to be expressed in a way
In order to tackle these issues we formulate the central notion of finding the minimal change set based on model inseparability
In particular we prove that given an achievable reduction ratio r we Link Discovery approach HR3 can achieve a reduction ratio r    r in a metric space
In RDF a blank node  is a node in an RDF graph
In RDF or anonymous resource  is a node in an RDF graph
In RDF or bnode  is a node in an RDF graph
In some circumstances
Instancebased matching is known to be a useful technique for matching ontologies
instance based matching of types
Instead of only considering the existing concepts present in each ontology we hypothesize new composite concepts
In this article we present an algorithm for validating facts by finding trustworthy sources for this article on the Web
In this article we present Deep Fact Validation  
In this article we present DeFacto  
In this paper we address the problem of describing RDFS entailment in such a way
In this paper we address this drawback by presenting the first Link Discovery approach with theoretical quality guarantees
In this paper we address this problem by finding alignments between concepts from multiple Linked Data sources
In this paper we are interested in what happens if we enrich these matching tools with knowledge of the domain of the ontologies
In this paper we cast the problem of detecting the Web API documentations as a text classification problem of classifying a given Web page as Web API associated or not
In this paper we conduct a systematic study to tackle this problem using machine learning techniques covering over 350 realworld ontologies
In this paper we conduct a systematic study to tackle this problem using machine learning techniques covering over four stateoftheart widelyused OWL 2 reasoners
In this paper we describe a mechanism for ontology alignment
In this paper we introduce a model to acquire such human contributions via microtask crowdsourcing
In this paper we introduce a novel approach of adding semantics as additional features into the training
In this paper we introduce CrowdMap 
In this paper we investigate performance variability phenomena in OWL ontologies
In this paper we investigate the characterisation and availability of temporal information in Linked Data at large scale
In this paper we present a classification methodology for federated SPARQL queries
In this paper we present an approach
In this paper we present a semantic model of a Web API directory graph
In this paper we present models
In this paper we propose an incremental execution model for SPARQLRANK queries we compare the performance of alternative physical operators and we propose a rankaware join algorithm
In this paper we propose a novel classification technique
In this paper we propose a schemaindependent instancepair similarity metric based on several general descriptive features
In this paper we propose Klink a new approach to i  automatically generating relations between research areas and ii  and external knowledge
In this paper we propose Klink a new approach to i  Google Scholar
In this paper we propose Klink a new approach to i  Wikipedia
In this paper we show how we can exploit blank nodes anonymity in order to reduce diff  size when comparing such Several RDFS Knowledge Bases
In this paper we show how we can exploit blank nodes anonymity in order to reduce the delta  size when comparing such Several RDFS Knowledge Bases
it can be implemented using standard probabilistic database systems
It is based on a classificational interpretation of mappings if O 1 are two ontologies then mappings between O 1 are interpreted to encode how elements of X are reclassified in the concepts of O 2
It is based on a classificational interpretation of mappings if O 1 are two ontologies then mappings between O 2 are interpreted to encode how elements of X are reclassified in the concepts of O 2
It is based on a classificational interpretation of mappings if O 2 are two ontologies then mappings between O 1 are interpreted to encode how elements of X are reclassified in the concepts of O 2
It is based on a classificational interpretation of mappings if O 2 are two ontologies then mappings between O 2 are interpreted to encode how elements of X are reclassified in the concepts of O 2
Like GeoSPARQL these new versions use OGC standards to represent geometries where the original versions used linear constraints
links given the presence of mutual nodes
method using a dataset
metrics that can be used to effectively predict reasoning performance
microtasks that address individual alignment questions
microtasks that evaluates the quality of the results
microtasks that publishes the microtasks on an online labor market
Minimal module extraction assign an absolute priority to one of these requirements thereby limiting the possibilities to influence the other two
models that rely solely on network topology information and b 
Moreover
Moreover we compare various methods for approximate reasoning based on hot spots
Moreover we compare various methods for knowledge compilation based on hot spots
Moreover we devise various methods for approximate reasoning based on hot spots
Moreover we devise various methods for knowledge compilation based on hot spots
Most importantly it is very timeconsuming as the experts have to carry out several search processes
Most importantly it is very timeconsuming as the experts must often read several documents
Most of the existing approaches rely on the quality of prior schema matching
naive Bayes support vector machines by over 3
network topology information and b  assessing the different behaviour that users exhibit when making followeeaddition decisions
new composite concepts defined as disjunctions of conjunctions of RDF types which we call restriction classes
new composite concepts defined as disjunctions of conjunctions of RDF types which we generate alignments between these composite concepts
new composite concepts defined as disjunctions of conjunctions of value restrictions which we call restriction classes
new composite concepts defined as disjunctions of conjunctions of value restrictions which we generate alignments between these composite concepts
Nonetheless few semantic accounts have been given so far for such weights
one containing a restaurant visit history
One important part of The Linking Open Data  project is to establish owl 
One important part of The Linking Open Data  project is to establish owl 
One important part of The Linking Open Data  project is to establish sameAs links among structured data sources
One important part of The Linking Open Data  project is to establish sameAs links among structured data sources
One of the main tasks is to provide sources for facts in order to ensure correctness of the provided knowledge
One of the main tasks is to provide sources for facts in order to ensure traceability of the provided knowledge
One of the main tasks is to validate facts
ones learned from local corpora of different sizesthese matching tools have emerged that automate this task
ontologies containing axioms outside the relevant fragment
ontologies that have different names
ontologies that have different structures
Ontology mappings are often assigned a confidence factor by matchers
Ontology mappings are often assigned a weight factor by matchers
Order is an important property of data
other logical languages are built around the idea that axioms enable the inference of new facts about the available data
other sources which are part of the Linked Open Data cloud
Our concept alignment approach is based on analyzing the extensions of these concepts
Our concept alignment approach is based on analyzing these concepts
our conclude that RDFS entailment can benefit even more from careful optimizations
our conclude that RDFS entailment lends RDFS entailment well to parallelization
our implement and evaluate our approach on study RDFS reasoning performance characteristics on different levels of parallelization
our implement and evaluate our approach on two realworld datasets performance characteristics on different levels of parallelization
Our present an evaluation of this new algorithm to Biological Classification
Our present an evaluation of this new algorithm to Genetics domains
Our present an evaluation of this new algorithm to Geospatial
perception which enable advanced integration and interpretation of heterogeneous sensor data
present a method to differentiate changes particular concept names
present methods to identify subsets of an ontology
Previous approaches to this issue have relied on syntactically specifying certain axioms as constraints or adding in new constructs for constraints and providing a different meaning for constraints
Previous approaches to this issue have relied on syntactically specifying certain axioms as constraints or adding in new constructs for constraints and providing a extended meaning for constraints
prior schema matching which is not always good enough in the Open Data scenario
producing linked data is time consuming
producing linked data requires specialized knowledge of RDF
producing linked data requires specialized knowledge of SPARQL
properties that are extracted from a model abstraction
properties that relate mapping entailment with description logic constructorsthere is currently a wide range of reasoners highly optimised for classification of OWL 2 ontologies
queries returning the top k
queries that cover the major aspects of strRS processing
Reasoners are combined in a blackbox modular mannerFor a number of years now we have seen the emergence of repositories of research data specified using OWLRDF as representation languages
recent Web service technology development owing to Web APIs simplicity of technology stack
recent work that allows a user to define a linked service from an online service
RE  system detects both binary relations
RE  system detects both nary relations
RE  system which learns grammarbased RE rules from the Web by utilizing large numbers of relation instances as seed
research areas and ii  populating a bibliographic ontology
research areas and ii  which combines both machine
researchers  evolve slowly
RE  system which learns grammarbased RE rules from the Web by utilizing large numbers of relation instances as seed
  r in a metric space where distances are measured by the means of a Minkowski metric of any order p   2
Secondly we identify a number of metrics
Second once a concept change is pinpointed the problem of distinguishing whether the concept is directly affected by a change has yet to be tackled
Second once a concept change is pinpointed the problem of distinguishing whether the concept is indirectly affected by a change has yet to be tackled
Second the presence of disjunction make the standard semantic difference too sensitive to change essentially any logically effectual change always affects all terms in the ontology
Second the presence of negation make the standard semantic difference too sensitive to change essentially any logically effectual change always affects all terms in the ontology
Second we use a taxonomy of items to model user item transactions in each epoch
Seemingly innocuous changes to an OWL ontology can degrade classification time from instantaneous to too long to wait for
Sentiment analysis over Twitter offer organisations a effective way to monitor the publics feelings towards the publics brand for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results
Sentiment analysis over Twitter offer organisations a effective way to monitor the publics feelings towards the publics methods for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results
Sentiment analysis over Twitter offer organisations a fast way to monitor the publics feelings towards the publics brand for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results
Sentiment analysis over Twitter offer organisations a fast way to monitor the publics feelings towards the publics business directors A wide range of features for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results
Sentiment analysis over Twitter offer organisations a fast way to monitor the publics feelings towards the publics methods for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results
Several RDFS Knowledge Bases rely heavily on blank nodes as Several RDFS Knowledge Bases  Several RDFS Knowledge Bases  are convenient for representing complex attributes or resources
Several RDFS Knowledge Bases  attributes  either associations with other resources  are known
Several RDFS Knowledge Bases  attributes  either associations with other resources  are known
Several RDFS Knowledge Bases  attributes  either literals with other resources  are known
Several RDFS Knowledge Bases  attributes  either literals with other resources  are known
several reasoners complete for ontologies
several reasoners that are complete for restricted fragments of OWL 2 such as the OWL 2 EL profile
several reasoners that are complete for restricted fragments of OWL 2 such as the OWL 2 EL profile are much more efficient than fullyfledged OWL 2 reasoners
several reasoners that are complete for restricted fragments of OWL 2 such as the OWL 2 EL profile are much more efficient than several reasoners
several reasoners that are complete for restricted fragments of OWL 2 such as the OWL 2 EL profile are not
several relations in parallel enabling a new method of rule filtering
Several similar systems have been studied
Similarly switching eg to take advantage of specific features  can result in wildly different classification times
Similarly switching reasoners  can result in wildly different classification times
similar transactions that exist in prior epochs
So far this task is often addressed by human curators in a threestep process issuing appropriate keyword queries for the statement to check using standard search engines
So far this task is often addressed by human curators in a threestep process retrieving potentially relevant documents
So far this task is often addressed by human curators in a threestep process screening those documents for relevant content
solutions in which Semantic Web technologies are adapted for publishing sharing analysing streaming data
solutions in which Semantic Web technologies are adapted for publishing sharing understanding streaming data
solutions in which Semantic Web technologies are extended for publishing sharing analysing streaming data
solutions in which Semantic Web technologies are extended for publishing sharing understanding streaming data
some transfer learning methods to utilize sameAs links in Open Data
some transfer learning methods to utilize the existing owl
sources that have rudimentary ontologies such as those
SRBench with which one can assess the abilities of a strRS engine to cope with a broad range of use cases typically encountered in realworld scenarios
SROIQ which underly
Stateoftheart SPARQL engines underuse order
statistics gathered during the previous step
Stronger couplings allowing for FOL rewritability
Stronger couplings are possible only for spatial calculi as weak as the lowresolution calculus RCC2
Subsequently we devise a series of computable approximationsa system that incrementally executes SPARQL queries on a Hadoop cluster
Subsequently We present various polynomial algorithms returning approximate solutions for the general caseData provenance is the history of derivation of a data artifact from Data provenance original sources
Such links indicate equivalent instances
Surprisingly
temporal information associated with RDF statements and graphs
test benchmarks that allows for comparability
test benchmarks that cover diverse characteristics of different queries
the 2011 billion triple challenge data set
The applicability of our approach to machine perception is evaluated on a smartphone mobile device demonstrating dramatic improvements in both efficiency and scaleWeb APIs have gained the proliferation of mashups
the approaches proposed in the literature
The approach is based on the translation of SPARQL into relational queries over annotated relations in this way also refuting a claim in the literature that the OPTIONAL construct of SPARQL can not be captured appropriately with the known abstract modelsan RDF graph which is not a literal
The approach is based on the translation of SPARQL into relational queries over annotated relations with values of the most general msemiring also refuting a claim in the literature that the OPTIONAL construct of SPARQL can not be captured appropriately with the known abstract models
the benchmark defines a concise yet comprehensive set of queries
the cached data
the complex linking tasks
The computational complexity of OWL however seriously limits The computational complexity of OWL applicability and use within resourceconstrained environments such as mobile devices
The costs are based on information about the instances of classes
The costs are based on information about the instances of properties
The data sets have been carefully chosen such that The data sets represent a realistic usage of streaming data
The data sets have been carefully chosen such that The data sets represent a relevant usage of streaming data
The data sets used in the benchmark
The data sets used in the benchmark
the different ways in which research areas can be related
The distributed nature of Linked Open Data requires federated techniques for query evaluation
The DLLite family of description logics is tailored towards FOL rewritability of query answering for unions of conjunctive queries hence The DLLite family of description logics is a suitable candidate for the thematic component of a combined geothematic logic
The drawbacks of a threestep process are manifold
the existence of a clear need for topical affinity between users for a follow link to be created
the existing approaches addressing The problem of discovering owl
the existing approaches addressing The problem of discovering sameAs links between pairwise data sources
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a costeffective manner
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a fast manner
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a scalable manner
The experiments clearly demonstrated that the overall approach is feasibleFOL  rewritability is a desirable feature for query answering over geothematic ontologies because in most geoprocessing scenarios one has to cope with large data volumes
the expressive power offered by the art semantic geospatial query languages GeoSPARQL GeoSPARQL
the expressive power offered by the art semantic geospatial query languages GeoSPARQL stSPARQL
the expressive power offered by the art semantic geospatial query languages stSPARQL GeoSPARQL
the expressive power offered by the art semantic geospatial query languages stSPARQL stSPARQL
the expressive power offered by the art the art semantic geospatial a new RDF store semantic geospatial query languages GeoSPARQL
the expressive power offered by the art the art semantic geospatial a new RDF store semantic geospatial query languages stSPARQL
the expressive power offered by the art the art semantic geospatial query languages GeoSPARQL implementation in Strabon semantic geospatial query languages GeoSPARQL
the expressive power offered by the art the art semantic geospatial query languages GeoSPARQL implementation in Strabon semantic geospatial query languages stSPARQL
the expressive power offered by the art the art semantic geospatial query languages stSPARQL implementation in Strabon semantic geospatial query languages GeoSPARQL
the expressive power offered by the art the art semantic geospatial query languages stSPARQL implementation in Strabon semantic geospatial query languages stSPARQL
The extracted entities expected relationships are verified linking
The extracted entities expected relationships are verified linking
The extracted entities expected relationships are verified using classification
The extracted entities expected relationships are verified using classification
The extracted entities expected relationships are verified using two evidence based techniques
The extracted entities expected relationships are verified using two evidence based techniques
the finegrained research topics which define the level at which typically and even more so PhD students  operate
the finegrained research topics which define the level at which typically researchers  operate
The heterogeneous nature of Linked Open Data requires federated techniques for query evaluation
The heterogeneous nature of Linked Open Data requires flexible techniques for query evaluation
the HYPPO algorithm implemented in LIMES 05 with respect to the number of comparisons they carry out
The identification of these hot spots allows users to isolate difficult portions of the ontology in a principled way
The identification of these hot spots allows users to isolate difficult portions of the ontology in a systematic way
the inference tasks needed for machine perception
The inherent heterogeneity of datasets on the Semantic Web has created a need to interlink The inherent heterogeneity of datasets on the Semantic Web
The main goal is to populate a knowledge base
The main idea of the proposed method is to build a mapping between the bnodes of the compared Several RDFS Knowledge Bases for reducing the delta size
the main tasks when maintaining knowledge bases
the maximum entropy model by over 3
Then the system automatically proposes a service model the user can refine interactively
Theoretical works have established worstcase complexity results for reasoning tasks for expressive ontology languages such as OWL DL and OWL 2 DL
The presented results are meant to give a first baselinecentralised approaches that can efficiently live decentralised approaches
The presented results illustrate the stateoftheart
The prime inference problem is computing answer probabilities
The problem of discovering owl is called instance matching
The problem of discovering sameAs links between pairwise data sources is called instance matching
There are also several reasoners
There exist several proposals in the literature to annotate SPARQL query results with values from abstract models adapting the seminal works on provenance for annotated relational databases
therefore and even more so PhD students  tend not to cover the most recent research trends
therefore researchers  tend not to cover the most recent research trends
There is recent work
the relations that exist between research areas
The resulting alignments are useful for refining existing ontologies
the results obtained from the crowd
The results show that our method predicts user interests much more accurately than the previous timedecaybased methodThe amount of data available in the Linked Data cloud continues to grow
The results show that We method outperforms the participants of OAEI2010Tracking user interests over time is important for making accurate recommendations
The results show that We method performs well on realworld Open Data data
these concepts linked instances
the semantics behind classes do not change so often while individual items often appear
the semantics behind classes do not change so often while individual items often disappear
these taxonomies are very coarsegrained
these taxonomies do not cater for the finegrained research topics
the situations in which the items transacted by users
the size of the corresponding signature of the extracted base with the original one
the size of the extracted base of the extracted base with the original one
The SPARQLRANK algebra is an extended SPARQL algebra
the specifics of Reasoners implementation are irrelevant to we approach
the static ordering usually
the time taken vs fully live execution
the training set for sentiment analysis
the W3C calculus can not be extended to compute all atomic class subsumptions
This changes however when the statistics are due to nondeterministic reasoning decisionsDetecting the difference between two description logic is challenging for ontology engineers due in part to the possibility of complex nonlocal logic effects of axiom changes
This changes however when the statistics are less accurate
This class of solutions promises both to facilitate the integration of research data with other relevant sources of information and also to support more intelligent forms of exploration
This class of solutions promises both to facilitate the integration of research data with other relevant sources of information and also to support more intelligent forms of querying
This extended concept language enables us to even align sources
This extended concept language enables us to find more complete definitions
This last process also enables the linking of our knowledge base to other sources
This latter contribution exposes latent factors within social networksThe distributed nature of Linked Open Data requires flexible techniques for query evaluation
this manual approach is inadequate for a number of reasons
This paper also includes properties
This paper asks how such methods could also be used for computing
This paper asks if such methods could also be used for computing
This paper presents a formal semantics for weighted mappings between different ontologies
This paper presents an approach to automatically extract entities from textual documents
This paper presents a new approach
This problem has been traditionally addressed by manually creating these taxonomies
This proposal avoids problems of previous proposalsontology alignment using instance
This proposal eliminates the need for special semantics
This semantics is a conservative extension of a semantics of crisp mappings
This semantics is justifiable by extensional practice of ontology matching
This suits the situations dynamically change over time do not change so often while individual items often appear
This suits the situations dynamically change over time do not change so often while individual items often disappear
This well captures the interests of users in each epoch even if there are few transactions
those that are simple renderings of relational databases
Three conflicting requirements arise in the context of knowledge base extraction of the extracted base with the original one
three strong supervised baselinesTopk queries ie queries results ordered by a userdefined scoring function are an important category of queries
Thus the users can eliminate dissimilar transactions while making use of similar transactions
Timeefficient algorithms are essential to address the complex
Timeefficient algorithms implemented in the stateoftheart frameworks
Tipalo identifies the most appropriate types for an entity by interpreting Tipalo natural language definition
Tipalo natural language definition which is extracted from Tipalo corresponding Wikipedia page abstract
To address the first issue various principled notions of  semantic diff   based on deductive inseparability  have been proposed in the literature
To address the first issue various principled notions of  semantic diff   based on deductive inseparability  have been shown to be computationally practical for the expressively restricted case of ELHrterminologies
To be robust against cost estimation errors a system interleaves query optimization with query execution determining the next steps to take based on data samples
To be robust against cost estimation errors a system interleaves query optimization with query execution determining the next steps to take based on statistics
To help researchers comparing streaming RDFSPARQL  engines in a standardised application scenario we have designed SRBench
To help researchers comparing strRS  engines in a standardised application scenario we have designed SRBench
To help users comparing streaming RDFSPARQL  engines in a standardised application scenario we have designed SRBench
To help users comparing strRS  engines in a standardised application scenario we have designed SRBench
To illustrate the expressive power we concentrate on the new version of the data model stRDF that we have developed we
To illustrate the expressive power we concentrate on the new version of the query language stSPARQL that we have developed we
too few terms are semantically annotated
too many terms are semantically annotated
To overcome this issue we employ OWL to formally define the inference tasks discrimination and then provide efficient algorithms for these tasks using bitvector encodings and operations
To overcome this issue we employ OWL to formally define the inference tasks explanation and then provide efficient algorithms for these tasks using bitvector encodings and operations
topk queries are mostly managed with a materializethensort processing scheme
To this end the W3C standard provides a simple system of deduction rules
tractable rulebased reasoning is possible when restricting to subsumptions between atomic classes
tuples corresponding to popular keys
two description logic based ontologies
two ontologies used to classify a common set X
Types are aligned to a subset of DOLCEDnS Ultra Lite classes
Types are aligned to two toplevel ontologies
Types are aligned to WordNet supersenses
Types are disambiguated to WordNet
Types are identified by means of a set of heuristics based on graph patterns
understanding various contexts of users is important to enable personalised selection of Web APIs in directories such as Programmable Web
uniform interpolation assign an absolute priority to one of these requirements thereby limiting the possibilities to influence the other two
usability for nonexpert users discusses the lessons learned about both our methodology of exposing nonexperts to semantic enrichment
usability for nonexpert users discusses the lessons learned about both the semantic enrichment process of exposing nonexperts to semantic enrichment
usability for nonexpert users presents the results of an enduser study to evaluate its acceptance by
usability for nonexpert users presents the results of usability for nonexpert usersDespite the increase in the number of linked instances in the Linked Data Cloud in recent times the absence of links at the concept level has resulted in heterogenous schemas challenging the interoperability goal of the Semantic Web
useful additional information
Userdefined semantic enrichment allows for a more targeted approach
various classifiers that accurately predict classification time for an ontology based on an ontology metric values
We also briefly discuss approximation of answer probabilitiesWe introduce SRBench  completely based on realworld data sets from the Linked Open Data cloud
We also demonstrate that query rewriting  backwards chaining  is an important tool for our framework
We also show that nonexistence of a rewriting into firstorder logic implies  Phardness
We analyze the problem of duplicates
We apply this approach to predict sentiment for three different Twitter datasets
Web APIs have gained increasing popularity in recent Web service technology development
We can now use those to understand dynamic user interests semantically
We carry out experiments on some datasets of OAEI2010
We compare HR3
We compare these rules with ones
we compare two different Locality Sensitive Hashing techniques for computing instance similarityMost of the semantic content available has been generated automatically by using annotation services for existing content
We conducted an enduser study to evaluate a tool acceptance by
We conducted usability for nonexpert users
We demonstrate that the Web is indeed needed for a good coverage of linguistic variation
We demonstrate the benefit of We approach through series of experiments with realworld datasetsThe lightweight ontology language OWL RL is used for reasoning with large amounts of data
We describe a novel configurable graphbased method for selection of Web APIs with personalised aspects
We describe a novel configurable graphbased method for selection of Web APIs with temporal aspects
We describe a system
We describe how these techniques can be used to estimate containment relations between two type systems
We describe how these techniques can be used to estimate equivalence relations between two type systems
We developed a tool for semantic annotation of digital documents
We establish a PTime vs  P dichotomy for the data complexity of The prime inference problem by lifting a corresponding result from probabilistic databases
We evaluate a novel configurable graphbased method for selection of Web APIs on a realworld dataset from ProgrammableWebcomDue to the high worst case complexity of the core reasoning problem for the expressive profiles of OWL 2 ontology engineers are often surprised
We evaluated the current implementation of a model to acquire such human contributions via microtask crowdsourcing in a series of The experiments Initiative
We evaluated the current implementation of a model to acquire such human contributions via microtask crowdsourcing in a series of The experiments the crowdsourcing platform CrowdFlower
We evaluated the current implementation of CrowdMap
We evaluate the adequacy of the query generation strategy by applying the adequacy of our methodology on the 2011 billion triple challenge dataThe last decade of research in ontology alignment has brought a variety of computational techniques to discover correspondences between ontologies
We evaluate the adequacy of the query generation strategy by applying the adequacy of the query generation strategy on the 2011 billion triple challenge data
We evaluate the adequacy of We methodology by applying the adequacy of our methodology on the 2011 billion triple challenge data
We evaluate the adequacy of We methodology by applying the adequacy of the query generation strategy on the 2011 billion triple challenge data
We evaluate the effectiveness of We approach both on a synthetic benchmark as well as on a Yahoo case of data analysis
We evaluate We method a music extracted from users tweets
We evaluate We one
we examine various methods to decide what constitutes the domain of a given dataset
we experimental study shows that the static outperforms the dynamic one when accurate statistics are available
we experiments show that the amount of temporal information available in the LOD cloud is still very small several different models have been used on different datasets with RDFThe Linking Open Data project is an ongoing effort to construct a global data space ie the Web of Data
we explore how to express the notion of a domain in terms usable for an ontology matching tool
We first compare results from two public SPARQL stores against current versions of the Linked Data sources two public SPARQL stores against current versions of the Linked Data sources they cache cache results are often missing
We first compare results from two public SPARQL stores against current versions of the Linked Data sources two public SPARQL stores against current versions of the Linked Data sources they cache cache results are outofdate
We further develop a heuristic
We goal is to obtain rule sets large enough to cover the actual range of linguistic variation thus tackling the longtail problem of realworld applications
We have tested a number of alternative algorithms evaluation shows that a method performs best with respect to a manually constructed standard
We have tested a number of We evaluation shows that a method performs best with respect to a manually constructed standard
We identify syntactic restrictions to mitigate this problem and propose a rule systemThe primary challenge of machine perception is to define efficient computational methods to derive highlevel knowledge from lowlevel sensor observation data
weights are interpreted to measure how complete reclassifications are
weights are interpreted to measure how precise reclassifications are
We introduce a generalpurpose benchmark primarily designed for streaming RDFSPARQL engines completely based on realworld data sets from the Linked Open Data cloud
We introduce two ideas to solve the sparsity problem
we main contributions are twofold
we prediction models have been shown to be highly effective achieving an accuracy of over 80Sentiment analysis over Twitter offer organisations a effective way to monitor the publics feelings towards the publics business directors A wide range of features for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results
We present a largescale relation extraction  system
We present an algorithm
We present Strabon a new all other geospatial RDF store
We present tool for automatically typing DBpedia entities
We propose a framework for querying probabilistic instance data in the presence of an OWL2 QL ontology arguing that the interplay of ontologies is fruitful in many applications such as managing data
We propose a framework for querying probabilistic instance data in the presence of an OWL2 QL ontology arguing that the interplay of probabilities is fruitful in many applications such as managing data
We propose a novel technique for EL
We propose a supervised generative topic model
We propose a tractable rewriting approach
We propose the use of Locality Sensitive Hashing techniques to vastly improve the scalability of instance matching across multiple types
We propose to instead directly state that the extension of certain concepts and roles are complete by making certain concepts and roles DBox predicates which eliminates the distinction between regular axioms and constraints for these concepts and roles
We prove that finding the optimal mapping is NPHard in the general case
We prove that finding the optimal mapping is polynomial in case there are not directly connected bnodes
We provide an approach capable of providing provenance information for a large fragment 
We provide an approach capable of providing provenance information for a significant fragment 
We provide an approach capable of providing provenance information for for the first time the major nonmonotonic constructs under multiset semantics
We results indicate that a system is indeed capable of processing huge datasets without precomputed statistics while exhibiting good loadbalancing properties
We results show an average increase of F harmonic accuracy score for identifying both negative sentiment of around 65a new all other geospatial RDF store that supports the state of the art semantic geospatial query languages GeoSPARQL
We results show an average increase of F harmonic accuracy score for identifying both positive sentiment of around 65
We results show that hybrid query execution can improve freshness vs fully cached results while reducing the timeWe present RE  system
We show how We can study the effect of domain knowledge on the quality of the alignmentThe paper presents an approach for costbased query planning for SPARQL queries issued over an OWL ontology using the OWL Direct Semantics entailment regime of SPARQL 11
We show how We can use this in a matching tool
We show that a novel configurable graphbased method for selection of Web APIs provides more contextualised results than currently available popularitybased rankings
We show that a weak coupling of DLLite with the expressive region connection calculus RCC8 allows for FOL rewritability under a spatial completeness condition for the ABox
we show that HR3 outperforms these previous approaches with respect to runtime in each of we four experimental setupsthe syntactic similarity of the extracted base with the original one
we show that the performance of Strabon experimentally scales to very large data volumes most of the times better than all other geospatial RDF stores the performance of Strabon experimentally has been compared withOntology are built around the idea that axioms enable the inference of new facts about the available data
we show that the performance of Strabon performs most of the times better than all other geospatial RDF stores the performance of Strabon experimentally has been compared with
We show the feasibility of We approach with DBpedia with hundreds of types respectively
We show the feasibility of We approach with DBpedia with thousands of types respectively
We show the feasibility of We approach with Freebase with hundreds of types respectively
We show the feasibility of We approach with Freebase with thousands of types respectively
We show the feasibility of We approach with two different type systems with hundreds of types respectively
We show the feasibility of We approach with two different type systems with thousands of types respectively
We solve the binary classification problem by machine learning algorithms
we study the performance of Strabon experimentally most of the times better than all other geospatial RDF stores the performance of Strabon experimentally has been compared with
We target 39 relations from Freebase
We thus propose using coherence estimates to split a query into a subquery
We thus propose using coherence estimates to split a query into a subquery
We transform the instance matching problem to the binary classification problem
we verify we techniques with a select set of varyingly difficult ontologies from the NCBO BioPortal firstly successfully identify performance hot spots against the major freely available DL reasoners and secondly significantly improve classification timemanaging data that was extracted from the web
we were able to firstly successfully identify performance hot spots against the major freely available DL reasoners and secondly significantly improve classification time
When such  ideally small  subsets are removed from an ontology we designate ideally small  subsets  hot spots 
When such  ideally small  subsets are removed from an ontology we designate such  subsets  hot spots 
When the remainder is much easier for the given reasoner to reason over we designate ideally small  subsets  hot spots 
When the remainder is much easier for the given reasoner to reason over we designate such  subsets  hot spots 
While the accuracy of automatic approaches has continuously improved human contributions remain a key ingredient of the process this input serves as a valuable source of domain knowledge automatically computed alignments
With enough tools to gain knowledge from too much streaming data researchers have set out for solutions
With the increasing problem of too much streaming data researchers have set out for solutions
X classified in the concepts of O 1
Yet few services consume linked data
Yet few services produce linked data
3M sentences extracted from 20M web pages
