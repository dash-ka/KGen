The last decade of research in ontology alignment has brought a variety of computational techniques to discover correspondences between ontologies
domain knowledge that is used to train the algorithms
domain knowledge that is used to augment
domain knowledge that is used to validate
While the accuracy of automatic approaches has continuously improved human contributions remain a key ingredient of the process this input serves as a valuable source of domain knowledge automatically computed alignments
In this paper we introduce CrowdMap 
In this paper we introduce a model to acquire such human contributions via microtask crowdsourcing
microtasks that address individual alignment questions
the results obtained from the crowd
For a given pair of ontologies CrowdMap a model to acquire such human contributions via microtask crowdsourcing translates the alignment problem into microtasks
microtasks that evaluates the quality of the results
microtasks that publishes the microtasks on an online labor market
a series of The experiments using ontologies from the Ontology Alignment Evaluation
We evaluated the current implementation of a model to acquire such human contributions via microtask crowdsourcing in a series of The experiments the crowdsourcing platform CrowdFlower
We evaluated the current implementation of CrowdMap
a series of The experiments using reference alignments from the Ontology Alignment Evaluation
We evaluated the current implementation of a model to acquire such human contributions via microtask crowdsourcing in a series of The experiments Initiative
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a fast manner
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a scalable manner
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a costeffective manner
The experiments clearly demonstrated that the overall approach is feasible