distributed collaborations that have come to be known as virtual organizations
problem solving across dynamic distributed collaborations
an emerging computational infrastructure that enables resource sharing
grids are an emerging computational infrastructure
an emerging computational infrastructure that coordinated problem
unlike the web the grid provides a range of fundamental mechanisms for sharing diverse types of resource such as scientific instruments
the web which primarily focuses on the sharing of information
unlike the web the grid provides a range of fundamental mechanisms for sharing diverse types of resource such as storage
unlike the web the grid provides a range of fundamental mechanisms for sharing diverse types of resource such as data
unlike the web the grid provides a range of fundamental mechanisms for sharing diverse types of resource such as software
unlike the web the grid provides a range of fundamental mechanisms for sharing diverse types of resource such as computers
in this talk i will introduce the grid concept
in this talk i illustrate the grid concept with application examples from a range of scientific disciplines
it is likely that technology will have important roles to play in grid services i will explore some of these potential areas of the semantic web technologies
technology that is being developed for the semantic web
some of these potential areas of the semantic web technologies identifying those that i think offer the most potentialthe web will transform the web from a collection of information into a distributed device of computation
in order to employ the web full potential appropriate description means for web services need to be developed
a fullfledged web service modeling framework that provides the appropriate conceptual model for describing web services
for this purpose we define a fullfledged web service modeling framework
a fullfledged web service modeling framework that provides the appropriate conceptual model for describing web services composition
a fullfledged web service modeling framework that provides the appropriate conceptual model for developing web services
a fullfledged web service modeling framework that provides the appropriate conceptual model for developing web services composition
web services philosophy is based on the following principle maximal decoupling complemented by scalable mediation servicethe web is moving from being a collection of pages toward a collection of services
services that interoperate through the internet
other services that can help toward the solution of a problem
the first step toward this interoperation is the location of other services
in this paper we claim that location of web services should be based on the semantic match between a description of the service
the service being offered
the service being sought
in this paper we claim that location of web services should be based on the semantic match between a declarative description of the service
furthermore we claim that the semantic match between a description of the service is outside the representation capabilities of languages such as wsdl
the service being sought
the service being offered
furthermore we claim that the semantic match between a declarative description of the service is outside the representation capabilities of languages such as wsdl
furthermore we claim that the semantic match between a declarative description of the service is outside the representation capabilities of registries such as uddi
furthermore we claim that the semantic match between a description of the service is outside the representation capabilities of registries such as uddithe advantage of the rdfdamloil family of languages over ordinary xml is that the rdfdamloil family of languages over ordinary xml is topicneutral
the advantage of the rdfdamloil family of languages over ordinary xml is that the rdfdamloil family of languages over ordinary xml is composable
however the rdfdamloil family of languages over ordinary xml expressivity is severely limited
the usual remedy is reification
this limitation is well known
reification in which rdf is used to describe formulas in a richer language
we propose a method for encoding typed predicate calculus using reification
reification which handles bound variables cleanly
reification which causes the size to increase by only a constant multiple
a method generalizes to virtually any system a claim which we illustrate by describing we program pddaml
pddl using we technique
pddaml which encodes domain specifications in pddl
we argue that reification while logically suspect is in practice benign because any algorithm capable of doing inferences using logical notations can be easily extended to  unreify  those notations as needed
we also argue that the ability to represent predicate calculus on the semantic web is crucialrdf provides a basic way to represent data for the semantic web
we have been experimenting with the query paradigm for working with rdf data in semantic web applications
a declarative access mechanism that is suitable for remote access
query of rdf data provides a declarative access mechanism
a declarative access mechanism that is suitable for application usage
one possible syntax derived from
rdf data that refines ideas first presented in at the design of one possible syntax
rdf data that refines ideas first presented in at the w3c workshop on query languages
we describe work on a conceptual model for querying rdf data that is suitable for application programmers
further we present experience gained in three implementations of the query languageontologies now play an important role for enabling the semantic web
ontologies provide a source of precisely defined terms for knowledgeintensive applications
the terms are used for concise communication across applications
the terms are used for concise communication across people
typically the development of ontologies involves collaborative efforts of multiple persons
ontoedit is an ontology editor
an ontology editor that integrates numerous aspects of ontology engineering
ontoedit which is guided by a comprehensive methodology
this paper focuses on collaborative development of ontologies with ontoeditthis paper describes two approaches for automatically converting rdf schema into an inference engine
this paper describes two approaches for automatically converting rdf schema into storage repository
this paper describes two approaches for automatically converting ruleml sources into an inference engine
this paper describes two approaches for automatically converting ruleml sources into storage repository
rather than using traditional inference systems
rather than using relational database systems
rather than using our solution bases on mainstream technologies like java
while this necessarily imposes some restrictions the ease of integration into an existing this landscape is a major advantage
we present the conversion tools limitations
we present the conversion tools
furthermore an extension to ruleml is proposed that allows javaenabled reaction rules where calls to java libraries can be performed upon a rule firing
this requires hosts to be javaenabled when rules are moved across the web
this requires hosts to be javaenabled when code are moved across the web
however the solution allows for great engineering flexibilitysemantic web mining aims at combining the two fastdeveloping research areas web mining
semantic web mining aims at combining the two fastdeveloping research areas semantic web
the idea is to improve on the one hand the results of web mining by exploiting the new semantic structures in the web
the idea is to make use of web mining on the other hand for building up the semantic web
the semantic web gives an overview of where the two areas meet today
the semantic web gives sketches ways of how a closer integration could be profitablethere are two major ongoing efforts to advance the world wide web
on one side there is the the world wide web research on the other side is the web service research
both activities aim to make content on the web accessible not only also for machines in order to create a foundation for business processes
both activities aim to make content on the web usable not only for humans to create a foundation for intelligent automated services
both activities aim to make content on the web usable not only also for machines in order to create a foundation for business processes
both activities aim to make content on the web accessible not only for humans to create a foundation for business processes
both activities aim to make content on the web accessible not only also for machines in order to create a foundation for intelligent automated services
both activities aim to make content on the web usable not only for humans to create a foundation for business processes
both activities aim to make content on the web accessible not only for humans to create a foundation for intelligent automated services
both activities aim to make content on the web usable not only also for machines in order to create a foundation for intelligent automated services
two major ongoing efforts to advance the world wide web are highly complementary
there is work in progress towards a unification of two major ongoing efforts to advance the world wide web
this paper contributes to this process of unification by presenting a method of connecting web services descriptions with semantic web ontologiesthe ability to rapidly locate software applications  as opposed to simply useful documents is becoming increasingly critical in many domains
the ability to rapidly locate software components  as opposed to simply useful documents is becoming increasingly critical in many domains
the ability to rapidly locate process models  as opposed to simply useful documents is becoming increasingly critical in many domains
the ability to rapidly locate useful online services  as opposed to simply useful documents is becoming increasingly critical in many domains
the ability to rapidly locate service organizations  as opposed to simply useful documents is becoming increasingly critical in many domains
current service retrieval technology is however notoriously prone to low precision
this paper describes a novel service retrieval approached based on the sophisticated use of process ontologies
our preliminary evaluations suggest that this approach offers qualitatively higher retrieval precision than existing approaches without sacrificing recall
our preliminary evaluations suggest that this approach offers qualitatively higher retrieval precision than existing approaches without sacrificing computational tractability or scalabilitythe development of the semantic web proceeds in layers
the damloil language which corresponds to a rich description logic
the most advanced layer that has reached maturity
currently the most advanced layer is the ontology layer in the from of the damloil language
the next step will be the the realization of logical rule systems on top of the ontology layerresources documenting subjects
topic maps have been developed in order to represent the structures of relationships between subjects independently of resources
topic maps have been developed in order to allow standard representation and interoperability of such structures
the iso 13250 xtm specification have provided a robust syntactic xml representation
a robust syntactic xml representation allowing interchange of topic maps
a robust syntactic xml representation allowing processing of topic maps
but topic maps have so far suffered from a lack of formal description
but topic maps have so far suffered from conceptual model
we propose here such a model based on the mathematical notions of connexity
we propose here such a model based on the mathematical notions of hypergraph
a model provides ways to check semantic consistency of topic maps
a model addresses the critical issue of topic map organization in semantic layers
moreover a model seems generic enough to be used as a foundation for other semantic standards like rdffor the web to reach the web to reach its full potential full potential the web to reach its full potential must evolve into the  semantic web  providing a universally accessible platform
a universally accessible platform that allows data to be processed by people
a universally accessible platform that allows data to be shared by people
a universally accessible platform that allows data to be shared by automated tools
a universally accessible platform that allows data to be processed by automated tools
the  semantic web  is a recent initiative of the world wide web consortium with the goal of extending the  semantic web  to facilitate universally accessible content
the  semantic web  is a recent initiative of the world wide web consortium with the goal of extending the  semantic web  to facilitate web automation
the  semantic web  is a recent initiative of the world wide web consortium with the goal of extending the  semantic web  to facilitate the  semantic web 
however if the  semantic web  is going to be adopted a clear migration path from present technologies to new ones is required
however if the  semantic web  is going to be assimilated a clear migration path from present technologies to new ones is required
the swadeurope project aims to support the world wide web consortium semantic web initiative in europe
semantic web initiative in europe providing targeted research to ensure semantic web technologies move into the mainstream of networked computing
the swadeurope project aims to support the world wide web consortium semantic web initiative in europe
semantic web initiative in europe providing targeted demonstrations to ensure semantic web technologies move into the mainstream of networked computing
semantic web initiative in europe providing targeted outreach to ensure semantic web technologies move into the mainstream of networked computing
the swadeurope project aims to support the development and deployment of the  semantic web  specifications through testing activities
the swadeurope project aims to support the development and deployment of the  semantic web  specifications through implementation activities
the swadeurope project aims to support the development and deployment of the  semantic web  specifications through research activitieswebtheme combines the power of software agentbased information retrieval with visual analytics to provide users with a new tool for understanding web information
webtheme allows users to both drill down into interesting portions of a collection
webtheme allows users to both quickly comprehend large collections of information from the semantic web
software agents work for users to perform controlled harvesting of web material of interest
visualization tools allow exploration of the resulting document space
analysis tools allow exploration of the resulting document space
information spaces are presented according to information spaces topical context
information spaces are organized according to information spaces topical context
tools enhance users understanding of users context
tools that display how the agents are linked further
the agents where the agents were gathered
tools that display how documents were collected by the agents
tools enhance users understanding of information
webtheme is a significant tool in the pursuit of the semantic web
in particular webtheme supports enhanced user insight into semantics of adhoc web information collections
in particular webtheme supports enhanced user insight into semantics of prestructured web information collections
in particular webtheme supports enhanced user insight into semantics of large web information collectionsthe semantic discontinuity between worldwide web languages and xml xml schema and xpath and semantic web languages and rdf rdfs and damloil forms a serious barrier for the stated goals of the world wide web
the semantic discontinuity between worldwide web languages and xml xml schema and xpath and semantic web languages and rdf rdfs and damloil results from a difference in modeling foundations between logics
the semantic discontinuity between worldwide web languages and xml xml schema and xpath and semantic web languages and rdf rdfs and damloil results from a difference in modeling foundations between xml
we propose to eliminate the semantic discontinuity between worldwide web languages and xml schema and semantic web languages
we propose to rdfs by creating a common semantic foundation for both the world wide web taking ideas from both
we propose to rdf by creating a common semantic foundation for both the world wide web taking ideas from both
we propose to damloil by creating a common semantic foundation for both the world wide web taking ideas from both
we propose to rdf by creating a common semantic foundation for both the world wide web taking ideas from both
we propose to eliminate the semantic discontinuity between worldwide web languages and xpath and semantic web languages
we propose to damloil by creating a common semantic foundation for both the world wide web taking ideas from both
we propose to rdfs by creating a common semantic foundation for both the world wide web taking ideas from both
we propose to eliminate the semantic discontinuity between worldwide web languages and xml and semantic web languages
a common semantic foundation results in essentially no change to xml and only minor changes to rdf
but a common semantic foundation allows the world wide web to get closer to the world wide web goal of describing the semantics of the world wide web
other semantic web languages  including rdfs  are considerably changed because of a common semantic foundation
other semantic web languages  including damloil  are considerably changed because of a common semantic foundationthis paper describes a miniexperiment in using the annotation tool to index photographs of a type of antique furniture
this paper describes a miniexperiment in using the annotation tool to index photographs of windsor chairs 
the annotation tool makes use of an ontology
an ontology based on art standards
we report on the experiences of subjects
subjects using the annotation tool
the results suggest also that an annotation tool has a clear added value for indexers
the results suggest that a certain level of domain expertise is needed for semantic annotationsmany rdf repositories have already been implemented with various access languages and mechanisms
the aim of the edutella framework is to allow communication between different rdf repository implementations
a query exchange language which can be used as lingua franca to retrieve information from rdf repositories
part of edutella is a query exchange language
this work shows why we also need standardization of distributed modification capabilities
we use replication services as guideline for we approach towards a modification exchange language for distributed rdf repositories
we describe use case scenarios for replication services
we use annotation services as guideline for we approach towards a modification exchange language for distributed rdf repositories
we describe use case scenarios for annotation servicesthis paper presents modular rule language for the semantic web
this paper presents a layered for the semantic web
this paper presents triple 
triple is borrows many basic features from flogic
triple is based on horn logic
triple is especially designed for querying rdf models
triple is especially designed for transforming rdf modelsthe resource description framework schema specification are supposed to be the foundations of the semantic web in that all other the semantic web languages are to be layered on top of all other semantic web languages
the resource description framework are supposed to be the foundations of the semantic web in that all other the semantic web languages are to be layered on top of all other semantic web languages
it turns out that such a layering can not be achieved in a straightforward way
this paper describes the problem with the straightforward layering
this paper lays out several alternative layering possibilities
the benefits and drawbacks of each of these possibilities are analyzed
the benefits and drawbacks of each of these possibilities are presentedsome modeling aspects that have to be addressed in the context of the integration of heterogeneous xml resources
some modeling aspects that have to be addressed in the context of the integration of autonomous xml resources
this paper deals with some modeling aspects
the emphasis of this paper is neither on on this paper technical details
the emphasis of this paper is neither on this paper algorithmic aspects technical details
we propose an integration system
instead we focus on the significance of offering appropriate highlevel primitives and mechanisms for representing the semantics of xml data
we posit that support for such primitives and mechanisms is a prerequisite for realizing the goals of the semantic webin this paper we present a damloil ontology for describing the properties and capabilities of web services
in this paper we present damls 
web services devices are garnering a great deal of interest from industry
web services webaccessible programs are garnering a great deal of interest from industry
standards are emerging for lowlevel descriptions of web services
damls complements this effort by providing web service descriptions at the application layer describing how a service does a service
damls complements this effort by providing web service descriptions at the application layer describing what a service can do
in this paper we describe the service grounding
in this paper we describe the service profile the process model
in this paper we describe three aspects of our ontology
the grounding which connects our ontology with lowlevel xmlbased descriptions of web services
this paper focuses on the groundingthe paper reviews the notions of expressiveness of description logics from m de rijke
the paper reviews the notions of expressiveness of description logics from  n kurtonina rijke
expressiveness of concept expressions in firstorder description logics
artificial intelligence 107303333 1999  and exemplifies artificial intelligence 107303333 1999
artificial intelligence 107303333 1999  and exemplifies use in the development in semantic web languages
the notion of bisimulation which characterizes the description logic alc provides a direct link to what is in the field of sociology
sociology called social network analysis
sociology called social network analysis
the perspective on data in the field of sociology  data are represented as labeled graphs fits exactly the modeling intuitions of web languages like oil
the perspective on data in the field of sociology  data are represented as labeled graphs fits exactly the modeling intuitions of web languages like damloil
this is exemplified in the study of trophic networks
an extension of oil with a limited form of self reference is proposed
a further connection is established between web languages
a further connection is established between hybrid logicrdf describes graphs of statements about resources
rdf is a fundamental lower layer of the semantic web
this paper explores the equality of two rdf graphs in light of the graph isomorphism literature
the standard graph isomorphism algorithms developed in the 1970s
we show that the standard graph isomorphism algorithms can be used effectively for comparing rdf graphs
we consider anonymous resources as unlabelled vertices in a graph
the techniques presented
the techniques are useful for testing rdf softwareexperience shows that the quality of the stored knowledge determines the success  of an ontology
experience shows that the quality of the stored knowledge determines therefore the effective usage  of an ontology
in fact an ontology will be even disregarded
in fact an ontology will be scarcely used
an ontology where relevant concepts are not conformant to a domain view of a given community
an ontology where relevant concepts are absent
in this paper we present a set of software tools 
software tools aimed at obtaining a shared consensus on a domain ontology content
software tools aimed at supporting domain experts in populating a domain ontology
in this paper we present a method 
consensus  is achieved in an explicit way implicitly since candidate concepts are selected among the terms that are frequently referred in the documents
a webbased groupware aimed at consensus building
the documents produced by the virtual community of users explicitly through the use of a webbased groupware
consensus  is achieved in an implicit way implicitly since candidate concepts are selected among the terms that are frequently referred in the documents
consensus  is achieved in an implicit way implicitly since candidate concepts are selected among the terms that are consistently referred in the documents
consensus  is achieved in an explicit way implicitly since candidate concepts are selected among the terms that are consistently referred in the documentsdescribing web resources using creating metadata according to a formal representation of a domain of discourse  is the essence of the next evolution step of the semantic web termed the semantic web
describing web resources using formal knowledge  is the essence of the next evolution step of the semantic web termed the semantic web
the semantic web rdfs  enables the creation and exchange of resource metadata as normal web data
resource description frameworkschema language  enables the creation and exchange of resource metadata as normal web data
in the semantic web we investigate the use of rdfs schemas as a means of knowledge representation and exchange in diverse application domains
a statistical analysis performed with the aid of vrp the validating rdf parser
in order to reason about the quality of existing rdf schemas a benchmark serves as the basis of a statistical analysis
the statistical data extracted lead to corollaries about the size
the statistical data extracted lead to corollaries about the morphology of rdfs schemas
furthermore the study of the collected schemas draws useful conclusions about frequent misuses of rdfs syntax andor semantics
furthermore the study of the collected schemas draws useful conclusions about the actual use of rdf modeling constructsensuring that ontologies are consistent is an important part of ontology development and testing
this is especially important when autonomous software agents are to use ontologies in autonomous software agents reasoning
reasoning with inconsistent ontologies may lead to erroneous conclusions
in this paper we introduce the consvisor tool for consistency checking of ontologies
the consvisor tool is the more recent ontology languages
the consvisor tool is both traditional data modeling languages
the consvisor tool is a consistency checker
consvisor checks consistency by verifying axioms
consvisor is part of the ubot toolkit
the ubot toolkit that uses a variety of techniques such as theorem proving
the ubot toolkit that uses a variety of techniques such as logic programming
some examples of the use of these tools are givenontologies are emerging as a key solution for knowledge sharing in cooperative business environment
from the technology point of view the growth of internet use has favoured the development of environments distributed work work
from the technology point of view the growth of internet use has favoured the development of environments devoted to collaborative work
work allowing different communities to increase effectiveness in different communities
work allowing different communities to increase flexibility in different communities
from the representation point of view an ontology management system represents a powerful tool to create common knowledge repositories
from the representation point of view an ontology management system represents a powerful tool to create shareable knowledge repositories
the goal of this work is to a webbased ontology management system
the goal of this work is to present symontox 
an open source environment supporting collaborative
the goal of this work is maintenance
the goal of this work is an open source environment
the goal of this work is distributed ontology constructionadvanced business document integration technologies performing intelligent document transformation
the web that require development of advanced business document integration technologies
the semantic web would enable new ways of doing business on the web
the documents use different vocabularies
different vocabularies that consist of large hierarchies of terms
accordingly vocabulary mapping becomes an important task in the whole business document transformation process
accordingly transformation becomes an important task in the whole business document transformation process
an important task in the whole business document transformation process includes map execution
an important task in the whole business document transformation process includes several subtasks
an important task in the whole business document transformation process includes map representation
map execution that must be seamlessly integrated into the document integration process
an important task in the whole business document transformation process includes map discovery
each using one of the vocabularies
in this paper we discuss the process of discovering the discovered maps each
we take the vocabularies of product classification codes as a playground
we take the vocabularies of product classification propose a reusable map discovery technique based on bayesian text classification approach
we show how the discovered maps can be integrated into the document integration processknowledgebearing arcs that lead to the node from a node
it is useful to express the location of a node in a semantic graph in terms of a sequence of knowledgebearing arcs
a node that is used as a point of reference
if the arcs on which such  graphbased depend disappear the expressions become invalid
the arcs on which such  graphbased addressing expressions several web ontology languages like damloil are based on dls
ontologies are set to play a key role in the semantic web
these not only provide a clear semantics to the ontology languages but allows these to exploit dl systems in order to provide correct reasoning services
these not only provide a clear semantics to the ontology languages but allows these to exploit dl systems in order to provide complete reasoning servicesthe semantic web promises to change the way agents harvest
the semantic web promises to change the way agents navigate
the semantic web promises to change the way agents utilize information on the internet
by providing a it is now possible for agents to reason about published knowledge without information agents
by providing a it is now possible for agents to read without information agents
by providing a it is now possible for agents to read without the need for scrapers
a structured distributed representation for expressing relationships
relationships defined by multiple ontologies
a structured distributed representation for expressing concepts
concepts defined by multiple ontologies
by providing a it is now possible for agents to reason about published knowledge without centralized ontologies
by providing a it is now possible for agents to read without centralized ontologies
by providing a it is now possible for agents to reason about published knowledge without the need for scrapers
agents can utilize this knowledge to invoke other agents thus supporting navigation across the semantic web
agents can utilize this knowledge to seek other agents thus supporting navigation across the semantic web
agents can utilize this knowledge to invoke web services thus supporting navigation across the semantic web
agents can utilize this knowledge to seek web services thus supporting navigation across the semantic web
we demonstrate how agents support enhanced navigation within present three agentbased services
we demonstrate how agents support a conference agent
we demonstrate how agents support the dma2ical translation agent
schedules grounded in different ontologies
we demonstrate how agents support enhanced navigation within a conferenceschedule domain
we demonstrate how agents support the retsina calendar agent
the retsina calendar agent which reasons about schedules marked up on the semantic web
the dma2ical translation agent which provides translation services between schedules
a conference agent that invokes the calendar agenttwo w3c standards aimed at enriching the web with machineprocessable semantic data
rdf schema are two w3c standards
rdf are two w3c standardsproduct configuration is a key technology in todays highly specialized economy
within the scope of eprocurement solutions various initiatives take into account the provision of configuration services
within the scope of stateoftheart b2b frameworks various initiatives take into account the provision of configuration services
however they all are based on the idea of defining quasistandards for manytomany relationships between customers
however they all are based on the idea of defining quasistandards for manytomany relationships between vendors
networked markets where suppliers dynamically form supplyside consortia
when moving towards networked markets more flexible approaches to b2b integration become necessary
the emerging paradigm of web services has therefore a huge potential in business application integration
this paper presents an application scenario for configuration web services this paper is currently under development in the research project cawicoms1
an ontologybased approach allows the advertisement of services
a configuration specific protocol defines the operational processes
however the lack of standards for the semantic annotation of web services is still a major shortcoming of current web technologyas long as there is not a sufficient base of rdfannotated pages the benefits of participating in the semantic web are barely visible
this is true in particular for content providers like individuals
this is true in particular for content providers like small institutions
the critical mass that will make the semantic web a success
these potential participants can not afford the additional work necessary for the semantic web yet these potential participants are needed for the semantic web to reach the critical mass
problems that may prevent small content providers from participating in the semantic web
the semantic web discusses problems
the semantic web discusses a possible way to lower the barrier for entry using tools like our own information layer systemthe usability of research papers on the web would be enhanced by a system
a system that explicitly modelled the rhetorical relations between claims in related papers
we describe claimaker 
we describe a system for modelling readers interpretations of the core content of papers
research papers using an ontology of relations
claimaker provides tools to build a semantic web representation of the claims in research papers
a system for modelling readers interpretations of the core content of papers provides tools to build a semantic web representation of the claims in research papers
a system that explicitly modelled the rhetorical relations between claims in related papers
we demonstrate how a system can be used to make interdocument queriesthis paper describes an approach to derive assessments about information sources based on individual feedback about the sources
a system that helps users annotate users analysis of alternative information sources
we describe a system
alternative information sources that can be contradictory
we describe trellis
alternative information sources that can be incomplete
as the user makes a decision on which to believe in making a final decision trellis captures the derivation of the decision in a semantic markup
as the user makes a decision on which sources to dismiss trellis captures the derivation of the decision in a semantic markup
trellis then uses these annotations to derive an assessment of the source based on the annotations of many individuals
we work builds on the semantic web and presents a tool and exploits the formal representations to derive measures of trust in the content of web resources
a tool that helps users create annotations
we work builds on the semantic web and presents a tool and exploits the formal representations to derive measures of trust in the formal representations original source
annotations that are in a mix of formal language
annotations that are in a mix of human languagethis paper describes some initial work on a netapi for accessing rdf data over the web
this paper describes some initial work on a netapi for updating rdf data over the web
a netapi for accessing rdf data over the web includes actions for conditional extraction
a netapi for updating rdf data over the web the ability to enquire about the capabilities of a hosting server
a netapi for accessing rdf data over the web update of rdf data actions for model upload and download
a netapi for updating rdf data over the web update of rdf data actions for model upload and download
a netapi for updating rdf data over the web includes actions for conditional extraction
a netapi for accessing rdf data over the web the ability to enquire about the capabilities of a hosting server
an initial experimental system is described which partially implements these ideas within the jena toolkita marketplace is the place
buyers participating in a business process
the place in which the demand and supply of buyers may meet
the place in which the demand and supply of vendors may meet
vendors participating in a business process
virtual communities in which buyers may meet proposals of several suppliers
therefore electronic marketplaces are virtual communities
virtual communities in which buyers may make the best choice
in the electronic commerce world the comparison between different products is blocked due to the lack of standards  on the contrary the proliferation of standards  describing different products
in the electronic commerce world the comparison between different products is blocked due to the lack of standards  on the contrary the proliferation of standards  classifying different products
therefore the need for b2c marketplaces is to reclassify products according to different standardization models
therefore the need for b2b marketplaces is to reclassify goods according to different standardization models
therefore the need for b2b marketplaces is to reclassify products according to different standardization models
therefore the need for b2c marketplaces is to reclassify goods according to different standardization models
a semiautomatic methodology supported by a tool
this paper aims to face this problem by suggesting the use of a semiautomatic methodology to define the mapping among different ecommerce product classification standards
a semiautomatic methodology supported by a tool
a semiautomatic methodology was developed for the momis system within the intelligent integration of information research area
the methodology that makes our extension applyable in general to product classification standard by selecting a fragment of eccmaunspsc standard
we describe we extension to the methodology
the methodology that makes our extension applyable in general to product classification standard by selecting a fragment of eclss standardthe idea of knowledge sharing has strong roots in the education process
moving learning material into the web environment the current development of the technology acquired a new dimension
moving learning material into the web environment acquired a new dimension
with the current development of the technology acquired a new dimension
learning objects are the chunks of knowledge
knowledge shared by elearning community
organizations are building repositories of annotate individuals with metadata to describe organizations standardization efforts are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate individuals with metadata to describe organizations educational values are on the way to provide a franca lingua for the educators
organizations are building repositories of learning objects educational values are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate organizations with metadata to describe individuals educational values are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate organizations with metadata to describe organizations standardization efforts are on the way to provide a franca lingua for the educators
organizations are building repositories of learning objects standardization efforts are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate organizations with metadata to describe individuals standardization efforts are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate individuals with metadata to describe individuals educational values are on the way to provide a franca lingua for the educators
individuals are building repositories of learning objects educational values are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate organizations with metadata to describe organizations educational values are on the way to provide a franca lingua for the educators
individuals are building repositories of learning objects standardization efforts are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate organizations with metadata to describe organizations standardization efforts are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate organizations with metadata to describe individuals educational values are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate individuals with metadata to describe organizations educational values are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate individuals with metadata to describe individuals standardization efforts are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate individuals with metadata to describe organizations standardization efforts are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate organizations with metadata to describe individuals standardization efforts are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate individuals with metadata to describe individuals educational values are on the way to provide a franca lingua for the educators
organizations are building repositories of annotate organizations with metadata to describe organizations educational values are on the way to provide a franca lingua for the educators
individuals are building repositories of annotate individuals with metadata to describe individuals standardization efforts are on the way to provide a franca lingua for the educators
in this paper the educators describe the peertopeer infrastructure for sharing learning object the educators are building in canada
objects connected to the peertopeer network
ponds are bigger repositories of learning objects
splash is an freely downloadable application
the pool projects builds on the three types of nodes
pool centrals increase the speed and breadth of the searches in the peertopeer network
an freely downloadable application which allows individuals to create metadata
an freely downloadable application which allows individuals to maintain individuals collection of learning objects
the pool projects uses cancore a subset of the ims metadata protocol to describe learning objects
in the second part of this paper we discuss the future direction of this initiative based on the maturing learning objects community learned in the deployment of pool network
in the second part of this paper we discuss the future direction of this initiative based on the maturing learning objects lessons learned in the deployment of pool network
solutions that are too complex
we argue that the standardization effort although very important currently provides solutions
we see the communities where the knowledge is shared to be the main force in the creation of the metadata standards
the metadata standards which would support the growth of semantic web
the implications of moving the responsibility for metadata creation on communities poses new requirements on tools
the implications of moving the responsibility for schemas on communities poses new requirements on tools
the implications of moving the responsibility for schemas on communities poses new requirements on interoperability
the implications of moving the responsibility for metadata creation on communities poses new requirements on interoperability
we outline approach we are developing to address new requirements
we describe new requirementsthis paper suggests four steps towards the realization of a semantic web
promotion of the idea should be based on practical application
there is need for the immediate development of practical demonstration applications
simplicity of error should be prime targets of development
tolerance of error should be prime targets of research
simplicity of error should be prime targets of research
tolerance of error should be prime targets of development
an open source project to develop a framework of applications should be started
an open source project to develop a framework of tools should be started
an open source project to populate a framework of applications should be started
an open source project to populate a framework of tools should be startedentailment as defined by rdfs modeltheoretical semantics is a basic requirement for processing rdf
entailment as defined by rdfs modeltheoretical semantics represents the kind of  semantic interoperability  that rdfbased systems have been anticipated to have to realize the vision of the  semantic web 
in this paper we give some results in we investigation of a practical implementation of the entailment rules based on the graphwalking query mechanism of the wilbur rdf toolkitthe darpa agent markup language ontology for services enables the description of webbased services such that the darpa agent markup language ontology for services can be discovered accessed and composed dynamically by intelligent software agents thereby facilitating the coordination between distributed heterogeneous systems on the web
the darpa agent markup language ontology for services enables the description of webbased services such that the darpa agent markup language ontology for the darpa agent markup language ontology for services can be discovered accessed and composed dynamically by other web services thereby facilitating the coordination between distributed heterogeneous systems on the web
the darpa agent markup language ontology for services enables the description of webbased services such that the darpa agent markup language ontology for services can be discovered accessed and composed dynamically by other web services thereby facilitating the coordination between distributed heterogeneous systems on the web
the darpa agent markup language ontology for services enables the description of webbased services such that the darpa agent markup language ontology for the darpa agent markup language ontology for services can be discovered accessed and composed dynamically by intelligent software agents thereby facilitating the coordination between distributed heterogeneous systems on the web
we propose a formalised an initial reference semantics for the darpa agent markup language ontology for services
we propose a formalised syntax for services
services which incorporates subtype polymorphism
the semantics we describe is derived from the semantics for concurrent haskell
the semantics we describe is derived from the semantics for erlang haskell
we contrast the semantics we describe with an alternate semantics
an alternate semantics proposed for the darpa agent markup language ontology for services based on petri nets
an alternate semantics proposed for the darpa agent markup language ontology for services based on the situation calculus
