Rules over a Knowledge Graph capture interpretable patterns in data have been proposed
Rules over various methods for rule learning have been proposed
Since KGs are inherently incomplete rules can be used to deduce missing facts
Statistical measures for learned rules such as confidence reflect rule quality well when the a Knowledge Graph is reasonably complete however Statistical measures for learned rules such as confidence might be misleading otherwise
scalability dictates that only a small set of candidate rules could be generated
So it is difficult to learn highquality rules from the a Knowledge Graph alone
Therefore pruning of candidate rules are major problems
Therefore the ranking are major problems
To address this issue we propose a rule learning method
a rule learning method that utilizes probabilistic representations of missing facts
rules induced from a a Knowledge Graph by relying on feedback from a precomputed embedding model over the a Knowledge Graph including text corpora
rules induced from a a Knowledge Graph by relying on feedback from a precomputed embedding model over external information sources including text corpora
In particular we iteratively extend rules
Experiments on realworld KGs demonstrate the effectiveness of our novel approach both with respect to the quality of fact predictions that Experiments on realworld KGs produce
Experiments on realworld KGs demonstrate the effectiveness of our novel approach both with respect to the quality of the learned rules